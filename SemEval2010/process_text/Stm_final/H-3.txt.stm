us queri context in inform retriev jing bai 1 , jian-yun nie 1 , hugu bouchard 2 , guihong cao 1 1 depart iro, univers of montreal cp. 6128, succursal centr-vill, montreal, quebec, h3c 3j7, canada {baij, nie, caogui}@iro.umontr.ca 2 yahoo! inc. montreal, quebec, canada bouchard@yahoo-inc.com abstract user queri is an element that specifi an inform need, but it is not the onli on. studi in literatur have found mani contextu factor that strongli influenc the interpret of a queri. recent studi have tri to consid the user"s interest by creat a user profil. howev, a singl profil for a user mai not be suffici for a varieti of queri of the user. in thi studi, we propos to us queri-specif context instead of user-centric on, includ context around queri and context within queri. the former specifi the environ of a queri such as the domain of interest, while the latter refer to context word within the queri, which is particularli us for the select of relev term relat. in thi paper, both type of context ar integr in an ir model base on languag model. our experi on sever trec collect show that each of the context factor bring signific improv in retriev effect. categori and subject descriptor h.3.3 [inform storag and retriev]: inform search and retriev - retriev model gener term algorithm, perform, experiment, theori. 1. introduct queri, especi short queri, do not provid a complet specif of the inform need. mani relev term can be absent from queri and term includ mai be ambigu. these issu have been address in a larg number of previou studi. typic solut includ expand either document or queri represent [19][35] by exploit differ resourc [24][31], us word sens disambigu [25], etc. in these studi, howev, it ha been gener assum that queri is the onli element avail about the user"s inform need. in realiti, queri is alwai formul in a search context. as it ha been found in mani previou studi [2][14][20][21][26], contextu factor have a strong influenc on relev judgment. these factor includ, among mani other, the user"s domain of interest, knowledg, prefer, etc. all these element specifi the context around the queri. so we call them context around queri in thi paper. it ha been demonstr that user"s queri should be place in it context for a correct interpret. recent studi have investig the integr of some context around the queri [9][30][23]. typic, a user profil is construct to reflect the user"s domain of interest and background. a user profil is us to favor the document that ar more close relat to the profil. howev, a singl profil for a user can group a varieti of differ domain, which ar not alwai relev to a particular queri. for exampl, if a user work in comput scienc issu a queri java hotel, the document on java languag will be incorrectli favor. a possibl solut to thi problem is to us queri-relat profil or model instead of user-centric on. in thi paper, we propos to model topic domain, among which the relat on(s) will be select for a given queri. thi method allow us to select more appropri queri-specif context around the queri. anoth strong contextu factor identifi in literatur is domain knowledg, or domain-specif term relat, such as program→comput in comput scienc. us thi relat, on would be abl to expand the queri program with the term comput. howev, domain knowledg is avail onli for a few domain (e.g. medicin). the shortag of domain knowledg ha led to the util of gener knowledg for queri expans [31], which is more avail from resourc such as thesauri, or it can be automat extract from document [24][27]. howev, the us of gener knowledg give rise to an enorm problem of knowledg ambigu [31]: we ar often unabl to determin if a relat appli to a queri. for exampl, usual littl inform is avail to determin whether program→comput is applic to queri java program and tv program. therefor, the relat ha been appli to all queri contain program in previou studi, lead to a wrong expans for tv program. look at the two queri exampl, howev, peopl can easili determin whether the relat is applic, by consid the context word java and tv. so the import question is how we can serv these context word in queri to select the appropri relat to appli. these context word form a context within queri. in some previou studi [24][31], context word in a queri have been us to select expans term suggest by term relat, which ar, howev, context-independ (such as program→comput). although improv ar observ in some case, thei ar limit. we argu that the problem stem from the lack of necessari context inform in relat themselv, and a more radic solut li in the addit of context in relat. the method we propos is to add context word into the condit of a relat, such as {java, program} → comput, to limit it applic to the appropri context. thi paper aim to make contribut on the follow aspect: • queri-specif domain model: we construct more specif domain model instead of a singl user model group all the domain. the domain relat to a specif queri is select (either manual or automat) for each queri. • context within queri: we integr context word in term relat so that onli appropri relat can be appli to the queri. • multipl contextu factor: final, we propos a framework base on languag model approach to integr multipl contextu factor. our approach ha been test on sever trec collect. the experi clearli show that both type of context can result in signific improv in retriev effect, and their effect ar complementari. we will also show that it is possibl to determin the queri domain automat, and thi result in compar effect to a manual specif of domain. thi paper is organ as follow. in section 2, we review some relat work and introduc the principl of our approach. section 3 present our gener model. then section 4 and 5 describ respect the domain model and the knowledg model. section 6 explain the method for paramet train. experi ar present in section 7 and conclus in section 8. 2. context and util in ir there ar mani contextu factor in ir: the user"s domain of interest, knowledg about the subject, prefer, document recenc, and so on [2][14]. among them, the user"s domain of interest and knowledg ar consid to be among the most import on [20][21]. in thi section, we review some of the studi in ir concern these aspect. domain of interest and context around queri a domain of interest specifi a particular background for the interpret of a queri. it can be us in differ wai. most often, a user profil is creat to encompass all the domain of interest of a user [23]. in [5], a user profil contain a set of topic categori of odp (open directori project, http://dmoz.org) identifi by the user. the document (web page) classifi in these categori ar us to creat a term vector, which repres the whole domain of interest of the user. on the other hand, [9][15][26][30], as well as googl person search [12] us the document read by the user, store on user"s comput or extract from user"s search histori. in all these studi, we observ that a singl user profil (usual a statist model or vector) is creat for a user without distinguish the differ topic domain. the systemat applic of the user profil can incorrectli bia the result for queri unrel to the profil. thi situat can often occur in practic as a user can search for a varieti of topic outsid the domain that he ha previous search in or identifi. a possibl solut to thi problem is the creation of multipl profil, on for a separ domain of interest. the domain relat to a queri ar then identifi accord to the queri. thi will enabl us to us a more appropri queri-specif profil, instead of a user-centric on. thi approach is us in [18] in which odp directori ar us. howev, onli a small scale experi ha been carri out. a similar approach is us in [8], where domain model ar creat us odp categori and user queri ar manual map to them. howev, the experi show variabl result. it remain unclear whether domain model can be effect us in ir. in thi studi, we also model topic domain. we will carri out experi on both automat and manual identif of queri domain. domain model will also be integr with other factor. in the follow discuss, we will call the topic domain of a queri a context around queri to contrast with anoth context within queri that we will introduc. knowledg and context within queri due to the unavail of domain-specif knowledg, gener knowledg resourc such as wordnet and term relat extract automat have been us for queri expans [27][31]. in both case, the relat ar defin between two singl term such as t1→t2. if a queri contain term t1, then t2 is alwai consid as a candid for expans. as we mention earlier, we ar face with the problem of relat ambigu: some relat appli to a queri and some other should not. for exampl, program→comput should not be appli to tv program even if the latter contain program. howev, littl inform is avail in the relat to help us determin if an applic context is appropri. to remedi thi problem, approach have been propos to make a select of expans term after the applic of relat [24][31]. typic, on defin some sort of global relat between the expans term and the whole queri, which is usual a sum of it relat to everi queri word. although some inappropri expans term can be remov becaus thei ar onli weakli connect to some queri term, mani other remain. for exampl, if the relat program→comput is strong enough, comput will have a strong global relat to the whole queri tv program and it still remain as an expans term. it is possibl to integr stronger control on the util of knowledg. for exampl, [17] defin strong logic relat to encod knowledg of differ domain. if the applic of a relat lead to a conflict with the queri (or with other piec of evid), then it is not appli. howev, thi approach requir encod all the logic consequ includ contradict in knowledg, which is difficult to implement in practic. in our earlier studi [1], a simpler and more gener approach is propos to solv the problem at it sourc, i.e. the lack of context inform in term relat: by introduc stricter condit in a relat, for exampl {java, program}→comput and {algorithm, program}→comput, the applic of the relat will be natur restrict to correct context. as a result, comput will be us to expand queri java program or program algorithm, but not tv program. thi principl is similar to that of [33] for word sens disambigu. howev, we do not explicitli assign a mean to a word; rather we try to make differ between word usag in differ context. from thi point of view, our approach is more similar to word sens discrimin [27]. in thi paper, we us the same approach and we will integr it into a more global model with other context factor. as the context word ad into relat allow us to exploit the word context within the queri, we call such factor context within queri. within queri context exist in mani queri. in fact, user often do not us a singl ambigu word such as java as queri (if thei ar awar of it ambigu). some context word ar often us togeth with it. in these case, context within queri ar creat and can be exploit. queri profil and other factor mani attempt have been made in ir to creat queri-specif profil. we can consid implicit feedback or blind feedback [7][16][29][32][35] in thi famili. a short-term feedback model is creat for the given queri from feedback document, which ha been proven to be effect to captur some aspect of the user"s intent behind the queri. in order to creat a good queri model, such a queri-specif feedback model should be integr. there ar mani other contextu factor ([26]) that we do not deal with in thi paper. howev, it seem clear that mani factor ar complementari. as found in [32], a feedback model creat a local context relat to the queri, while the gener knowledg or the whole corpu defin a global context. both type of context have been proven us [32]. domain model specifi yet anoth type of us inform: it reflect a set of specif background term for a domain, for exampl pollut, rain, greenhous, etc. for the domain of environ. these term ar often presum when a user issu a queri such as wast cleanup in the domain. it is us to add them into the queri. we see a clear complementar among these factor. it is then us to combin them togeth in a singl ir model. in thi studi, we will integr all the abov factor within a unifi framework base on languag model. each compon contextu factor will determin a differ rank score, and the final document rank combin all of them. thi is describ in the follow section. 3. gener ir model in the languag model framework, a typic score function is defin in kl-diverg as follow: ( ) ( ) ( ) ( )dq vt dq kltptpdqscore θθθθ |||log|, −∝= ∑∈ (1) where θd is a (unigram) languag model creat for a document d, θq a languag model for the queri q, and v the vocabulari. smooth on document model is recogn to be crucial [35], and on of common smooth method is the jelinek-mercer interpol smooth: ( ) ( ) ( ) ( )cdd tptptp θλθλθ ||1'| +−= (2) where λ is an interpol paramet and θc the collect model. in the basic languag model approach, the queri model is estim by maximum likelihood estim (mle) without ani smooth. in such a set, the basic retriev oper is still limit to keyword match, accord to a few word in the queri. to improv retriev effect, it is import to creat a more complet queri model that repres better the inform need. in particular, all the relat and presum word should be includ in the queri model. a more complet queri model by sever method have been propos us feedback document [16][35] or us term relat [1][10][34]. in these case, we construct two model for the queri: the initi queri model contain onli the origin term, and a new model contain the ad term. thei ar then combin through interpol. in thi paper, we gener thi approach and integr more model for the queri. let us us 0 qθ to denot the origin queri model, f qθ for the feedback model creat from feedback document, dom qθ for a domain model and k qθ for a knowledg model creat by appli term relat. 0 qθ can be creat by mle. f qθ ha been us in sever previou studi [16][35]. in thi paper, f qθ is extract us the 20 blind feedback document. we will describ the detail to construct dom qθ and k qθ in section 4 and 5. given these model, we creat the follow final queri model by interpol: ∑∈ = xi i qiq tptp )|()|( θαθ (3) where x={0, dom, k, f} is the set of all compon model and iα (with 1=∑∈xi iα ) ar their mixtur weight. then the document score in equat (1) is extend as follow: ( ) ∑∑∑ ∈∈ ∈ == xi ii vt xi d i qi dqscoretptpdqscor ),()|(log)|(, αθθα (4) where )|(log)|(),( d vt i qi tptpdqscore θθ∑∈ = is the score accord to each compon model. here we can see that our strategi of enhanc the queri model by contextu factor is equival to document re-rank, which is us in [5][15][30]. the remain problem is to construct domain model and knowledg model and to combin all the model (paramet set). we describ thi in the follow section. 4. construct and us domain model as in previou studi, we exploit a set of document alreadi classifi in each domain. these document can be identifi in two differ wai: 1) on can take advantag of an exist domain hierarchi and the document manual classifi in them, such as odp. in that case, a new queri should be classifi into the same domain either manual or automat. 2) a user can defin hi own domain. by assign a domain to hi queri, the system can gather a set of answer to the queri automat, which ar then consid to be in-domain document. the answer could be those that the user have read, brows through, or judg relev to an in-domain queri, or thei can be simpli the top-rank retriev result. an earlier studi [4] ha compar the abov two strategi us trec queri 51-150, for which a domain ha been manual assign. these domain have been map to odp categori. it is found that both approach mention abov ar equal effect and result in compar perform. therefor, in thi studi, we onli us the second approach. thi choic is also motiv by the possibl to compar between manual and automat assign of domain to a new queri. thi will be explain in detail in our experi. whatev the strategi, we will obtain a set of document for each domain, from which a languag model can be extract. if maximum likelihood estim is us directli on these document, the result domain model will contain both  domain-specif term and gener term, and the former do not emerg. therefor, we emploi an em process to extract the specif part of the domain as follow: we assum that the document in a domain ar gener by a domain-specif model (to be extract) and gener languag model (collect model). then the likelihood of a document in the domain can be formul as follow: ( ) ( ) ( ) ( )[ ] ( ) ∏∈ +−= dt dtc cdomdom tptpdp ; ||1'| θηθηθ (5) where c(t; d) is the count of t in document d and η is a smooth paramet (which will be fix at 0.5 as in [35]). the em algorithm is us to extract the domain model domθ that maxim p(dom| θ"dom) (where dom is the set of document in the domain), that is: ( ) ( ) ( ) ( )[ ] ( ) ∏ ∏∈ ∈ +−= = domd dt dtc cdom domdom tptp domp dom dom ; ' ||1maxarg |maxarg θηθη θθ θ θ (6) thi is the same process as the on us to extract feedback model in [35]. it is abl to extract the most specif word of the domain from the document while filter out the common word of the languag. thi can be observ in the follow tabl, which show some word in the domain model of environ befor and after em iter (50 iter). tabl 1. term probabl befor/after em term initi final chang term initi final chang air 0.00358 0.00558 + 56% year 0.00357 0.00052 - 86% environ 0.00213 0.00340 + 60% system 0.00212 7.13*e-6 - 99% rain 0.00197 0.00336 + 71% program 0.00189 0.00040 - 79% pollut 0.00177 0.00301 + 70% million 0.00131 5.80*e-6 - 99% storm 0.00176 0.00302 + 72% make 0.00108 5.79*e-5 - 95% flood 0.00164 0.00281 + 71% compani 0.00099 8.52*e-8 - 99% tornado 0.00072 0.00125 + 74% presid 0.00077 2.71*e-6 - 99% greenhous 0.00034 0.00058 + 72% month 0.00073 3.88*e-5 - 95% given a set of domain model, the relat on have to be assign to a new queri. thi can be done manual by the user or automat by the system us queri classif. we will compar both approach. queri classif ha been investig in sever studi [18][28]. in thi studi, we us a simpl classif method: the select domain is the on with which the queri"s kl-diverg score is the lowest, i.e.: )|(log)|(minarg 0 dom qt q dom q tptp dom θθθ θ ∑∈ = (7) thi classif method is an extens to naïve bay as shown in [22]. the score depend on the domain model is then as follow: ∑∈ = vt d dom qdom tptpdqscore )|(log)|(),( θθ (8) although the abov equat requir us all the term in the vocabulari, in practic, onli the strongest term in the domain model ar us and the term with low probabl ar often nois. therefor, we onli retain the top 100 strongest term. the same strategi is us for knowledg model. although domain model ar more refin than a singl user profil, the topic in a singl domain can still be veri differ, make the domain model too larg. thi is particularli true for larg domain such as scienc and technolog defin in trec queri. us such a larg domain model as the background can introduc much nois term. therefor, we further construct a  sub-domain model more relat to the given queri, by us a subset of in-domain document that ar relat to the queri. these document ar the top-rank document retriev with the origin queri within the domain. thi approach is inde a combin of domain and feedback model. in our experi, we will see that thi further specif of sub-domain is necessari in some case, but not in all, especi when feedback model is also us. 5. extract context-depend term relat from document in thi paper, we extract term relat from the document collect automat. in gener, a term relat can be repres as a→b. both a and b have been restrict to singl term in previou studi. a singl term in a mean that the relat is applic to all the queri contain that term. as we explain earlier, thi is the sourc of mani wrong applic. the solut we propos is to add more context term into a, so that it is applic onli when all the term in a appear in a queri. for exampl, instead of creat a context-independ relat java→program, we will creat {java, comput}→program, which mean that program is select when both java and comput appear in a queri. the term ad in the condit specifi a stricter context to appli the relat. we call thi type of relat context-depend relat. in principl, the addit is not restrict to on term. howev, we will make thi restrict due to the follow reason: • user queri ar usual veri short. ad more term into the condit will creat mani rare applic relat; • in most case, an ambigu word such as java can be effect disambigu by on us context word such as comput or hotel; • the addit of more term will also lead to a higher space and time complex for extract and store term relat. the extract of relat of type {tj,tk} → ti can be perform us mine algorithm for associ rule [13]. here, we us a simpl co-occurr analysi. window of fix size (10 word in our case) ar us to obtain co-occurr count of three term, and the probabl )|( kji tttp is determin as follow: ∑= lt kjlkjikji tttctttctttp ),,(),,()|( (9) where ),,( kji tttc is the count of co-occurr. in order to reduc space requir, we further appli the follow filter criteria: • the two term in the condit should appear at least certain time togeth in the collect (10 in our case) and thei should be relat. we us the follow pointwis mutual inform as a measur of related (mi > 0) [6]: )()( ),( log),( kj kj kj tptp ttp ttmi = • the probabl of a relat should be higher than a threshold (0.0001 in our case); have a set of relat, the correspond knowledg model is defin as follow: )|()|()|( )|()|()|( 00 )( 0 )( qkqjkj qtt i qkjkj qtt i k q tptptttp ttptttptp kj kj θθ θθ ∑ ∑ ∈ ∈ = = (10) where (tj tk)∈q mean ani combin of two term in the queri. thi is a direct extens of the translat model propos in [3] to our context-depend relat. the score accord to the knowledg model is then defin as follow: ∑ ∑∈ ∈ = vt diqkqjkj qtt ik i kj tptptptttpdqscore )|(log)|()|()|(),( 00 )( θθθ (11) again, onli the top 100 expans term ar us. 6. model paramet there ar sever paramet in our model: λ in equat (2) and αi (i∈{0, dom, k, f}) in equat (3). as the paramet λ onli affect document model, we will set it to the same valu in all our experi. the valu λ=0.5 is determin to maxim the effect of the baselin model (see section 7.2) on the train data: trec queri 1-50 and document on disk 2. the mixtur weight αi of compon model ar train on the same train data us the follow method of line search [11] to maxim the mean averag precis (map): each paramet is consid as a search direct. we start by search in on direct - test all the valu in that direct, while keep the valu in other direct unchang. each direct is search in turn, until no improv in map is observ. in order to avoid be trap at a local maximum, we start from 10 random point and the best set is select. 7. experi 7.1 set the main test data ar those from trec 1-3 ad-hoc and filter track, includ queri 1-150, and document on disk 1-3. the choic of thi test collect is due to the avail of manual specifi domain for each queri. thi allow us to compar with an approach us automat domain identif. below is an exampl of topic: <num> number: 103 <dom> domain: law and govern <titl> topic: welfar reform we onli us topic titl in all our test. queri 1-50 ar us for train and 51-150 for test. 13 domain ar defin in these queri and their distribut among the two set of queri ar shown in fig. 1. we can see that the distribut vari strongli between domain and between the two queri set. we have also test on trec 7 and 8 data. for thi seri of test, each collect is us in turn as train data while the other is us for test. some statist of the data ar describ in tab. 2. all the document ar preprocess us porter stemmer in lemur and the standard stoplist is us. some queri (4, 5 and 3 in the three queri set) onli contain on word. for these queri, knowledg model is not applic. on domain model, we examin sever question: • when queri domain is specifi manual, is it us to incorpor the domain model? • if the queri domain is not specifi, can it be determin automat? how effect is thi method? • we describ two wai to gather document for a domain: either us document judg relev to queri in the domain or us document retriev for these queri. how do thei compar? on knowledg model, in addit to test it effect, we also want to compar the context-depend relat with context-independ on. final, we will see the impact of each compon model when all the factor ar combin. 7.2 baselin method two baselin model ar us: the classic unigram model without ani expans, and the model with feedback. in all the experi, document model ar creat us jelinek-mercer smooth. thi choic is made accord to the observ in [36] that the method perform veri well for long queri. in our case, as queri ar expand, thei perform similarli to long queri. in our preliminari test, we also found thi method perform better than the other method (e.g. dirichlet), especi for the main baselin method with feedback model. tabl 3 show the retriev effect on all the collect. 7.3 knowledg model thi model is combin with both baselin model (with or without feedback). we also compar the context-depend knowledg model with the tradit context-independ term relat (defin between two singl term), which ar us to expand queri. thi latter select expans term with strongest global relat to the queri. thi relat is measur by the sum of relat to each of the queri term. thi method is equival to [24]. it is also similar to the translat model [3]. we call it 0 5 10 15 20 25 30 35 environm entfin int.econom ic int.financ int.polit int.r elat law &g ov. m edic&bio.m ilitarypolit sci.&tech. u s econom ic u s polit queri 1-50 queri 51-150 figur 1. distribut of domain tabl 2. trec collect statist collect document size (gb) voc. # of doc. queri train disk 2 0.86 350,085 231,219 1-50 disk 1-3 disk 1-3 3.10 785,932 1,078,166 51-150 trec7 disk 4-5 1.85 630,383 528,155 351-400 trec8 disk 4-5 1.85 630,383 528,155 401-450 co-occurr model in tabl 4. t-test is also perform for statist signific. as we can see, simpl co-occurr relat can produc rel strong improv; but context-depend relat can produc much stronger improv in all case, especi when feedback is not us. all the improv over  cooccurr model ar statist signific (thi is not shown in the tabl). the larg differ between the two type of relat clearli show that context-depend relat ar more appropri for queri expans. thi confirm the hypothesi we made, that by incorpor context inform into relat, we can better determin the appropri relat to appli and thu avoid introduc inappropri expans term. the follow exampl can further confirm thi observ, where we show the strongest expans term suggest by both type of relat for the queri #384 space station moon: co-occurr relat: year 0.016552 power 0.013226 time 0.010925 1 0.009422 develop 0.008932 offic 0.008485 oper 0.008408 2 0.007875 earth 0.007843 work 0.007801 radio 0.007701 system 0.007627 build 0.007451 000 0.007403 includ 0.007377 state 0.007076 program 0.007062 nation 0.006937 open 0.006889 servic 0.006809 air 0.006734 space 0.006685 nuclear 0.006521 full 0.006425 make 0.006410 compani 0.006262 peopl 0.006244 project 0.006147 unit 0.006114 gener 0.006036 dai 0.006029 context-depend relat: space 0.053913 mar 0.046589 earth 0.041786 man 0.037770 program 0.033077 project 0.026901 base 0.025213 orbit 0.025190 build 0.025042 mission 0.023974 call 0.022573 explor 0.021601 launch 0.019574 develop 0.019153 shuttl 0.016966 plan 0.016641 flight 0.016169 station 0.016045 intern 0.016002 energi 0.015556 oper 0.014536 power 0.014224 transport 0.012944 construct 0.012160 nasa 0.011985 nation 0.011855 perman 0.011521 japan 0.011433 apollo 0.010997 lunar 0.010898 in comparison with the baselin model with feedback (tab. 3), we see that the improv made by knowledg model alon ar slightli lower. howev, when both model ar combin, there ar addit improv over the feedback model, and these improv ar statist signific in 2 case out of 3. thi demonstr that the impact produc by feedback and term relat ar differ and complementari. 7.4 domain model in thi section, we test sever strategi to creat and us domain model, by exploit the domain inform of the queri set in variou wai. strategi for creat domain model: c1 - with the relev document for the in-domain queri: thi strategi simul the case where we have an exist directori in which document relev to the domain ar includ. c2 - with the top-100 document retriev with the in-domain queri: thi strategi simul the case where the user specifi a domain for hi queri without judg document relev, and the system gather relat document from hi search histori. strategi for us domain model: u1 - the domain model is determin by the user manual. u2 - the domain model is determin by the system. 7.4.1 creat domain model we test strategi c1 and c2. in thi seri of test, each of the queri 51-150 is us in turn as the test queri while the other queri and their relev document (c1) or top-rank retriev document (c2) ar us to creat domain model. the same method is us on queri 1-50 to tune the paramet. tabl 3. baselin model unigram model coll. measur without fb with fb avgp 0.1570 0.2344 (+49.30%) recal /48 355 15 711 19 513disk 1-3 p@10 0.4050 0.5010 avgp 0.1656 0.2176 (+31.40%) recal /4 674 2 237 2 777trec7 p@10 0.3420 0.3860 avgp 0.2387 0.2909 (+21.87%) recal /4 728 2 764 3 237trec8 p@10 0.4340 0.4860 tabl 4. knowledg model co-occurr knowledg model coll. measur without fb with fb without fb with fb avgp 0.1884 (+20.00%)++ 0.2432 (+3.75%)** 0.2164 (+37.83%)++ 0.2463 (+5.08%)** recal /48 355 17 430 20 020 18 944 20 260 disk1-3 p@10 0.4640 0.5160 0.5050 0.5120 avgp 0.1823 (+10.08%)++ 0.2350 (+8.00%)* 0.2157 (+30.25%)++ 0.2401 (+10.34%)** recal /4 674 2 329 2 933 2 709 2 985 trec7 p@10 0.3780 0.3760 0.3900 0.3900 avgp 0.2519 (+5.53%) 0.2926 (+0.58%) 0.2724 (+14.12%)++ 0.3007 (+3.37%) recal /4 728 2 829 3 279 3 090 3 338 trec8 p@10 0.4360 0.4940 0.4720 0.5000 (the column withoutfb is compar to the baselin model without feedback, while withfb is compar to the baselin with feedback. ++ and + mean signific chang in t-test with respect to the baselin without feedback, at the level of p<0.01 and p<0.05, respect. ** and * ar similar but compar to the baselin model with feedback.) tabl 5. domain model with relev document (c1) domain sub-domain coll. measur without fb with fb without fb with fb avgp 0.1700 (+8.28%)++ 0.2454 (+4.69%)** 0.1918 (+22.17%)++ 0.2461 (+4.99%)** recal /48 355 16 517 20 141 17 872 20 212 disk1-3 (u1) p@10 0.4370 0.5130 0.4490 0.5150 avgp 0.1715 (+3.56%)++ 0.2389 (+9.79%)* 0.1842 (+11.23%)++ 0.2408 (+10.66%)** recal /4 674 2 270 2 965 2 428 2 987 trec7 (u2) p@10 0.3720 0.3740 0.3880 0.3760 avgp 0.2442 (+2. 30%) 0.2957 (+1.65%) 0.2563 (+7.37%) 0.2967 (+1.99%) recal /4 728 2 796 3 308 2 873 3 302 trec8 (u2) p@10 0.4420 0.5000 0.4280 0.5020 tabl 6. domain model with top-100 document (c2) domain sub-domain coll. measur without fb with fb without fb with fb avgp 0.1718 (+9.43%)++ 0.2456 (+4.78%)** 0.1799 (+14.59%)++ 0.2452 (+4.61%)** recal /48 355 16 558 20 131 17 341 20 155 disk1-3 (u1) p@10 0.4300 0.5140 0.4220 0.5110 avgp 0.1765 (+6.58%)++ 0.2395 (+10.06%)** 0.1785 (+7.79%)++ 0.2393 (+9.97%)** recal /4 674 2 319 2 969 2 254 2 968 trec7 (u2) p@10 0.3780 0.3820 0.3820 0.3820 avgp 0.2434 (+1.97%) 0.2949 (+1.38%) 0.2441 (+2.26%) 0.2961 (+1.79%) recal /4 728 2 772 3 318 2 734 3 311 trec8 (u2) p@10 0.4380 0.4960 0.4280 0.5020 we also compar the domain model creat with all the  indomain document (domain) and with onli the top-10 retriev document in the domain with the queri (sub-domain). in these test, we us manual identif of queri domain for disk 1-3 (u1), but automat identif for trec7 and 8 (u2). first, it is interest to notic that the incorpor of domain model can gener improv retriev effect in all the case. the improv on disk 1-3 and trec7 ar statist signific. howev, the improv scale ar smaller than us feedback and relat model. look at the distribut of the domain (fig. 1), thi observ is not surpris: for mani domain, we onli have few train queri, thu few  indomain document to creat domain model. in addit, topic in the same domain can vari greatli, in particular in larg domain such as scienc and technolog, intern polit, etc. second, we observ that the two method to creat domain model perform equal well (tab. 6 vs. tab. 5). in other word, provid relev judgment for queri doe not add much advantag for the purpos of creat domain model. thi mai seem surpris. an analysi immedi show the reason: a domain model (in the wai we creat) onli captur term distribut in the domain. relev document for all in-domain queri vari greatli. therefor, in some larg domain, characterist term have variabl effect on queri. on the other hand, as we onli us term distribut, even if the top document retriev for the in-domain queri ar irrelev, thei can still contain domain characterist term similarli to relev document. thu both strategi produc veri similar effect. thi result open the door for a simpler method that doe not requir relev judgment, for exampl us search histori. third, without feedback model, the sub-domain model construct with relev document perform much better than the whole domain model (tab. 5). howev, onc feedback model is us, the advantag disappear. on on hand, thi confirm our earlier hypothesi that a domain mai be too larg to be abl to suggest relev term for new queri in the domain. it indirectli valid our first hypothesi that a singl user model or profil mai be too larg, so smaller domain model ar prefer. on the other hand, sub-domain model captur similar characterist to feedback model. so when the latter is us, sub-domain model becom superflu. howev, if domain model ar construct with top-rank document (tab. 6), sub-domain model make much less differ. thi can be explain by the fact that the domain construct with top-rank document tend to be more uniform than relev document with respect to term distribut, as the top retriev document usual have stronger statist correspond with the queri than the relev document. 7.4.2 determin queri domain automat it is not realist to alwai ask user to specifi a domain for their queri. here, we examin the possibl to automat identifi queri domain. tabl 7 show the result with thi strategi us both strategi for domain model construct. we can observ that the effect is onli slightli lower than those produc with manual identif of queri domain (tab. 5 & 6, domain model). thi show that automat domain identif is a wai to select domain model as effect as manual identif. thi also demonstr the feasibl to us domain model for queri when no domain inform is provid. look at the accuraci of the automat domain identif, howev, it is surprisingli low: for queri 51-150, onli 38% of the determin domain correspond to the manual identif. thi is much lower than the abov 80% rate report in [18]. a detail analysi reveal that the main reason is the close of sever domain in trec queri (e.g. intern relat, intern polit, polit). howev, in thi situat, wrong domain assign to queri ar not alwai irrelev and useless. for exampl, even when a queri in intern relat is classifi in intern polit, the latter domain can still suggest us term to the queri. therefor, the rel low classif accuraci doe not mean low us of the domain model. 7.5 complet model the result with the complet model ar shown in tabl 8. thi model integr all the compon describ in thi paper: origin queri model, feedback model, domain model and knowledg model. we have test both strategi to creat domain model, but the differ between them ar veri small. so we onli report the result with the relev document. our first observ is that the complet model produc the best result. all the improv over the baselin model (with feedback) ar statist signific. thi result confirm that the integr of contextu factor is effect. compar to the other result, we see consist, although small in some case, improv over all the partial model. look at the mixtur weight, which mai reflect the import of each model, we observ that the best set in all the collect vari in the follow rang: 0.1≤α0 ≤0.2, 0.1≤αdom ≤0.2, 0.1≤αk ≤0.2 and 0.5≤αf ≤0.6. we see that the most import factor is feedback model. thi is also the singl factor which produc the highest improv over the origin queri model. thi observ seem to indic that thi model ha the highest capabl to captur the inform need behind the queri. howev, even with lower weight, the other model do have strong impact on the final effect. thi demonstr the benefit of integr more contextu factor in ir. tabl 7. automat queri domain identif (u2) dom. with rel. doc. (c1) dom. with top-100 doc. (c2) coll. measur without fb with fb without fb with fb avgp 0.1650 (+5.10%)++ 0.2444 (+4.27%)** 0.1670 (+6.37%)++ 0.2449 (+4.48%)** recal 16 343 20 061 16 414 20 090 disk 1-3 (u2) p@10 0.4270 0.5100 0.4090 0.5140 tabl 8. complet model (c1) all doc. domain coll. measur man. dom. id. (u1) auto. dom. id. (u2) avgp 0.2501 (+6.70%) ** 0.2489 (+6.19%) ** recal /48 355 20 514 20 367 disk 1-3 p@10 0.5200 0.5230 avgp 0.2462 (+13.14%) ** recal /4 674 3 014trec7 p@10 n/a 0.3960 avgp 0.3029 (+4.13%) ** recal /4 728 3 321trec8 p@10 n/a 0.5020 8. conclus tradit ir approach usual consid the queri as the onli element avail for the user inform need. mani previou studi have investig the integr of some contextu factor in ir model, typic by incorpor a user profil. in thi paper, we argu that a singl user profil (or model) can contain a too larg varieti of differ topic so that new queri can be incorrectli bias. similarli to some previou studi, we propos to model topic domain instead of the user. previou investig on context focus on factor around the queri. we show in thi paper that factor within the queri ar also import - thei help select the appropri term relat to appli in queri expans. we have integr the abov contextu factor, togeth with feedback model, in a singl languag model. our experiment result strongli confirm the benefit of us context in ir. thi work also show that the languag model framework is appropri for integr mani contextu factor. thi work can be further improv on sever aspect, includ other method to extract term relat, to integr more context word in condit and to identifi queri domain. it would also be interest to test the method on web search us user search histori. we will investig these problem in our futur research. 9. refer [1] bai, j., nie, j.y., cao, g., context-depend term relat for inform retriev, emnlp"06, pp. 551-559, 2006. [2] belkin, n.j., interact with text: inform retriev as inform seek behavior, inform retriev"93: von der modellierung zu anwendung, pp. 55-66, konstanz: kraus & womser-hacker, 1993. [3] berger, a., lafferti, j., inform retriev as statist translat, sigir"99, pp. 222-229, 1999. [4] bouchard, h., nie, j.y., modèle de langu appliqués à la recherch d"inform contextuel, conf. en recherch d"inform et applic (coria), lyon, 2006. [5] chirita, p.a., paiu, r., nejdl, w., kohlschütter, c., us odp metadata to person search, sigir, pp. 178-185, 2005. [6] church, k. w., hank, p., word associ norm, mutual inform, and lexicographi. acl, pp. 22-29, 1989. [7] croft, w. b., cronen-townsend, s., lavrenko, v., relev feedback and person: a languag model perspect, in: the delo-nsf workshop on person and recommend system digit librari, pp. 49-54, 2006. [8] croft, w. b., wei, x., context-base topic model for queri modif, ciir technic report, univers of massachusett, 2005. [9] dumai, s., cutrel, e., cadiz, j., janck, g., sarin, r., robbin, d. c., stuff i've seen: a system for person inform retriev and re-us, sigir'03, pp. 72-79, 2003. [10] fang, h., zhai, c., semant term match in axiomat approach to inform retriev, sigir"06, pp.115-122, 2006. [11] gao, j., qi, h., xia, x., nie, j.-y., linear discrimin model for inform retriev. sigir"05, pp. 290-297, 2005. [12] gool person search, http://www.googl.com/psearch. [13] hipp, j., guntzer, u., nakhaeizadeh, g., algorithm for associ rule mine - a gener survei and comparison. sigkdd explor, 2 (1), pp. 58-64, 2000. [14] ingwersen, p., jäverlin, k., inform retriev in context: irix, sigir forum, 39: pp. 31-39, 2004. [15] kim, h.-r., chan, p.k., person rank of search result with learn user interest hierarchi from bookmark, webkdd"05 workshop at acm-kdd, pp. 32-43, 2005. [16] lavrenko, v., croft, w. b., relev-base languag model, sigir"01, pp. 120-127, 2001. [17] lau, r., bruza, p., song, d., belief revis for adapt inform retriev, sigir"04, pp. 130-137, 2004. [18] liu, f., yu,c., meng, w., person web search by map user queri to categori, cikm"02, pp. 558-565. [19] liu, x., croft, w. b., cluster-base retriev us languag model, sigir '04, pp. 186-193, 2004. [20] morri, r.c., toward a user-center inform servic, jasi, 45: pp. 20-30, 1994. [21] park, t.k., toward a theori of user-base relev: a call for a new paradigm of inquiri, jasi, 45: pp. 135-141, 1994. [22] peng, f., schuurman, d., wang, s. augment naiv bay classifi with statist languag model. inf. retr. 7(3-4): pp. 317-345, 2004. [23] pitkow, j., schütze, h., cass, t., coolei, r., turnbul, d., edmond, a., adar, e., breuel, t., person search, commun of acm, 45: pp. 50-55, 2002. [24] qiu, y., frei, h.p. concept base queri expans. sigir"93, pp.160-169, 1993. [25] sanderson, m., retriev with good sens, inf. ret., 2(1): pp. 49-69, 2000. [26] schamber, l., eisenberg, m.b., nilan, m.s., a  reexamin of relev: toward a dynam, situat definit, inform process and manag, 26(6): pp. 755-774, 1990. [27] schütze, h., pedersen j.o., a cooccurr-base thesauru and two applic to inform retriev, inform process and manag, 33(3): pp. 307-318, 1997. [28] shen, d., pan, r., sun, j-t., pan, j.j., wu, k., yin, j., yang, q. queri enrich for web-queri classif.  acmtoi, 24(3): pp. 320-352, 2006. [29] shen, x., tan, b., zhai, c., context-sensit inform retriev us implicit feedback, sigir"05, pp. 43-50, 2005. [30] teevan, j., dumai, s.t., horvitz, e., person search via autom analysi of interest and activ, sigir"05, pp. 449-456, 2005. [31] voorhe, e., queri expans us lexic-semant relat. sigir"94, pp. 61-69, 1994. [32] xu, j., croft, w.b., queri expans us local and global document analysi, sigir"96, pp. 4-11, 1996. [33] yarowski, d. unsupervis word sens disambigu rival supervis method. acl, pp. 189-196. 1995. [34] zhou x., hu x., zhang x., lin x., song i-y.,  contextsensit semant smooth for the languag model approach to genom ir, sigir"06, pp. 170-177, 2006. [35] zhai, c., lafferti, j., model-base feedback in the languag model approach to inform retriev, cikm"01, pp. 403-410, 2001. [36] zhai, c., lafferti, j., a studi of smooth method for languag model appli to ad-hoc inform retriev. sigir, pp.334-342, 2001. 