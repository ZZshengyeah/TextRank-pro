latent concept expans us markov random field donald metzler metzler@cs.umass.edu w. bruce croft croft@cs.umass.edu center for intellig inform retriev depart of comput scienc univers of massachusett amherst, ma 01003 abstract queri expans, in the form of pseudo-relev feedback or relev feedback, is a common techniqu us to  improv retriev effect. most previou approach have ignor import issu, such as the role of featur and the import of model term depend. in thi paper, we propos a robust queri expans techniqu base on the markov random field model for inform retriev. the techniqu, call latent concept expans, provid a mechan for model term depend dure  expans. furthermor, the us of arbitrari featur within the model provid a power framework for go beyond  simpl term occurr featur that ar implicitli us by most other expans techniqu. we evalu our  techniqu against relev model, a state-of-the-art languag model queri expans techniqu. our model  demonstr consist and signific improv in retriev effect across sever trec data set. we also  describ how our techniqu can be us to gener  meaning multi-term concept for task such as queri  suggest/reformul. categori and subject descriptor h.3.3 [inform storag and retriev]: inform search and retriev gener term algorithm, experiment, theori 1. introduct user of inform retriev system ar requir to  express complex inform need in term of boolean  express, a short list of keyword, a sentenc, a question, or possibl a longer narr. a great deal of inform is lost dure the process of translat from the inform need to the actual queri. for thi reason, there ha been a strong interest in queri expans techniqu. such  techniqu ar us to augment the origin queri to produc a represent that better reflect the underli  inform need. queri expans techniqu have been well studi for variou model in the past and have shown to significantli improv effect in both the relev feedback and pseudo-relev feedback set [12, 21, 28, 29]. recent, a markov random field (mrf) model for  inform retriev wa propos that goe beyond the  simplist bag of word assumpt that underli bm25 and the (unigram) languag model approach to inform  retriev [20, 22]. the mrf model gener the unigram, bigram, and other variou depend model [14]. most past term depend model have fail to show consist, signific improv over unigram baselin, with few except [8]. the mrf model, howev, ha been shown to be highli effect across a number of task, includ ad hoc retriev [14, 16], name-page find [16], and japanes languag web search [6]. until now, the model ha been sole us for rank  document in respons to a given queri. in thi work, we show how the model can be extend and us for queri  expans us a techniqu that we call latent concept expans (lce). there ar three primari contribut of our work. first, lce provid a mechan for combin term  depend with queri expans. previou queri expans techniqu ar base on bag of word model. therefor, by perform queri expans us the mrf model, we ar abl to studi the dynam between term depend and queri expans. next, as we will show, the mrf model allow arbitrari featur to be us within the model. queri expans  techniqu in the past have implicitli onli made us of term occurr featur. by us more robust featur set, it is possibl to produc better expans term that  discrimin between relev and non-relev document better. final, our propos approach seamlessli provid a  mechan for gener both singl and multi-term concept. most previou techniqu, by default, gener term  independ. there have been sever approach that make us of gener concept, howev such approach were somewhat heurist and done outsid of the model [19, 28]. our approach is both formal motiv and a natur  extens of the underli model. the remaind of thi paper is laid out as follow. in section 2 we describ relat queri expans approach. section 3 provid an overview of the mrf model and  detail our propos latent concept expans techniqu. in section 4 we evalu our propos model and analyz the result. final, section 5 conclud the paper and  summar the major result. 2. relat work on of the classic and most wide us approach to queri expans is the rocchio algorithm [21]. rocchio"s  approach, which wa develop within the vector space model, reweight the origin queri vector by move the weight toward the set of relev or pseudo-relev document and awai from the non-relev document. unfortun, it is not possibl to formal appli rocchio"s approach to a statist retriev model, such as languag model for inform retriev. a number of formal queri expans techniqu have been develop for the languag model framework,  includ zhai and lafferti"s model-base feedback and lavrenko and croft"s relev model [12, 29]. both approach  attempt to us pseudo-relev or relev document to  estim a better queri model. model-base feedback find the model that best describ the relev document while take a background (nois) model into consider. thi separ the content model from the background model. the content model is then interpol with the origin queri model to form the  expand queri. the other techniqu, relev model, is more close  relat to our work. therefor, we go into the detail of the model. much like model-base feedback, relev model estim an improv queri model. the onli differ  between the two approach is that relev model do not explicitli model the relev or pseudo-relev document. instead, thei model a more gener notion of relev, as we now show. given a queri q, a relev model is a multinomi  distribut, p(·|q), that encod the likelihood of each term given the queri as evid. it is comput as: p(w|q) = d p(w|d)p(d|q) ≈ d∈rq p(w|d)p(q|d)p(d) w d∈rq p(w|d)p(q|d)p(d) (1) where rq is the set of document that ar relev or  pseudorelev to queri q. in the pseudo-relev case, these ar the top rank document for queri q. furthermor, it is assum that p(d) is uniform over thi set. these mild assumpt make comput the bayesian posterior more practic. after the model is estim, document ar rank by clip the relev model by choos the k most like term from p(·|q). thi clip distribut is then  interpol with with the origin, maximum likelihood queri model [1]. thi can be thought of as expand the origin queri by k weight term. throughout the remaind of thi work, we refer to thi instanti of relev model as rm3. there ha been rel littl work done in the area of queri expans in the context of depend model [9]. howev, there have been sever attempt to expand us multi-term concept. xu and croft"s local context  analysi (lca) method combin passag-level retriev with concept expans, where concept were singl term and phrase [28]. expans concept were chosen and weight us a metric base on co-occurr statist. howev, it is not clear base on the analysi done how much the phrase help over the singl term alon. papka and allan investig us relev feedback to perform multi-term concept expans for document  rout [19]. the concept us in their work ar more gener than those us in lca, and includ inqueri queri  languag structur, such as #uw50(white hous), which  correspond to the concept the term white and hous occur, in ani order, within 50 term of each other. result show that combin singl term and larg window multi-term concept significantli improv effect. howev, it is unclear whether the same approach is also effect for ad hoc retriev, due to the differ in the task. 3. model thi section detail our propos latent concept expans techniqu. as mention previous, the techniqu is an extens of the mrf model for inform retriev [14]. therefor, we begin by provid an overview of the mrf model and our propos extens. 3.1 mrf for ir 3.1.1 basic markov random field, which ar undirect graphic  model, provid a compact, robust wai of model a joint  distribut. here, we ar interest in model the joint distribut over a queri q = q1, . . . , qn and a document d. it is assum the underli distribut over pair of document and queri is a relev distribut. that is, sampl from the distribut give pair of document and queri, such that the document is relev to the queri. a mrf is defin by a graph g and a set of non-neg potenti function over the cliqu in g. the node in the graph repres the random variabl and the edg defin the independ semant of the distribut. a mrf  satisfi the markov properti, which state that a node is  independ of all of it non-neighbor node given observ valu for it neighbor. given a graph g, a set of potenti ψi, and a paramet vector Λ, the joint distribut over q and d is given by: pg,Λ(q, d) = 1 zΛ c∈c(g) ψ(c; Λ) where z is a normal constant. we follow common convent and parameter the potenti as ψi(c; Λ) = exp[λifi(c)], where fi(c) is a real-valu featur function. 3.1.2 construct g given a queri q, the graph g can be construct in a number of wai. howev, follow previou work, we  consid three simpl variant [14]. these variant ar full  independ, where each queri term is independ of each other given a document, sequenti depend, which  assum a depend exist between adjac queri term, and full depend, which make no independ  assumpt. 3.1.3 parameter mrf ar commonli parameter base on the  maxim cliqu of g. howev, such a parameter is too coars for our need. we need a parameter that allow us to associ featur function with cliqu on a more fine grain level, while keep the number of featur, and thu the number of paramet, reason. therefor, we allow cliqu to share featur function and paramet base on cliqu set. that is, all of the cliqu within a cliqu set ar associ with the same featur function and share a  singl paramet. thi effect ti togeth the paramet of the featur associ with each set, which significantli reduc the number of paramet while still provid a mechan for fine-tune on the level of cliqu set. we propos seven cliqu set for us with inform  retriev. the first three cliqu set consist of cliqu that contain on or more queri term and the document node. featur over these cliqu should encod how well the term in the cliqu configur describ the document. these set ar: • td - set of cliqu contain the document node and exactli on queri term. • od - set of cliqu contain the document node and two or more queri term that appear in sequenti  order within the queri. • ud - set of cliqu contain the document node and two or more queri term that appear in ani order within the queri. note that ud is a superset of od. by ty the paramet among the cliqu within each set we can control how much influenc each type get. thi also avoid the problem of try to determin how to estim weight for each cliqu within the set. instead, we now must onli estim a singl paramet per set. next, we consid cliqu that onli contain queri term node. these cliqu, which were not consid in [14], ar defin in an analog wai to those just defin, except the the cliqu ar onli made up of queri term node and do not contain the document node. featur function over these cliqu should captur how compat queri term ar to on anoth. these cliqu featur mai take on the form of languag model that impos well-formed of the term. therefor, we defin follow queri-depend cliqu set: • tq - set of cliqu contain exactli on queri term. • oq - set of cliqu contain two or more queri term that appear in sequenti order within the queri. • uq - set of cliqu contain two or more queri term that appear in ani order within the queri. final, there is the cliqu that onli contain the  document node. featur over thi node can be us as a type of document prior, encod document-centric properti. thi trivial cliqu set is then: • d - cliqu set contain onli the singleton node d we note that our cliqu set form a set cover over the cliqu of g, but ar not a partit, sinc some cliqu appear in multipl cliqu set. after ty the paramet in our cliqu set togeth and us the exponenti potenti function form, we end up with the follow simplifi form of the joint distribut: log pg,Λ(q, d) = λtd c∈td ftd (c) + λod c∈od fod (c) + λud c∈ud fud (c) fdq(d,q) - document and queri depend + λtq c∈tq ftq (c) + λoq c∈oq foq (c) + λuq c∈uq fuq (c) fq(q) - queri depend + λdfd(d) fd(d) - document depend − log zΛ document + queri independ where fdq, fq, and fd ar conveni function defin by the document and queri depend, queri depend, and document depend compon of the joint  distribut, respect. these will be us to simplifi and clarifi express deriv throughout the remaind of the paper. 3.1.4 featur ani arbitrari featur function over cliqu configur can be us in the model. the correct choic of featur  depend larg on the retriev task and the evalu  metric. therefor, there is like not to be a singl, univers applic set of featur. to provid an idea of the rang of featur that can be us, we now briefli describ possibl type of featur that could be us. possibl queri term depend featur  includ tf, idf, name entiti, term proxim, and text style to name a few. mani type of document depend featur can be us, as well, includ document length, pagerank, readabl, and genr, among other. sinc it is not our goal here to find optim featur, we us a simpl, fix set of featur that have been shown to be effect in previou work [14]. see tabl 1 for a list of featur us. these featur attempt to captur term occurr and term proxim. better featur select in the futur will like lead to improv effect. 3.1.5 rank given a queri q, we wish to rank document in  descend order accord to pg,Λ(d|q). after drop document independ express from log pg,Λ(q, d), we deriv the follow rank function: pg,Λ(d|q) rank = fdq(d, q) + fd(d) (2) which is a simpl weight linear combin of featur function that can be comput effici for reason graph. 3.1.6 paramet estim now that the model ha been fulli specifi, the final step is to estim the model paramet. although mrf ar gener model, it is inappropri to train them us featur valu ftd (qi, d) log (1 − α) tfqi,d |d| + α cfqi |c| fod (qi, qi+1 . . . , qi+k, d) log (1 − β) tf#1(qi...qi+k),d |d| + β cf#1(qi...qi+k) |c| fud (qi, ..., qj, d) log (1 − β) tf#uw(qi...qj ),d |d| + β cf#uw(qi...qj ) |c| ftq (qi) − log cfqi |c| foq (qi, qi+1 . . . , qi+k) − log cf#1(qi...qi+k) |c| fuq (qi, ..., qj) − log cf#uw(qi...qj ) |c| fd 0 tabl 1: featur function us in markov random field model. here, tfw,d is the number of time term w occur in document d, tf#1(qi...qi+k),d denot the number of time the exact phrase qi . . . qi+k occur in document d, tf#uw(qi...qj ),d is the number of time the term qi, . . . qj appear order or unord within a window of n term, and |d| is the length of document d. the cf and |c| valu ar analog defin on the collect level. final, α and β ar model hyperparamet that control smooth for singl term and phrase featur, respect. convent likelihood-base approach becaus of metric diverg [17]. that is, the maximum likelihood estim is unlik to be the estim that maxim our evalu metric. for thi reason, we discrimin train our model to directli maxim the evalu metric under  consider [14, 15, 25]. sinc our paramet space is small, we make us of a simpl hill climb strategi, although other more sophist approach ar possibl [10]. 3.2 latent concept expans in thi section we describ how thi extend mrf model can be us in a novel wai to gener singl and  multiterm concept that ar topic relat to some origin queri. as we will show, the concept gener us our techniqu can be us for queri expans or other task, such as suggest altern queri formul. we assum that when a user formul their origin queri, thei have some set of concept in mind, but ar onli abl to express a small number of them in the form of a queri. we treat the concept that the user ha in mind, but did not explicitli express in the queri, as latent concept. these latent concept can consist of a singl term,  multipl term, or some combin of the two. it is, therefor, our goal to recov these latent concept given some origin queri. thi can be accomplish within our framework by first expand the origin graph g to includ the type of  concept we ar interest in gener. we call thi expand graph h. in figur 1, the middl graph provid an exampl of how to construct an expand graph that can gener singl term concept. similarli, the graph on the right  illustr an expand graph that gener two term concept. although these two exampl make us of the sequenti  depend assumpt (i.e. depend between adjac queri term), it is import to note that both the origin queri and the expans concept can us ani independ structur. after h is construct, we comput ph,Λ(e|q), a  probabl distribut over latent concept, accord to: ph,Λ(e|q) = d∈r ph,Λ(q, e, d) d∈r e ph,Λ(q, e, d) where r is the univers of all possibl document and e is some latent concept that mai consist of on or more term. sinc it is not practic to comput thi  summat, we must approxim it. we notic that ph,Λ(q, e, d) is like to be peak around those document d that ar highli rank accord to queri q. therefor, we  approxim ph,Λ(e|q) by onli sum over a small subset of relev or pseudo-relev document for queri q. thi is comput as follow: ph,Λ(e|q) ≈ d∈rq ph,Λ(q, e, d) d∈rq e ph,Λ(q, e, d) (3) ∝ d∈rq exp fqd(q, d) + fd(d) + fqd(e, d) + fq(e) where rq is a set of relev or pseudo-relev document for queri q and all cliqu set ar construct us h. as we see, the likelihood contribut for each document in rq is a combin of the origin queri"s score for the document (see equat 2), concept e"s score for the  document, and e"s document-independ score. therefor, thi equat can be interpret as measur how well q and e account for the top rank document and the good of e, independ of the document. for maximum  robust, we us a differ set of paramet for fqd(q, d) and fqd(e, d), which allow us to weight the term, order, and unord window featur differ for the origin queri and the candid expans concept. 3.2.1 queri expans to us thi framework for queri expans, we first choos an expans graph h that encod the latent concept  structur we ar interest in expand the queri us. we then select the k latent concept with the highest likelihood given by equat 3. a new graph g is construct by augment the origin graph g with the k expans  concept e1, . . . , ek. final, document ar rank accord to pg ,Λ(d|q, e1, . . . , ek) us equat 2. 3.2.2 comparison to relev model inspect equat 1 and 3 reveal the close  connect that exist between lce and relev model. both figur 1: graphic model represent of relev model (left), latent concept expans us singl term concept (middl), and latent concept expans us two term concept (right) for a three term queri. model essenti comput the likelihood of a term (or  concept) in the same manner. it is easi to see that just as the mrf model can be view as a gener of languag model, so too can lce be view as a gener of relev model. there ar import differ between mrf/lce and unigram languag model/relev model. see figur 1 for graphic model represent of both model.  unigram languag model and relev model ar base on the multinomi distribut. thi distribut  assumpt lock the model into the bag of word represent and the implicit us of term occurr featur. howev, the distribut underli the mrf model allow us to move beyond both of these assumpt, by model both depend between queri term and allow arbitrari featur to be explicitli us. move beyond the simplist bag of word assumpt in thi wai result in a gener, robust model and, as we show in the next section, translat into signific improv in retriev effect. 4. experiment result in order to better understand the strength and  weak of our techniqu, we evalu it on a wide rang of data set. tabl 2 provid a summari of the trec data set consid. the wsj, ap, and robust collect ar smaller and consist entir of newswir articl, wherea wt10g and gov2 ar larg web collect. for each data set, we split the avail topic into a train and test set, where the train set is us sole for paramet  estim and the test set is us for evalu purpos. all experi were carri out us a modifi version of indri, which is part of the lemur toolkit [18, 23]. all collect were stop us a standard list of 418  common term and stem us a porter stemmer. in all case, onli the titl portion of the trec topic ar us to construct queri. we construct g us the sequenti depend assumpt for all data set [14]. 4.1 ad-hoc retriev result we now investig how well our model perform in  practic in a pseudo-relev feedback set. we compar unigram languag model (with dirichlet smooth), the mrf model (without expans), relev model, and lce to better understand how each model perform across the variou data set. for the unigram languag model, the smooth  paramet wa train. for the mrf model, we train the model paramet (i.e. Λ) and model hyperparamet (i.e. α, β). for rm3 and lce, we also train the number of  pseudonam descript # doc train topic test topic wsj wall st. journal 87-92 173,252 51-150 151-200 ap assoc. press 88-90 242,918 51-150 151-200 robust robust 2004 data 528,155 301-450 601-700 wt10g trec web collect 1,692,096 451-500 501-550 gov2 2004 crawl of .gov domain 25,205,179 701-750 751-800 tabl 2: overview of trec collect and topic. relev feedback document us and the number of  expans term. 4.1.1 expans with singl term concept we begin by evalu how well our model perform when expand us onli singl term. befor we describ and analyz the result, we explicitli state how expans term likelihood ar comput under thi setup (i.e. us the sequenti depend assumpt, expand with singl term concept, and us our featur set). the expans term likelihood ar comput as follow: ph,Λ(e|q) ∝ d∈rq exp λtd w∈q log (1 − α) tfw,d |d| + α cfw |c| + λod b∈q log (1 − β) tf#1(b),d |d| + β cf#1(b) |c| + λud b∈q log (1 − β) tf#uw(b),d |d| + β cf#uw(b) |c| + log (1 − α) tfe,d |d| + α cfe |c| λtd cfe |c| λtq (4) where b ∈ q denot the set of bigram in q. thi equat clearli show how lce differ from relev model. when we set λtd = λt,d = 1 and all other paramet to 0, we obtain the exact formula that is us to comput term likelihood in the relev model framework. therefor, lce add two veri import factor to the equat. first, it add the order and unord window featur that ar appli to the origin queri. second, it appli an intuit tf.idf-like form to the candid expans term w. the idf factor, which is not present in relev model, plai an import role in expans term select. <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% rm3 lce 05101520 ap <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% rm3 lce 05101520253035 robust <= −100% (−100%, −75%] (−75%, −50%] (−50%, −25%] (−25%, 0%] (0%, 25%] (25%, 50%] (50%, 75%] (75%, 100%] > 100% rm3 lce 0510152025 wt10g figur 2: histogram that demonstr and compar the robust of relev model (rm3) and latent concept expans (lce) with respect to the queri likelihood model (ql) for the ap, robust, and wt10g data set. the result, evalu us mean averag precis, ar given in tabl 3. as we see, the mrf model, relev  model, and lce alwai significantli outperform the unigram languag model. in addit, lce show signific  improv over relev model across all data set. the rel improv over relev model is 6.9% for ap, 12.9% for wsj, 6.5% for robust, 16.7% for wt10g, and 7.3% for gov2. furthermor, lce show small, but not signific,  improv over relev model for metric such as  precis at 5, 10, and 20. howev, both relev model and lce show statist signific improv in such metric over the unigram languag model. anoth interest result is that the mrf model is  statist equival to relev model on the two web data set. in fact, the mrf model outperform relev  model on the wt10g data set. thi reiter the import of non-unigram, proxim-base featur for content-base web search observ previous [14, 16]. although our model ha more free paramet than  relev model, there is surprisingli littl overfit. instead, the model exhibit good gener properti. 4.1.2 expans with multi-term concept we also investig expand us both singl and two word concept. for each queri, we expand us a set of singl term concept and a set of two term concept. the set were chosen independ. unfortun, onli  neglig increas in mean averag precis were observ. thi result mai be due to the fact that strong  correl exist between the singl term expans concept. we found that the two word concept chosen often consist of two highli correl term that ar also chosen as singl term concept. for exampl, the two term concept stock market wa chosen while the singl term concept stock and market were also chosen. therefor, mani two word concept ar unlik to increas the discrimin power of the expand queri. thi result suggest that concept should be chosen accord to some criteria that also take novelti, divers, or term correl into account. anoth potenti issu is the featur set us. other featur set mai ultim yield differ result, especi if thei reduc the correl among the expans concept. therefor, our experi yield no conclus result with regard to expans us multi-term concept. instead, the result introduc interest open question and direct for futur explor. lm mrf rm3 lce wsj .3258 .3425α .3493α .3943αβγ ap .2077 .2147α .2518αβ .2692αβγ robust .2920 .3096α .3382αβ .3601αβγ wt10g .1861 .2053α .1944α .2269αβγ gov2 .3234 .3520α .3656α .3924αβγ tabl 3: test set mean averag precis for  languag model (lm), markov random field (mrf), relev model (rm3), and latent concept  expans (lce). the superscript α, β, and γ indic statist signific improv (p < 0.05) over lm, mrf, and rm3, respect. 4.2 robust as we have shown, relev model and latent concept expans can significantli improv retriev effect over the baselin queri likelihood model. in thi section we analyz the robust of these two method. here, we defin robust as the number queri whose effect ar improv/hurt (and by how much) as the result of  appli these method. a highli robust expans techniqu will significantli improv mani queri and onli minim hurt a few. figur 2 provid an analysi of the robust of  relev model and latent concept expans for the ap, robust, and wt10g data set. the analysi for the two data set not shown is similar. the histogram  provid, for variou rang of rel decreas/increas in mean averag precis, the number of queri that were hurt/improv with respect to the queri likelihood baselin. as the result show, lce exhibit strong robust for each data set. for ap, relev model improv 38 queri and hurt 11, wherea lce improv 35 and hurt 14.  although relev model improv the effect of 3 more queri than lce, the rel improv exhibit by lce is significantli larger. for the robust data set,  relev model improv 67 queri and hurt 32, and lce improv 77 and hurt 22. final, for the wt10g  collect, relev model improv 32 queri and hurt 16, and lce improv 35 and hurt 14. as with ap, the amount of improv exhibit by the lce versu relev model is significantli larger for both the robust and wt10g data set. in addit, when lce doe hurt perform, it is less like to hurt as much as relev model, which is a desir properti. 1 word concept 2 word concept 3 word concept telescop hubbl telescop hubbl space telescop hubbl space telescop hubbl telescop space space hubbl space space telescop hubbl mirror telescop mirror space telescop nasa nasa telescop hubbl hubbl telescop astronomi launch mirror telescop nasa hubbl space astronomi telescop nasa space telescop mirror shuttl telescop space telescop space nasa test hubbl mirror hubbl telescop mission new nasa hubbl mirror mirror mirror discoveri telescop astronomi space telescop launch time telescop optic space telescop discoveri univers hubbl optic shuttl space telescop optic telescop discoveri hubbl telescop flaw light telescop shuttl two hubbl space tabl 4: fifteen most like on, two, and three word concept construct us the top 25 document retriev for the queri hubbl telescop achiev on the robust collect. overal, lce improv effect for 65%-80% of queri, depend on the data set. when us in combin with a highli accur queri perform predict system, it mai be possibl to select expand queri and minim the loss associ with sub-baselin perform. 4.3 multi-term concept gener although we found that expans us multi-term  concept fail to produc conclus improv in  effect, there ar other potenti task that these concept mai be us for, such as queri suggest/reformul,  summar, and concept mine. for exampl, for a queri suggest task, the origin queri could be us to  gener a set of latent concept which correspond to altern queri formul. although evalu our model on these task is beyond the scope of thi work, we wish to show an illustr  exampl of the type of concept gener us our model. in tabl 4, we present the most like on, two, and three term concept gener us lce for the queri hubbl telescop achiev us the top 25 rank document from the robust collect. it is well known that gener multi-term concept  us a unigram-base model produc unsatisfactori result, sinc it fail to consid term depend. thi is not the case when gener multi-term concept us our model. instead, a major of the concept gener ar well-form and meaning. there ar sever case where the concept ar less coher, such as mirror mirror mirror. in thi case, the likelihood of the term mirror appear in a pseudo-relev document outweigh the languag  model featur (e.g. foq ), which caus thi non-coher concept to have a high likelihood. such exampl ar in the minor, howev. not onli ar the concept gener well-form and  meaning, but thei ar also topic relev to the origin queri. as we see, all of the concept gener ar on topic and in some wai relat to the hubbl telescop. it is  interest to see that the concept hubbl telescop flaw is on of the most like three term concept, given that it is  somewhat contradictori to the origin queri. despit thi  contradict, document that discuss the telescop flaw ar also like to describ the success, as well, and therefor thi is like to be a meaning concept. on import thing to note is that the concept lce gener ar of a differ natur than those that would be gener us a bigram relev model. for exampl, a bigram model would be unlik to gener the concept telescop space nasa, sinc none of the bigram that make up the concept have high likelihood. howev, sinc our model is base on a number of differ featur over variou type of cliqu, it is more gener and robust than a bigram model. although we onli provid the concept gener for a singl queri, we note that the same analysi and conclus gener across other data set, with coher, topic relat concept be consist gener us lce. 4.4 discuss our latent concept expans techniqu captur two  semiorthogon type of depend. in inform retriev, there ha been a long-term interest in understand the role of term depend. out of thi research, two broad type of depend have been identifi. the first type of depend is syntact depend. thi type of depend cover phrase, term proxim, and term co-occurr [2, 4, 5, 7, 26]. these method captur the fact that queri implicitli or explicitli impos a certain set of posit depend. the second type is semant depend. exampl of  semant depend ar relev feedback, pseudo-relev feedback, synonym, and to some extent stem [3]. these techniqu have been explor on both the queri and  document side. on the queri side, thi is typic done us some form of queri expans, such as relev model or lce. on the document side, thi is done as document  expans or document smooth [11, 13, 24]. although there mai be some overlap between syntact and semant depend, thei ar mostli orthogon. our model us both type of depend. the us of phrase and proxim featur within the model captur  syntact depend, wherea lce captur queri-side semant depend. thi explain why the initi improv in effect achiev by us the mrf model is not lost after queri expans. if the same type of depend were captur by both syntact and semant depend, lce would be expect to perform about equal as well as relev model. therefor, by model both type of depend we see an addit effect, rather than an  absorb effect. an interest area of futur work is to determin whether or not model document-side semant depend can add anyth to the model. previou result that have  combin queri- and document-side semant depend have shown mix result [13, 27]. 5. conclus in thi paper we propos a robust queri expans  techniqu call latent concept expans. the techniqu wa shown to be a natur extens of the markov random field model for inform retriev and a gener of  relev model. lce is novel in that it perform singl or multi-term expans within a framework that allow the model of term depend and the us of arbitrari  featur, wherea previou work ha been base on the bag of word assumpt and term occurr featur. we show that the techniqu can be us to produc high qualiti, well form, topic relev multi-term  expans concept. the concept gener can be us in an altern queri suggest modul. we also show that the model is highli effect. in fact, it achiev  signific improv in mean averag precis over relev model across a select of trec data set. it wa also shown the mrf model itself, without ani queri expans, outperform relev model on larg web data set. thi reconfirm previou observ that model  depend via the us of proxim featur within the mrf ha more of an impact on larger, noisier collect than smaller, well-behav on. final, we reiter the import of choos  expans term that model relev, rather than the relev document and show how lce captur both syntact and queri-side semant depend. futur work will look at incorpor document-side depend, as well. acknowledg thi work wa support in part by the center for intellig  inform retriev, in part by nsf grant #cn-0454018, in part by arda and nsf grant #ccf-0205575, and in part by microsoft live lab. ani opinion, find and conclus or  recommend express in thi materi ar those of the author(s) and do not necessarili reflect those of the sponsor. 6. refer [1] n. abdul-jaleel, j. allan, w. b. croft, f. diaz, l. larkei, x. li, m. d. smucker, and c. wade. umass at trec 2004: novelti and hard. in onlin proceed of the 2004 text retriev conf., 2004. [2] c. l. a. clark and g. v. cormack. shortest-substr retriev and rank. acm tran. inf. syst., 18(1):44-78, 2000. [3] k. collin-thompson and j. callan. queri expans us random walk model. in proc. 14th intl. conf. on inform and knowledg manag, page 704-711, 2005. [4] w. b. croft. boolean queri and term depend in probabilist retriev model. journal of the american societi for inform scienc, 37(4):71-77, 1986. [5] w. b. croft, h. turtl, and d. lewi. the us of phrase and structur queri in inform retriev. in proc. 14th ann. intl. acm sigir conf. on research and develop in inform retriev, page 32-45, 1991. [6] k. eguchi. ntcir-5 queri expans experi us term depend model. in proc. of the fifth ntcir workshop meet on evalu of inform access technolog, page 494-501, 2005. [7] j. fagan. automat phrase index for document retriev: an examin of syntact and non-syntact method. in proc. tenth ann. intl. acm sigir conf. on research and develop in inform retriev, page 91-101, 1987. [8] j. gao, j. nie, g. wu, and g. cao. depend languag model for inform retriev. in proc. 27th ann. intl. acm sigir conf. on research and develop in inform retriev, page 170-177, 2004. [9] d. harper and c. j. van rijsbergen. an evalu of feedback in document retriev us co-occurr data. journal of document, 34(3):189-216, 1978. [10] t. joachim. a support vector method for multivari perform measur. in proc. of the intern conf. on machin learn, page 377-384, 2005. [11] o. kurland and l. lee. corpu structur, languag model, and ad-hoc inform retriev. in proc. 27th ann. intl. acm sigir conf. on research and develop in inform retriev, page 194-201, 2004. [12] v. lavrenko and w. b. croft. relev-base languag model. in proc. 24th ann. intl. acm sigir conf. on research and develop in inform retriev, page 120-127, 2001. [13] x. liu and w. b. croft. cluster-base retriev us languag model. in proc. 27th ann. intl. acm sigir conf. on research and develop in inform retriev, page 186-193, 2004. [14] d. metzler and w. b. croft. a markov random field model for term depend. in proc. 28th ann. intl. acm sigir conf. on research and develop in inform retriev, page 472-479, 2005. [15] d. metzler and w. b. croft. linear featur base model for inform retriev. inform retriev, to appear, 2006. [16] d. metzler, t. strohman, y. zhou, and w. b. croft. indri at terabyt track 2005. in onlin proceed of the 2005 text retriev conf., 2005. [17] w. morgan, w. greiff, and j. henderson. direct maxim of averag precis by hill-climb with a comparison to a maximum entropi approach. technic report, mitr, 2004. [18] p. ogilvi and j. p. callan. experi us the lemur toolkit. in proc. of the text retriev conf., 2001. [19] r. papka and j. allan. why bigger window ar better than smaller on. technic report, univers of massachusett, amherst, 1997. [20] s. robertson, s. walker, s. jone, m. m. hancock-beaulieu, and m. gatford. okapi at trec-3. in onlin proceed of the third text retriev conf., page 109-126, 1995. [21] j. j. rocchio. relev feedback in inform retriev, page 313-323. prentic-hall, 1971. [22] f. song and w. b. croft. a gener languag model for inform retriev. in proc. eighth intern confer on inform and knowledg manag (cikm 99), page 316-321, 1999. [23] t. strohman, d. metzler, h. turtl, and w. b. croft. indri: a languag model-base serach engin for complex queri. in proc. of the intern conf. on intellig analysi, 2004. [24] t. tao, x. wang, q. mei, and c. zhai. languag model inform retriev with document expans. in proc. of hlt/naacl, page 407-414, 2006. [25] b. taskar, c. guestrin, and d. koller. max-margin markov network. in proc. of advanc in neural inform process system (nip 2003), 2003. [26] c. j. van rijsbergen. a theoret basi for the us of cooccurr data in inform retriev. journal of document, 33(2):106-119, 1977. [27] x. wei and w. b. croft. lda-base document model for ad-hoc retriev. in proc. 29th ann. intl. acm sigir conf. on research and develop in inform retriev, page 178-185, 2006. [28] j. xu and w. b. croft. improv the effect of inform retriev with local context analysi. acm tran. inf. syst., 18(1):79-112, 2000. [29] c. zhai and j. lafferti. model-base feedback in the languag model approach to inform retriev. in proc. 10th intl. conf. on inform and knowledg manag, page 403-410, 2001. 