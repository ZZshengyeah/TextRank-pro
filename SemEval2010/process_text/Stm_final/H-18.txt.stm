topic segment with share topic detect and align of multipl document bingjun sun*, prasenjit mitra*† , hongyuan zha‡ , c. lee gile*† , john yen*† *depart of comput scienc and engin † colleg of inform scienc and technolog the pennsylvania state univers univers park, pa 16802 ‡ colleg of comput the georgia institut of technolog atlanta, ga 30332 *bsun@cse.psu.edu, † {pmitra,gile,jyen}@ist.psu.edu, ‡ zha@cc.gatech.edu abstract topic detect and track [26] and topic segment [15] plai an import role in captur the local and  sequenti inform of document. previou work in thi area usual focus on singl document, although similar multipl document ar avail in mani domain. in thi paper, we introduc a novel unsupervis method for share topic detect and topic segment of multipl similar document base on mutual inform (mi) and weight mutual inform (wmi) that is a combin of mi and term weight. the basic idea is that the optim  segment maxim mi(or wmi). our approach can detect share topic among document. it can find the optim boundari in a document, and align segment among  document at the same time. it also can handl singl-document segment as a special case of the multi-document  segment and align. our method can identifi and strengthen cue term that can be us for segment and partial remov stop word by us term weight base on entropi learn from multipl document. our experiment result show that our algorithm work well for the task of singl-document segment, share topic detect, and multi-document segment. util inform from multipl document can tremend improv the  perform of topic segment, and us wmi is even better than us mi for the multi-document segment. categori and subject descriptor h.3.3 [inform storag and retriev]:  inform search and retriev-cluster; h.3.1 [inform storag and retriev]: content analysi and  indexinglinguist process; i.2.7 [artifici intellig]:  natur languag process-text analysi; i.5.3 [pattern recognit]: cluster-algorithm;similar measur gener term algorithm, design, experiment 1. introduct mani research have work on topic detect and  track (tdt) [26] and topic segment dure the past decad. topic segment intend to identifi the boundari in a document with the goal to captur the latent topic  structur. topic segment task usual fall into two  categori [15]: text stream segment where topic transit is identifi, and coher document segment in which document ar split into sub-topic. the former categori ha applic in automat speech recognit, while the latter on ha more applic such as partial-text queri of long document in inform retriev, text summari, and qualiti measur of multipl document. previou research in connect with tdt fall into the former  categori, target on topic track of broadcast speech data and newswir text, while the latter categori ha not been studi veri well. tradit approach perform topic segment on  document on at a time [15, 25, 6]. most of them perform badli in subtl task like coher document segment [15]. often, end-user seek document that have the  similar content. search engin, like, googl, provid link to obtain similar page. at a finer granular, user mai  actual be look to obtain section of a document similar to a particular section that presum discuss a topic of the user interest. thu, the extens of topic  segment from singl document to identifi similar segment from multipl similar document with the same topic is a natur and necessari direct, and multi-document topic segment is expect to have a better perform sinc more inform is util. tradit approach us similar measur base on term frequenc gener have the same assumpt that similar vocabulari tend to be in a coher topic segment [15, 25, 6]. howev, thei usual suffer the issu of  identifi stop word. for exampl, addit document-depend stop word ar remov togeth with the gener stop word in [15]. there ar two reason that we do not remov stop word directli. first, identifi stop word is anoth  issu [12] that requir estim in each domain. remov common stop word mai result in the loss of us  inform in a specif domain. second, even though stop word can be identifi, hard classif of stop word and  nonstop word cannot repres the gradual chang amount of inform content of each word. we emploi a soft  classif us term weight. in thi paper, we view the problem of topic segment as an optim issu us inform theoret  techniqu to find the optim boundari of a document given the number of text segment so as to minim the loss of mutual inform (mi) (or a weight mutual inform (wmi)) after segment and align. thi is equal to maxim the mi (or wmi). the mi focus on  measur the differ among segment wherea previou research focus on find the similar (e.g. cosin distanc) of segment [15, 25, 6]. topic align of multipl similar document can be achiev by cluster sentenc on the same topic into the same cluster. singl-document topic segment is just a special case of the multi-document topic segment and align problem. term can be co-cluster as in [10] at the same time, given the number of cluster, but our experiment result show that thi method result in a wors segment (see tabl 1, 4, and 6).  usual, human reader can identifi topic transit base on cue word, and can ignor stop word. inspir by thi, we give each term (or term cluster) a weight base on entropi among differ document and differ segment of  document. not onli can thi approach increas the contribut of cue word, but it can also decreas the effect of common stop word, noisi word, and document-depend stop word. these word ar common in a document. mani method base on sentenc similar requir that these word ar remov befor topic segment can be perform [15]. our result in figur 3 show that term weight ar us for multi-document topic segment and align. the major contribut of thi paper is that it introduc a novel method for topic segment us mi and show that thi method perform better than previous us  criteria. also, we have address the problem of topic  segment and align across multipl document, wherea most exist research focus on segment of singl document. multi-document segment and align can util inform from similar document and improv the perform of topic segment greatli. obvious, our approach can handl singl document as a special case when multipl document ar unavail. it can detect share topic among document to judg if thei ar multipl document on the same topic. we also introduc the new criterion of wmi base on term weight learn from  multipl similar document, which can improv perform of topic segment further. we propos an iter greedi algorithm base on dynam program and show that it work well in practic. some of our prior work is in [24]. the rest of thi paper is organ as follow: in section 2, we review relat work. section 3 contain a formul of the problem of topic segment and align of multipl document with term co-cluster, a review of the criterion of mi for cluster, and final an introduct to wmi. in section 4, we first propos the iter greedi algorithm of topic segment and align with term co-cluster, and then describ how the algorithm can be optim by  usfigur 1: illustr of multi-document  segment and align. ing dynam program. in section 5, experi about singl-document segment, share topic detect, and multi-document segment ar describ, and result ar present and discuss to evalu the perform of our algorithm. conclus and some futur direct of the research work ar discuss in section 6. 2. previou work gener, the exist approach to text segment fall into two categori: supervis learn [19, 17, 23] and unsupervis learn [3, 27, 5, 6, 15, 25, 21].  supervis learn usual ha good perform, sinc it learn function from label train set. howev, often  get larg train set with manual label on document sentenc is prohibit expens, so unsupervis  approach ar desir. some model consid depend  between sentenc and section, such as hidden markov model [3, 27], maximum entropi markov model [19], and  condit random field [17], while mani other approach ar base on lexic cohes or similar of sentenc [5, 6, 15, 25, 21]. some approach also focu on cue word as hint of topic transit [11]. while some exist method onli consid inform in singl document [6, 15], other  util multipl document [16, 14]. there ar not mani work in the latter categori, even though the perform of  segment is expect to be better with util of  inform from multipl document. previou research studi method to find share topic [16] and topic segment and summar between just a pair of document [14]. text classif and cluster is a relat research area which categor document into group us supervis or unsupervis method. topic classif or cluster is an import direct in thi area, especi co-cluster of document and term, such as lsa [9], plsa [13], and approach base on distanc and bipartit graph  partit [28] or maximum mi [2, 10], or maximum entropi [1, 18]. criteria of these approach can be util in the  issu of topic segment. some of those method have been extend into the area of topic segment, such as plsa [5] and maximum entropi [7], but to our best knowledg, us mi for topic segment ha not been studi. 3. problem formul our goal is to segment document and align the segment across document (figur 1). let t be the set of term {t1, t2, ..., tl}, which appear in the unlabel set of  document d = {d1, d2, ..., dm}. let sd be the set of sentenc for document d ∈ d, i.e.{s1, s2, ..., snd }. we have a 3d  matrix of term frequenc, in which the three dimens ar random variabl of d, sd, and t. sd actual is a random vector includ a random variabl for each d ∈ d. the term frequenc can be us to estim the joint probabl distribut p(d, sd, t), which is p(t, d, s) = t(t, d, s)/nd, where t(t, d, s) is the number of t in d"s sentenc s and nd is the total number of term in d. ˆs repres the set of segment {ˆs1, ˆs2, ..., ˆsp} after segment and align among multipl document, where the number of segment | ˆs| = p. a segment ˆsi of document d is a sequenc of  adjac sentenc in d. sinc for differ document si mai discuss differ sub-topic, our goal is to cluster adjac sentenc in each document into segment, and align similar segment among document, so that for differ document ˆsi is about the same sub-topic. the goal is to find the  optim topic segment and align map segd(si) : {s1, s2, ..., snd } → {ˆs1, ˆs2, ..., ˆsp} and alid(ˆsi) : {ˆs1, ˆs2, ..., ˆsp} → {ˆs1, ˆs2, ..., ˆsp}, for all d ∈ d, where ˆsi is ith segment with the constraint that onli adjac sentenc can be map to the same segment, i.e. for d, {si, si+1, ..., sj} → {ˆsq}, where q ∈ {1, ..., p}, where p is the segment number, and if i > j, then for d, ˆsq is miss. after segment and align, random vector sd becom an align random variabl ˆs. thu, p(d, sd, t) becom p(d, ˆs, t). term co-cluster is a techniqu that ha been emploi [10] to improv the accuraci of document cluster. we evalu the effect of it for topic segment. a term t is map to exactli on term cluster. term co-cluster involv simultan find the optim term cluster map clu(t) : {t1, t2, ..., tl} → {ˆt1, ˆt2, ..., ˆtk}, where k ≤ l, l is the total number of word in all the document, and k is the number of cluster. 4. methodolog we now describ a novel algorithm which can handl  singledocu segment, share topic detect, and  multidocu segment and align base on mi or wmi. 4.1 mutual inform mi i(x; y ) is a quantiti to measur the amount of  inform which is contain in two or more random variabl [8, 10]. for the case of two random variabl, we have i(x; y ) = x∈x y∈y p(x, y)log p(x, y) p(x)p(y) , (1) obvious, when random variabl x and y ar  independ, i(x; y ) = 0. thu, intuit, the valu of mi  depend on how random variabl ar depend on each other. the optim co-cluster is the map clux : x → ˆx and clui : y → ˆy that minim the loss: i(x; y ) − i( ˆx; ˆy ), which is equal to maxim i( ˆx; ˆy ). thi is the criterion of mi for cluster. in the case of topic segment, the two random  variabl ar the term variabl t and the segment variabl s, and each sampl is an occurr of a term t = t in a particular segment s = s. i(t; s) is us to measur how depend t and s ar. howev, i(t; s) cannot be  comput for document befor segment, sinc we do not have a set of s due to the fact that sentenc of document d, si ∈ sd, is not align with other document. thu, instead of minim the loss of mi, we can maxim mi after topic segment, comput as: i( ˆt; ˆs) = ˆt∈ ˆt ˆs∈ ˆs p(ˆt, ˆs)log p(ˆt, ˆs) p(ˆt)p(ˆs) , (2) where p(ˆt, ˆs) ar estim by the term frequenc tf of term cluster ˆt and segment ˆs in the train set d. note that here a segment ˆs includ sentenc about the the same topic among all document. the optim solut is the map clut : t → ˆt, segd : sd → ˆs , and alid : ˆs → ˆs, which maxim i( ˆt; ˆs). 4.2 weight mutual inform in topic segment and align of multipl  document, if p(d, ˆs, t) is known, base on the margin  distribut p(d|t) and p( ˆs|t) for each term t ∈ t, we can categor term into four type in the data set: • common stop word ar common both along the  dimens of document and segment. • document-depend stop word that depend on the person write style ar common onli along the  dimens of segment for some document. • cue word ar the most import element for  segment. thei ar common along the dimens of document onli for the same segment, and thei ar not common along the dimens of segment. • noisi word ar other word which ar not common along both dimens. entropi base on p(d|t) and p( ˆs|t) can be us to  identifi differ type of term. to reinforc the contribut of cue word in the mi comput, and simultan  reduc the effect of the other three type of word, similar as the idea of the tf-idf weight [22], we us entropi of each term along the dimens of document d and segment ˆs, i.e. ed(ˆt) and eˆs(ˆt), to comput the weight. a cue word usual ha a larg valu of ed(ˆt) but a small valu of eˆs(ˆt). we introduc term weight (or term cluster weight) wˆt = ( ed(ˆt) maxˆt ∈ ˆt (ed(ˆt )) )a (1 − eˆs(ˆt) maxˆt ∈ ˆt (eˆs(ˆt )) )b , (3) where ed(ˆt) = d∈d p(d|ˆt)log|d| 1 p(d|ˆt) , eˆs(ˆt) = ˆs∈ ˆs p(ˆs|ˆt)log| ˆs| 1 p(ˆs|ˆt) , and a > 0 and b > 0 ar power to adjust term weight. usual a = 1 and b = 1 as default, and maxˆt ∈ ˆt (ed(ˆt )) and maxˆt ∈ ˆt (eˆs(ˆt )) ar us to normal the entropi valu. term cluster weight ar us to adjust p(ˆt, ˆs), pw(ˆt, ˆs) = wˆtp(ˆt, ˆs) ˆt∈ ˆt ;ˆs∈ ˆs wˆtp(ˆt, ˆs) , (4) and iw( ˆt; ˆs) = ˆt∈ ˆt ˆs∈ ˆs pw(ˆt, ˆs)log pw(ˆt, ˆs) pw(ˆt)pw(ˆs) , (5) where pw(ˆt) and pw(ˆs) ar margin distribut of pw(ˆt, ˆs). howev, sinc we do not know either the term weight or p(d, ˆs, t), we need to estim them, but wˆt depend on p(ˆs|t) and ˆs, while ˆs and p(ˆs|t) also depend on wˆt that is still unknown. thu, an iter algorithm is requir to estim term weight wˆt and find the best  segment and align to optim the object function iw concurr. after a document is segment into sentenc input: joint probabl distribut p(d, sd, t), number of text segment p ∈ {2, 3, ..., max(sd)}, number of term cluster k ∈ {2, 3, ..., l} (if k = l, no term co-cluster requir), and weight type w ∈ {0, 1}, indic to us i or iw, respect. output: map clu, seg, ali, and term weight wˆt. initi: 0. i = 0. initi clu (0) t , seg (0) d , and ali (0) d ; initi w (0) ˆt us equat (6) if w = 1; stage 1: 1. if |d| = 1, k = l, and w = 0, check all sequenti  segment of d into p segment and find the best on segd(s) = argmaxˆsi( ˆt; ˆs), and return segd; otherwis, if w = 1 and k = l, go to 3.1; stage 2: 2.1 if k < l, for each term t, find the best cluster ˆt as clu(i+1)(t) = argmaxˆti( ˆt; ˆs(i)) base on seg(i) and ali(i); 2.2 for each d, check all sequenti segment of d into p segment with map s → ˆs → ˆs, and find the best on ali (i+1) d (seg (i+1) d (s)) = argmaxˆsi( ˆt(i+1); ˆs) base on clu(i+1)(t) if k < l or clu(0)(t) if k = l; 2.3 i + +. if clu, seg, or ali chang, go to 2.1; otherwis, if w = 0, return clu(i), seg(i), and ali(i); els j = 0, go to 3.1; stage 3: 3.1 updat w (i+j+1) ˆt base on seg(i+j), ali(i+j), and clu(i) us equat (3); 3.2 for each d, check all sequenti segment of d into p segment with map s → ˆs → ˆs, and find the best on ali (i+j+1) d (seg (i+j+1) d (s)) = argmaxˆsiw( ˆt(i); ˆs) base on clu(i) and w (i+j+1) ˆt ; 3.3 j + +. if iw( ˆt; ˆs) chang, go to step 6; otherwis, stop and return clu(i), seg(i+j), ali(i+j), and w (i+j) ˆt ; figur 2: algorithm: topic segment and  align base on mi or wmi. and each sentenc is segment into word, each word is stem. then the joint probabl distribut p(d, sd, t) can be estim. final, thi distribut can be us to comput mi in our algorithm. 4.3 iter greedi algorithm our goal is to maxim the object function, i( ˆt; ˆs) or iw( ˆt; ˆs), which can measur the depend of term  occurr in differ segment. gener, first we do not know the estim term weight, which depend on the optim topic segment and align, and term cluster.  moreov, thi problem is np-hard [10], even though if we know the term weight. thu, an iter greedi algorithm is  desir to find the best solut, even though probabl onli local maxima ar reach. we present the iter greedi algorithm in figur 2 to find a local maximum of i( ˆt; ˆs) or iw( ˆt; ˆs) with simultan term weight estim. thi algorithm can is iter and greedi for multi-document case or singl-document case with term weight estim and/or term co-cluster. otherwis, sinc it is just a on step algorithm to solv the task of singl-document  segment [6, 15, 25], the global maximum of mi is guarante. we will show later that term co-cluster reduc the  accuraci of the result and is not necessari, and for  singledocu segment, term weight ar also not requir. 4.3.1 initi in step 0, the initi term cluster clut and topic  segment and align segd and alid ar import to avoid local maxima and reduc the number of iter. first, a good guess of term weight can be made by us the distribut of term frequenc along sentenc for each document and averag them to get the initi valu of wˆt: wt = ( ed(t) maxt ∈t (ed(t )) )(1 − es(t) maxt ∈t (es(t )) ), (6) where es(t) = 1 |dt| d∈dt (1 − s∈sd p(s|t)log|sd| 1 p(s|t) ), where dt is the set of document which contain term t. then, for the initi segment seg(0) , we can simpli segment document equal by sentenc. or we can find the optim segment just for each document d which maxim the wmi, seg (0) d = argmaxˆsiw(t; ˆs), where w = w (0) ˆt . for the initi align ali(0) , we can first assum that the order of segment for each d is the same. for the initi term cluster clu(0) , first cluster label can be set randomli, and after the first time of step 3, a good initi term cluster is obtain. 4.3.2 differ case after initi, there ar three stage for differ case. total there ar eight case, |d| = 1 or |d| > 1, k = l or k < l, w = 0 or w = 1. singl document  segment without term cluster and term weight estim (|d| = 1, k = l, w = 0) onli requir stage 1 (step 1). if term cluster is requir (k < l), stage 2 (step 2.1, 2.2, and 2.3) is execut iter. if term weight estim is requir (w = 1), stage 3 (step 3.1, 3.2, and 3.3) is  execut iter. if both ar requir (k < l, w = 1), stage 2 and 3 run on after the other. for multi-document  segment without term cluster and term weight estim (|d| > 1, k = l, w = 0), onli iter of step 2.2 and 2.3 ar requir. at stage 1, the global maximum can be found base on i( ˆt; ˆs) us dynam program in section 4.4.  simultan find a good term cluster and estim term weight is imposs, sinc when move a term to a new term cluster to maxim iw( ˆt; ˆs), we do not know that the weight of thi term should be the on of the new cluster or the old cluster. thu, we first do term cluster at stage 2, and then estim term weight at stage 3. at stage 2, step 2.1 is to find the best term cluster and step 2.2 is to find the best segment. thi cycl is repeat to find a local maximum base on mi i until it  converg. the two step ar: (1) base on current term  cluster cluˆt, for each document d, the algorithm segment all the sentenc sd into p segment sequenti (some  segment mai be empti), and put them into the p segment ˆs of the whole train set d (all possibl case of differ segment segd and align alid ar check) to find the optim case, and (2) base on the current segment and align, for each term t, the algorithm find the best term cluster of t base on the current segment segd and align alid. after find a good term cluster, term weight ar estim if w = 1. at stage 3, similar as stage 2, step 3.1 is term weight re-estim and step 3.2 is to find a better segment. thei ar repeat to find a local maximum base on wmi iw until it converg. howev, if the term cluster in stage 2 is not accur, then the term weight estim at stage 3 mai have a bad result. final, at step 3.3, thi  algorithm converg and return the output. thi algorithm can handl both singl-document and multi-document  segment. it also can detect share topic among document by check the proport of overlap sentenc on the same topic, as describ in sec 5.2. 4.4 algorithm optim in mani previou work on segment, dynam  program is a techniqu us to maxim the object function. similarli, at step 1, 2.2, and 3.2 of our algorithm, we can us dynam program. for stage 1, us  dynam program can still find the global optimum, but for stage 2 and stage 3, we can onli find the optimum for each step of topic segment and align of a  document. here we onli show the dynam program for step 3.2 us wmi (step 1 and 2.2 ar similar but thei can us either i or iw). there ar two case that ar not shown in the algorithm in figur 2: (a) singl-document  segment or multi-document segment with the same  sequenti order of segment, where align is not requir, and (b) multi-document segment with differ  sequenti order of segment, where align is necessari. the align map function of the former case is simpli just alid(ˆsi) = ˆsi, while for the latter on"s align map function alid(ˆsi) = ˆsj, i and j mai be differ. the  comput step for the two case ar list below: case 1 (no align): for each document d: (1) comput pw(ˆt), partial pw(ˆt, ˆs) and partial pw(ˆs)  without count sentenc from d. then put sentenc from i to j into part k, and comput partial wmi piw( ˆt; ˆsk(si, si+1, ..., sj)) ˆt∈ ˆt pw(ˆt, ˆsk)log pw(ˆt, ˆsk) pw(ˆt)pw(ˆsk) , where alid(si, si+1, ..., sj) = k, k ∈ {1, 2, ..., p}, 1 ≤ i ≤ j ≤ nd, and segd(sq) = ˆsk for all i ≤ q ≤ j. (2) let m(sm, 1) = piw( ˆt; ˆs1(s1, s2, ..., sm)). then m(sm, l) = maxi[m(si−1, l − 1) + piw( ˆt; ˆsl(si, ..., sm))], where 0 ≤ m ≤ nd, 1 < l < p, 1 ≤ i ≤ m + 1, and when i > m, no sentenc ar put into ˆsk when comput piw (note piw( ˆt; ˆs(si, ..., sm)) = 0 for singl-document  segment). (3) final m(snd , p) = maxi[m(si−1, p − 1)+ piw( ˆt; ˆsp(si, ..., snd ))], where 1 ≤ i ≤ nd+1. the optim iw is found and the correspond segment is the best. case 2 (align requir): for each document d: (1) comput pw(ˆt), partial pw(ˆt, ˆs), and partial pw(ˆs), and piw( ˆt; ˆsk(si, si+1, ..., sj)) similarli as case 1. (2) let m(sm, 1, k) = piw( ˆt; ˆsk(s1, s2, ..., sm)), where k ∈ {1, 2, ..., p}. then m(sm, l, kl) = maxi,j[m(si−1, l − 1, kl/j) + piw( ˆt; ˆsalid(ˆsl )=j(si, si+1, ..., sm))], where 0 ≤ m ≤ nd, 1 < l < p, 1 ≤ i ≤ m + 1, kl ∈ set(p, l), which is the set of all p! l!(p−l)! combin of l segment chosen from all p segment, j ∈ kl, the set of l segment chosen from all p segment, and kl/j is the combin of l − 1 segment in kl except segment j. (3) final, m(snd , p, kp) = maxi,j[m(si−1, p − 1, kp/j) +piw( ˆt; ˆsalid(ˆsl )=j(si, si+1, ..., snd ))], where kp is just the combin of all p segment and 1 ≤ i ≤ nd + 1, which is the optim iw and the correspond segment is the best. the step of case 1 and 2 ar similar, except in case 2, align is consid in addit to segment. first, basic item of probabl for comput iw ar comput exclud doc d, and then partial wmi by put everi possibl sequenti segment (includ empti segment) of d into everi segment of the set. second, the optim sum of piw for l segment and the leftmost m sentenc, m(sm, l), is found. final, the maxim wmi is found among  differ sum of m(sm, p − 1) and piw for segment p. 5. experi in thi section, singl-document segment, share topic detect, and multi-document segment will be test. differ hyper paramet of our method ar studi. for conveni, we refer to the method us i as mik if w = 0, and iw as wmik if w = 2 or as wmik if w = 1, where k is the number of term cluster, and if k = l, where l is the total number of term, then no term cluster is requir, i.e. mil and wmil. 5.1 singl-document segment 5.1.1 test data and evalu the first data set we test is a synthet on us in previou research [6, 15, 25] and mani other paper. it ha 700 sampl. each is a concaten of ten segment. each segment is the first n sentenc select randomli from the brown corpu, which is suppos to have a differ topic from each other. current, the best result on thi data set is achiev by ji et.al. [15]. to compar the  perform of our method, the criterion us wide in previou research is appli, instead of the unbias criterion  introduc in [20]. it choos a pair of word randomli. if thei ar in differ segment (differ) for the real  segment (real), but predict (pred) as in the same segment, it is a miss. if thei ar in the same segment (same), but predict as in differ segment, it is a fals alarm. thu, the error rate is comput us the follow equat: p(err|real, pred) = p(miss|real, pred, diff)p(diff|real) +p(fals alarm|real, pred, same)p(same|real). 5.1.2 experi result we test the case when the number of segment is known. tabl 1 show the result of our method with differ hyper paramet valu and three previou approach, c99[25], u00[6], and addp03[15], on thi data set when the  segment number is known. in wmi for singl-document  segment, the term weight ar comput as follow: wˆt = 1−eˆs(ˆt)/maxˆt ∈ ˆt (eˆs(ˆt )). for thi case, our method mil and wmil both outperform all the previou approach. we compar our method with addp03us on-sampl on-side t-test and p-valu ar shown in tabl 2. from the p-valu, we can see that mostli the differ ar veri tabl 1: averag error rate of singl-document segment given segment number known rang of n 3-11 3-5 6-8 9-11 sampl size 400 100 100 100 c99 12% 11% 10% 9% u00 10% 9% 7% 5% addp03 6.0% 6.8% 5.2% 4.3% mil 4.68% 5.57% 2.59% 1.59% wmil 4.94% 6.33% 2.76% 1.62% mi100 9.62% 12.92% 8.66% 6.67% tabl 2: singl-document segment: p-valu of t-test on error rate rang of n 3-11 3-5 6-8 9-11 addp03, mil 0.000 0.000 0.000 0.000 addp03, wmil 0.000 0.099 0.000 0.000 mil, wmil 0.061 0.132 0.526 0.898 signific. we also compar the error rate between our two method us two-sampl two-side t-test to check the hypothesi that thei ar equal. we cannot reject the  hypothesi that thei ar equal, so the differ ar not  signific, even though all the error rate for mil ar smaller than wmil. howev, we can conclud that term weight contribut littl in singl-document segment. the  result also show that mi us term co-cluster (k = 100) decreas the perform. we test differ number of term cluster, and found that the perform becom  better when the cluster number increas to reach l. wmik<l ha similar result that we did not show in the tabl. as mention befor, us mi mai be inconsist on  optim boundari given differ number of segment. thi situat occur especi when the similar among  segment ar quit differ, i.e. some transit ar veri obviou, while other ar not. thi is becaus usual a document is a hierarch structur instead of onli a  sequenti structur. when the segment ar not at the same level, thi situat mai occur. thu, a hierarch topic segment approach is desir, and the structur highli depend on the number of segment for each intern node and the stop criteria of split. for thi data set of  singledocu segment, sinc it is just a synthet set, which is just a concaten of sever segment about differ topic, it is reason that approach simpli base on term frequenc have a good perform. usual for the task of segment coher document for sub-topic, the  effect decreas much. 5.2 share topic detect 5.2.1 test data and evalu the second data set contain 80 new articl from googl new. there ar eight topic and each ha 10 articl. we randomli split the set into subset with differ document number and each subset ha all eight topic. we  compar our approach mil and wmil with lda [4]. lda treat a document in the data set as a bag of word, find it distribut on topic, and it major topic. mil and wmil view each sentenc as a bag of word and tag it with a topic label. then for each pair of document, lda determin if thei ar on the same topic, while mil and tabl 3: share topic detect: averag error rate for differ number of document in each subset #doc 10 20 40 80 lda 8.89% 16.33% 1.35% 0.60% mil, θ = 0.6 4.17% 1.71% 1.47% 0.0% wmil, θ = 0.8 18.6% 3.16% 1.92% 0.0% wmil check whether the proport overlap sentenc on the same topic is larger than the adjust threshold θ. that is, in mil and wmil, for a pair of document d, d , if [ s∈sd,s ∈sd 1(topic=topic )/min(|sd|, |sd|)] > θ, where sd is the set of sentenc of d, and |sd| is the number of sentenc of d, then d and d have the share topic. for a pair of document select randomli, the error rate is comput us the follow equat: p(err|real, pred) = p(miss|real, pred, same)p(same|real) +p(fals alarm|real, pred, diff)p(diff|real), where a miss mean if thei have the same topic (same) for the real case (real), but predict (pred) as on the same topic. if thei ar on differ topic (diff), but predict as on the same topic, it is a fals alarm. 5.2.2 experi result the result ar shown in tabl 3. if most document have differ topic, in wmil, the estim of term weight in equat (3) is not correct. thu, wmil is not expect to have a better perform than mil, when most document have differ topic. when there ar fewer document in a subset with the same number of topic, more document have differ topic, so wmil is more wors than mil. we can see that for most case mil ha a better (or at least similar) perform than lda. after share topic  detect, multi-document segment of document with the share topic is abl to be execut. 5.3 multi-document segment 5.3.1 test data and evalu for multi-document segment and align, our goal is to identifi these segment about the same topic among multipl similar document with share topic. us iw is expect to perform better than i, sinc without term weight the result is affect serious by document-depend stop word and noisi word which depend on the person write style. it is more like to treat the same segment of differ document as differ segment under the effect of document-depend stop word and noisi word. term weight can reduc the effect of document-depend stop word and noisi word by give cue term more weight. the data set for multi-document segment and  align ha 102 sampl and 2264 sentenc total. each is the introduct part of a lab report select from the cours of biol 240w, pennsylvania state univers. each sampl ha two segment, introduct of plant hormon and the content in the lab. the length rang of sampl is from two to 56 sentenc. some sampl onli have on part and some have a revers order the these two segment. it is not hard to identifi the boundari between two segment for  human. we label each sentenc manual for evalu. the criterion of evalu is just us the proport of the number of sentenc with wrong predict segment  label in the total number of sentenc in the whole train tabl 4: averag error rate of multi-document segment given segment number known #doc mil wmil k mik wmik 102 3.14% 2.78% 300 4.68% 6.58% 51 4.17% 3.63% 300 17.83% 22.84% 34 5.06% 4.12% 300 18.75% 20.95% 20 7.08% 5.42% 250 20.40% 21.83% 10 10.38% 7.89% 250 21.42% 21.91% 5 15.77% 11.64% 250 21.89% 22.59% 2 25.90% 23.18% 50 25.44% 25.49% 1 23.90% 24.82% 25 25.75% 26.15% tabl 5: multi-document segment: p-valu of t-test on error rate for mil and wmil #doc 51 34 20 10 5 2 p-valu 0.19 0.101 0.025 0.001 0.000 0.002 set as the error rate: p(error|predict, real) = d∈d s∈sd 1(predict=real)/ d∈d nd. in order to show the benefit of multi-document  segment and align, we compar our method with differ paramet on differ partit of the same train set. except the case that the number of document is 102 and on (thei ar special case of us the whole set and the pure singl-document segment), we randomli divid the train set into m partit, and each ha 51, 34, 20, 10, 5, and 2 document sampl. then we appli our  method on each partit and calcul the error rate of the whole train set. each case wa repeat for 10 time for comput the averag error rate. for differ partit of the train set, differ k valu ar us, sinc the  number of term increas when the document number in each partit increas. 5.3.2 experi result from the experi result in tabl 4, we can see the follow observ: (1) when the number of document increas, all method have better perform. onli from on to two document, mil ha decreas a littl. we can observ thi from figur 3 at the point of document  number = 2. most curv even have the worst result at thi point. there ar two reason. first, becaus sampl vote for the best multi-document segment and align, but if onli two document ar compar with each other, the on with miss segment or a total differ sequenc will affect the correct segment and align of the other. second, as note at the begin of thi section, if two  document have more document-depend stop word or noisi word than cue word, then the algorithm mai view them as two differ segment and the other segment is miss. gener, we can onli expect a better perform when the number of document is larger than the number of  segment. (2) except singl-document segment, wmil is alwai better than mil, and when the number of document is reach on or increas to a veri larg number, their perform becom closer. tabl 5 show p-valu of  twosampl on-side t-test between mil and wmil. we also can see thi trend from p-valu. when document number = 5, we reach the smallest p-valu and the largest differ between error rate of mil and wmil. for singl-document tabl 6: multi-document segment: averag error rate for document number = 5 in each  subset with differ number of term cluster #cluster 75 100 150 250 l mik 24.67% 24.54% 23.91% 22.59% 15.77% segment, wmil is even a littl bit wors than mil, which is similar as the result of the singl-document  segment on the first data set. the reason is that for  singledocu segment, we cannot estim term weight accur, sinc multipl document ar unavail. (3) us term cluster usual get wors result than mil and wmil.(4) us term cluster in wmik is even wors than in mik, sinc in wmik term cluster ar found first us i befor us iw. if the term cluster ar not correct, then the term weight ar estim wors, which mai  mislead the algorithm to reach even wors result. from the result we also found that in multi-document segment and align, most document with miss segment and a revers order ar identifi correctli. tabl 6 illustr the experi result for the case of 20 partit (each ha five document sampl) of the train set and topic segment and align us mik with differ number of term cluster k. notic that when the number of term cluster increas, the error rate becom smaller. without term cluster, we have the best result. we did not show result for wmik with term cluster, but the result ar similar. we also test wmil with differ hyper paramet of a and b to adjust term weight. the result ar  present in figur 3. it wa shown that the default case wmil : a = 1, b = 1 gave the best result for differ  partit of the train set. we can see the trend that when the document number is veri small or larg, the differ between mil : a = 0, b = 0 and wmil : a = 1, b = 1  becom quit small. when the document number is not larg (about from 2 to 10), all the case us term weight have better perform than mil : a = 0, b = 0 without term weight, but when the document number becom larger, the case wmil : a = 1, b = 0 and wmil : a = 2, b = 1 becom wors than mil : a = 0, b = 0. when the document number becom veri larg, thei ar even wors than case with small document number. thi mean that a proper wai to estim term weight for the criterion of wmi is veri import. figur 4 show the term weight learn from the whole train set. four type of word ar  categor roughli even though the transit among them ar subtl. figur 5 illustr the chang in (weight) mutual inform for mil and wmil. as expect, mutual  inform for mil increas monoton with the number of step, while wmil doe not. final, mil and wmil ar scalabl, with comput complex shown in figur 6. on advantag for our approach base on mi is that  remov stop word is not requir. anoth import  advantag is that there ar no necessari hyper paramet to adjust. in singl-document segment, the perform base on mi is even better for that base on wmi, so no extra hyper paramet is requir. in multi-document  segment, we show in the experi, a = 1 and b = 1 is the best. our method give more weight to cue term. howev, usual cue term or sentenc appear at the  begin of a segment, while the end of the segment mai be 1 2 5 10 20 34 51 102 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 document number errorr mil :a=0,b=0 wmi l :a=1,b=1 wmi l :a=1,b=0 wmi l :a=2,b=1 figur 3: error rate for differ hyper  paramet of term weight. 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 normal document entropi normalizedsegmententropi noisi word cue word common stop word doc−dep stop word figur 4: term weight learn from the whole train set. 0 100 200 300 400 500 600 0.06 0.08 0.1 0.12 0.14 0.16 0.18 number of step (weight)mutualinform mi l wmi l figur 5: chang in (weight) mi for mil and wmil. 0 20 40 60 80 100 120 0 200 400 600 800 1000 1200 1400 1600 1800 2000 document number timetoconverg(sec) mi l wmi l figur 6: time to converg for mil and wmil. much noisi. on possibl solut is give more weight to term at the begin of each segment. moreov, when the length of segment ar quit differ, long segment have much higher term frequenc, so thei mai domin the segment boundari. normal of term  frequenc versu the segment length mai be us. 6. conclus and futur work we propos a novel method for multi-document topic segment and align base on weight mutual  inform, which can also handl singl-document case. we us dynam program to optim our algorithm. our approach outperform all the previou method on  singledocu case. moreov, we also show that do  segment among multipl document can improv the  perform tremend. our result also illustr that  us weight mutual inform can util the inform of multipl document to reach a better perform. we onli test our method on limit data set. more data set especi complic on should be test. more previou method should be compar with. moreov,  natur segment like paragraph ar hint that can be us to find the optim boundari. supervis learn also can be consid. 7. acknowledg the author want to thank xiang ji, and prof. j. scott payn for their help. 8. refer [1] a. banerje, i. ghillon, j. ghosh, s. merugu, and d. modha. a gener maximum entropi approach to bregman co-cluster and matrix approxim. in proceed of sigkdd, 2004. [2] r. bekkerman, r. el-yaniv, and a. mccallum. multi-wai distribut cluster via pairwis interact. in proceed of icml, 2005. [3] d. m. blei and p. j. moreno. topic segment with an aspect hidden markov model. in proceed of sigir, 2001. [4] d. m. blei, a. ng, and m. jordan. latent dirichlet alloc. journal of machin learn research, 3:993-1022, 2003. [5] t. brant, f. chen, and i. tsochantaridi. topic-base document segment with probabilist latent semant analysi. in proceed of cikm, 2002. [6] f. choi. advanc in domain indeped linear text segment. in proceed of the naacl, 2000. [7] h. christensen, b. kolluru, y. gotoh, and s. renal. maximum entropi segment of broadcast new. in proceed of icassp, 2005. [8] t. cover and j. thoma. element of inform theori. john wilei and son, new york, usa, 1991. [9] s. deerwest, s. dumai, g. furna, t. landauer, and r. harshman. index by latent semant analysi. journal of the american societi for inform system, 1990. [10] i. dhillon, s. mallela, and d. modha. inform-theoret co-cluster. in proceed of sigkdd, 2003. [11] m. hajim, h. takeo, and o. manabu. text segment with multipl surfac linguist cue. in proceed of cole-acl, 1998. [12] t. k. ho. stop word locat and identif for adapt text recognit. intern journal of document analysi and recognit, 3(1), august 2000. [13] t. hofmann. probabilist latent semant analysi. in proceed of the uai"99, 1999. [14] x. ji and h. zha. correl summar of a pair of multilingu document. in proceed of ride, 2003. [15] x. ji and h. zha. domain-independ text segment us anisotrop diffus and dynam program. in proceed of sigir, 2003. [16] x. ji and h. zha. extract share topic of multipl document. in proceed of the 7th pakdd, 2003. [17] j. lafferti, a. mccallum, and f. pereira. condit random field: probabilist model for segment and label sequenc data. in proceed of icml, 2001. [18] t. li, s. ma, and m. ogihara. entropi-base criterion in categor cluster. in proceed of icml, 2004. [19] a. mccallum, d. freitag, and f. pereira. maximum entropi markov model for inform extract and segment. in proceed of icml, 2000. [20] l. pevzner and m. hearst. a critiqu and improv of an evalu metric for text segment. comput linguist, 28(1):19-36, 2002. [21] j. c. reynar. statist model for topic segment. in proceed of acl, 1999. [22] g. salton and m. mcgill. introduct to modern inform retriev. mcgraw hill, 1983. [23] b. sun, q. tan, p. mitra, and c. l. gile. extract and search of chemic formula in text document on the web. in proceed of www, 2007. [24] b. sun, d. zhou, h. zha, and j. yen. multi-task text segment and align base on weight mutual inform. in proceed of cikm, 2006. [25] m. utiyama and h. isahara. a statist model for domain-independ text segment. in proceed of the 39th acl, 1999. [26] c. wayn. multilingu topic detect and track: success research enabl by corpora and evalu. in proceed of lrec, 2000. [27] j. yamron, i. carp, l. gillick, s. low, and p. van mulbregt. a hidden markov model approach to text segment and event track. in proceed of icassp, 1998. [28] h. zha and x. ji. correl multilingu document via bipartit graph model. in proceed of sigir, 2002. 