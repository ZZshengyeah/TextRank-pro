interest nugget and their impact on definit question answer kian-wei kor depart of comput scienc school of comput nation univers of singapor dkor@comp.nu.edu.sg tat-seng chua depart of comput scienc school of comput nation univers of singapor chuat@comp.nu.edu.sg abstract current approach to identifi definit sentenc in the  context of question answer mainli involv the us of linguist or syntact pattern to identifi inform nugget. thi is  insuffici as thei do not address the novelti factor that a  definit nugget must also possess. thi paper propos to address the defici by build a human interest model from extern knowledg. it is hope that such a model will allow the  comput of human interest in the sentenc with respect to the topic. we compar and contrast our model with current definit question answer model to show that interesting plai an import factor in definit question answer. categori and subject descriptor h.3.3 [inform search and retriev]: retriev model; h.1.2 [user/machin system]: human factor gener term algorithm, human factor, experiment 1. definit question  answer definit question answer wa first introduc to the text retriev confer question answer track main task in 2003. the definit question, also call other question in recent year, ar defin as follow. given a question topic x, the task of a  definit qa system is akin to answer the question what is x? or who is x?. the definit qa system is to search through a new corpu and return return a set of answer that best describ the question topic. each answer should be a uniqu topic-specif nugget that make up on facet in the definit of the question topic. 1.1 the two aspect of topic nugget offici, topic-specif answer nugget or simpli topic nugget ar describ as inform nugget. each inform nugget is a sentenc fragment that describ some factual inform about the topic. depend on the topic type and domain, thi can includ topic properti, relationship the topic ha with some close  relat entiti, or event that happen to the topic. from observ of the answer set for definit question  answer from trec 2003 to 2005, it seem that a signific  number of topic nugget cannot simpli be describ as inform nugget. rather, these topic nugget have a trivia-like qualiti  associ with them. typic, these ar out of the ordinari piec of inform about a topic that can piqu a human reader"s  interest. for thi reason, we decid to defin answer nugget that can evok human interest as interest nugget. in essenc,  interest nugget answer the question what is x famou for?, what defin x? or what is extraordinari about x?. we now have two veri differ perspect as to what  constitut an answer to definit question. an answer can be some import factual inform about the topic or some novel and interest aspect about the topic. thi dualiti of inform and interesting can be clearli observ in the five vital answer nugget for a trec 2005 topic of georg foreman. certain  answer nugget ar more inform while other nugget ar more interest in natur. inform nugget - wa graduat of job corp. - becam oldest world champion in box histori. interest nugget - ha lent hi name to line of food prepar product. - wave american flag after win 1968 olymp championship. - return to box after 10 yr hiatu. as an african-american profession heavyweight boxer, an  averag human reader would find the last three nugget about georg foreman interest becaus boxer do not usual lend their name to food prepar product, nor do boxer retir for 10 year  befor return to the ring and becom the world"s oldest box champion. foreman"s wave of the american flag at the olymp is interest becaus the innoc action caus some  africanamerican to accus foreman of be an uncl tom. as seen here, interest nugget ha some surpris factor or uniqu qualiti that make them interest to human reader. 1.2 identifi interest nugget sinc the origin offici descript for definit compris of identifi inform nugget, most research ha focus entir on identifi inform nugget. in thi paper, we focu on  explor the properti of interest nugget and develop wai of identifi such interest nugget. a human interest model  definit question answer system is develop with emphasi on identifi interest nugget in order to evalu the impact of interest nugget on the perform of a definit  question answer system. we further experi with combin the human interest model with a lexic pattern base definit question answer system in order to captur both inform and interest nugget. 2. relat work there ar current two gener method for definit  question answer. the more common method us a lexic  patternbas approach wa first propos by blair-goldensohn et al. [1] and xu et al. [14]. both group predominantli us pattern such as copula and apposit, as well as manual craft  lexicosyntact pattern to identifi sentenc that contain inform nugget. for exampl, xu et al. us 40 manual defin structur  pattern in their 2003 definit question answer system. sinc then, in an attempt to captur a wider class of inform nugget, mani such system of increas complex ha been creat. a recent system by harabagiu et al. [6] creat a definit  question answer system that combin the us of 150 manual  defin posit and neg pattern, name entiti relat and special craft inform extract templat for 33 target  domain. here, a musician templat mai contain lexic pattern that identifi inform such as the musician"s music style, song sung by the musician and the band, if ani, that the musician belong to. as on can imagin, thi is a knowledg intens approach that requir an expert linguist to manual defin all possibl lexic or syntact pattern requir to identifi specif type of inform. thi process requir a lot of manual labor, expertis and is not scalabl. thi lead to the develop of the soft-pattern approach by cui et al. [4, 11]. instead of manual encod pattern,  answer to previou definit question answer evalu were convert into gener pattern and a probabilist model is train to identifi such pattern in sentenc. given a potenti answer sentenc, the probabilist model output a probabl that  indic how like the sentenc match on or more pattern that the model ha seen in train. such lexicalosyntact pattern approach have been shown to be adept at identifi factual inform nugget such as a person"s birthdat, or the name of a compani"s ceo. howev, these  pattern ar either global applic to all topic or to a specif set of entiti such as musician or organ. thi is in direct contrast to interest nugget that ar highli specif to  individu topic and not to a set of entiti. for exampl, the interest nugget for georg foreman ar specif onli georg foreman and no other boxer or human be. topic specif or topic relev is thu an import criteria that help identifi interest nugget. thi lead to the explor of the second relev-base  approach that ha been us in definit question answer.  predominantli, thi approach ha been us as a backup method for identifi definit sentenc when the primari method of  lexicalosyntact pattern fail to find a suffici number of  inform nugget [1]. a similar approach ha also been us as a baselin system for trec 2003 [14]. more recent, chen et al. [3] adapt a bi-gram or bi-term languag model for definit question answer. gener, the relev-base approach requir a definit corpu that contain document highli relev to the topic. the baselin system in trec 2003 simpli us the topic word as it definit corpu. blair-goldensohn et al. [1] us a machin learner to includ in the definiton corpu sentenc that ar like to be definit. chen et al. [3] collect snippet from googl to build it definit corpu. from the definit corpu, a definit centroid vector is built or a set of centroid word ar select. thi centroid  vector or set of centroid word is taken to be highli indic of the topic. system can then us thi centroid to identifi definit  answer by us a varieti of distanc metric to compar against  sentenc found in the set of retriev document for the topic.  blairgoldensohn et al. [1] us cosin similar to rank sentenc by central. chen et al. [3] build a bigram languag model us the 350 most frequent occur googl snippet term, describ in their paper as an order centroid, to estim the probabl that a sentenc is similar to the order centroid. as describ here, the relev-base approach is highli  specif to individu topic due to it depend on a topic specif definit corpu. howev if individu sentenc ar view as a document, then relev-base approach essenti us the collect topic specif centroid word as a form of document  retriev with autom queri expans to identifi strongli  relev sentenc. thu such method identifi relev sentenc and not sentenc contain definit nugget. yet, the trec 2003 baselin system [14] outperform all but on other system. the bi-term languag model [3] is abl to report result that ar highli competit to state-of-the-art result us thi retriev-base  approach. at trec 2006, a simpl weight sum of all term model with term weight us sole googl snippet outperform all other system by a signific margin [7]. we believ that interest nugget often come in the form of trivia, novel or rare fact about the topic that tend to strongli  cooccur with direct mention of topic keyword. thi mai explain why relev-base method can perform competit in  definit question answer. howev, simpli compar against a singl centroid vector or set of centroid word mai have over  emphas topic relev and ha onli identifi interest  definit nugget in an indirect manner. still, relev base retriev method can be us as a start point in identifi interest nugget. we will describ how we expand upon such method to identifi interest nugget in the next section. 3. human interest model get a comput system to identifi sentenc that a human reader would find interest is a tall order. howev, there ar mani document on the world wide web that ar contain concis, human written summari on just about ani topic. what"s more, these document ar written explicitli for human be and will contain inform about the topic that most human reader would be interest in. assum we can identifi such relev  document on the web, we can leverag them to assist in identifi definit answer to such topic. we can take the assumpt that most sentenc found within these web document will  contain interest facet about the topic at hand. thi greatli simplifi the problem to that of find within the aquaint corpu sentenc similar to those found in web  document. thi approach ha been successfulli us in sever factoid and list question answer system [11] and we feel the us of such an approach for definit or other question answer is justifi. identifi interest nugget requir comput  machineri to understand world knowledg and human insight. thi is still a veri challeng task and the us of human written  document dramat simplifi the complex of the task. in thi paper, we report on such an approach by experi with a simpl word-level edit distanc base weight term  comparison algorithm. we us the edit distanc algorithm to score the similar of a pair of sentenc, with on sentenc come from web resourc and the other sentenc select from the aquaint corpu. through a seri of experi, we will show that even such a simpl approach can be veri effect at definit  question answer. 3.1 web resourc there exist on the internet articl on just about ani topic a  human can think of. what"s more, mani such articl ar central locat on sever promin websit, make them an easili  access sourc of world knowledg. for our work on identifi interest nugget, we focus on find short on or two page articl on the internet that ar highli relev to our desir topic. such articl ar us as thei contain concis inform about the topic. more importantli, the articl ar written by human, for human reader and thu contain the critic human world  knowledg that a comput system current is unabl to captur. we leverag thi world knowledg by collect articl for each topic from the follow extern resourc to build our interest corpu for each topic. wikipedia is a web-base, free-content encyclopedia written  collabor by volunt. thi resourc ha been us by mani question answer system as a sourc of knowledg about each topic. we us a snapshot of wikipedia taken in march 2006 and includ the most relev articl in the  interest corpu. newslibrari is a searchabl archiv of new articl from over 100 differ newspap agenc. for each topic, we  download the 50 most relev articl and includ the titl and first paragraph of each articl in the interest corpu. googl snippet ar retriev by issu the topic as a queri to the googl search engin. from the search result, we  extract the top 100 snippet. while googl snippet ar not articl, we find that thei provid a wide coverag of  author inform about most topic. due to their comprehens coverag of a wide varieti of  topic, the abov resourc form the bulk of our interest corpu. we also extract document from other resourc. howev, as these resourc ar more specif in natur, we do not alwai get ani singl relev document. these resourc ar list below. biographi.com is the websit for the biographi televis cabl channel. the channel"s websit contain searchabl  biographi on over 25,000 notabl peopl. if the topic is a person and we can find a relev biographi on the person, we  includ it it in our interest corpu. bartlebi.com contain a searchabl copi of sever resourc  includ the columbia encyclopedia, the world factbook, and sever english dictionari. s9.com is a biographi dictionari on over 33,000 notabl peopl. like biographi.com, we includ the most relev biographi we can find in the interest corpu. googl definit googl search engin offer a featur call definit that provid the definit for a queri, if it ha on. we us thi featur and extract whatev definit the googl search engin ha found for each topic into the interest corpu. figur 1: human interest model architectur. wordnet wordnet is an well-known electron semant lexicon for the english languag. besid group english word into set of synonym call synset, it also provid a short definit on the mean of word found in each synset. we add thi short definit, if there is on, into our interest  corpu. we have two major us for thi topic specif interest corpu, as a sourc of sentenc contain interest nugget and as a unigram languag model of topic term, i. 3.2 multipl interest centroid we have seen that interest nugget ar highli specif to a topic. relev-base approach such as the bigram languag model us by chen et al. [3] ar focus on identifi highli relev sentenc and pick up definit answer nugget as an indirect consequ. we believ that the us of onli a singl  collect of centroid word ha over-emphas topic relev and choos instead to us multipl centroid. sinc sentenc in the interest corpu of articl we collect from the internet ar like to contain nugget that ar of interest to human reader, we can essenti us each sentenc as  pseudocentroid. each sentenc in the interest corpu essenti rais a differ aspect of the topic for consider as a sentenc of interest to human reader. by perform a pairwis sentenc  comparison between sentenc in the interest corpu and candid  sentenc retriev from the aquaint corpu, we increas the  number of sentenc comparison from o(n) to o(nm). here, n is the number of potenti candid sentenc and m is the number of sentenc in the interest corpu. in return, we obtain a divers rank list of answer that ar individu similar to variou  sentenc found in the topic"s interest corpu. an answer can onli be highli rank if it is strongli similar to a sentenc in the interest corpu, and is also strongli relev to the topic. 3.3 implement figur 1 show the system architectur for the propos human interest-base definit qa system. the aquaint retriev modul shown in figur 1 reus a document retriev modul of a current factoid and list question answer system we have implement. given a set of word describ the topic, the aquaint retriev modul doe queri expans us googl and search an index of aquaint  document to retriev the 800 most relev document for  consider. the web retriev modul on the other hand, search the onlin resourc describ in section 3.1 for interest document in order to popul the interest corpu. the him ranker, or human interest model rank modul, is the implement of what is describ in thi paper. the modul first build the unigram languag model, i, from the collect web document. thi languag model will be us to weight the  import of term within sentenc. next, a sentenc chunker is us to segment all 800 retriev document into individu sentenc. each of these sentenc can be a potenti answer sentenc that will be independ rank by interesting. we rank sentenc by interesting us sentenc from both the interest corpu of  extern document as well as the unigram languag model we built earlier which we us to weight term. a candid sentenc in our top 800 relev aquaint  document is consid interest if it is highli similar in content to a sentenc found in our collect of extern web-document. to achiev thi, we perform a pairwis similar comparison between a candid sentenc and sentenc in our extern document  us a weight-term edit distanc algorithm. term weight ar us to adjust the rel import of each uniqu term found in the interest corpu. when both sentenc share the same term, the similar score is increment by the two time the term"s weight and everi dissimilar term decrement the similar score by the dissimilar term"s weight. we choos the highest achiev similar score for a candid sentenc as the human interest model score for the candid  sentenc. in thi manner, everi candid sentenc is rank by  interesting. final, to obtain the answer set, we select the top 12 highest rank and non redund sentenc as definit answer for the topic. 4. initi experi the human interest-base system describ in the previou  section is design to identifi onli interest nugget and not  inform nugget. thu, it can be describ as a handicap  system that onli deal with half the problem in definit question answer. thi is done in order to explor how interesting plai a factor in definit answer. in order to compar and  contrast the differ between inform and interest nugget, we also implement the soft-pattern bigram model propos by cui et al. [4, 11]. in order to ensur compar result, both  system ar provid ident input data. sinc both system requir the us of extern resourc, thei ar both provid the same web articl retriev by our web retriev modul. both system also rank the same same set of candid sentenc in the form of 800 most relev document as retriev by our aquaint retriev modul. for the experi, we us the trec 2004 question set to tune ani system paramet and us the trec 2005 question set to test the both system. both system ar evalu the result  us the standard score methodolog for trec definit. trec provid a list of vital and okai nugget for each question topic. everi question is score on nugget recal (nr) and nugget  precis (np) and a singl final score is comput us f-measur (see equat 1) with β = 3 to emphas nugget recal. here, nr is the number of vital nugget return divid by total number of vital nugget while np is comput us a minimum allow charact length function defin in [12]. the evalu is  automat conduct us pourpr v1.0c [10]. fscore = β2 ∗ np ∗ nr (β2 + 1)np + nr (1) system f3-score best trec 2005 system 0.2480 soft-pattern (sp) 0.2872 human interest model (him) 0.3031 tabl 1: perform on trec 2005 question set figur 2: perform by entiti type. 4.1 inform vs interesting our first experi compar the perform of sole  identifi interest nugget against sole identifi inform nugget. we compar the result attain by the human interest model that onli identifi interest nugget with the result of the syntact pattern find soft-pattern model as well as the result of the top perform definit system in trec 2005 [13]. tabl 1 show the f3 score the three system for the trec 2005 question set. the human interest model clearli outperform both soft pattern and the best trec 2005 system with a f3 score of 0.303. the result is also compar with the result of a human manual run, which attain a f3 score of 0.299 on the same question set [9]. thi result is confirm that interest nugget doe inde plai a signific role in pick up definit answer, and mai be more vital than us inform find lexic pattern. in order to get a better perspect of how well the human  interest model perform for differ type of topic, we manual divid the trec 2005 topic into four broad categori of  person, organ, thing and event as list in tabl 3. these categori conform to trec"s gener divis of  question topic into 4 main entiti type [13]. the perform of  human interest model and soft pattern bigram model for each entiti type can be seen in figur 2. both system exhibit consist  behavior across entiti type, with the best perform come from person and organ topic and the worst perform from thing and event topic. thi can mainli be attribut to our select of web-base resourc for the definit corpu us by both system. in gener, it is harder to locat a singl web articl that describ an event or a gener object. howev given the same set of web-base inform, the human interest model consist outperform the soft-pattern model for all four entiti type. thi suggest that the human interest model is better abl to leverag the inform found in web resourc to identifi  definit answer. 5. refin encourag by the initi experiment result, we explor two further optim of the basic algorithm. 5.1 weight interest term the word trivia refer to tidbit of unimport or uncommon  inform. as we have note, interest nugget often ha a  trivialik qualiti that make them of interest to human be. from thi descript of interest nugget and trivia, we hypothes that interest nugget ar like to occur rare in a text corpora. there is a possibl that some low-frequenc term mai  actual be import in identifi interest nugget. a standard  unigram languag model would not captur these low-frequenc term as import term. to explor thi possibl, we experi with three differ term weight scheme that can provid more weight to certain low-frequenc term. the weight scheme we consid includ commonli us tfidf, as well as inform theoret kullback-leiber diverg and jensen-shannon  diverg [8]. tfidf, or term frequenc × invers document frequenc, is a standard inform retriev weight scheme that balanc the import of a term in a document and in a corpu. for our experi, we comput the weight of each term as tf × log( n nt ), where tf is the term frequenc, nt is the number of sentenc in the interest corpu have the term and n is the total number of sentenc in the interest corpu. kullback-leibler diverg (equat 2) is also call kl  diverg or rel entropi, can be view as measur the  dissimilar between two probabl distribut. here, we treat the aquaint corpu as a unigram languag model of gener english [15], a, and the interest corpu as a unigram languag model  consist of topic specif term and gener english term, i.  gener english word ar like to have similar distribut in both languag model i and a. thu us kl diverg as a term weight scheme will caus strong weight to be given to  topicspecif term becaus their distribut in the interest corpu thei occur significantli more often or less often than in gener english. in thi wai, high frequenc centroid term as well as low frequenc rare but topic-specif term ar both identifi and highli weight us kl diverg. dkl(i a) = t i(t)log i(t) a(t) (2) due to the power law distribut of term in natur languag, there ar onli a small number of veri frequent term and a larg number of rare term in both i and a. while the common term in english consist of stop word, the common term in the topic specif corpu, i, consist of both stop word and relev topic word. these high frequenc topic specif word occur veri much more frequent in i than in a. as a result, we found that kl diverg ha a bia toward highli frequent topic term as we ar measur direct dissimilar against a model of gener english where such topic term ar veri rare. for thi reason, we explor anoth diverg measur as a possibl term weight scheme. jensen-shannon diverg or js diverg extend upon kl diverg as seen in equat 3. as with kl diverg, we also us js diverg to measur the dissimilar between our two languag model, i and a. dj(i a) = 1 2 ¢dkl  i i+a 2 ¡+ dkl  a i+a 2 ¡£ (3) figur 3: perform by variou term weight scheme on the human interest model. howev, js diverg ha addit properti1 of be  symmetr and non-neg as seen in equat 4. the symmetr properti give a more balanc measur of dissimilar and avoid the bia that kl diverg ha. dj(i a) = dj(a i) = 0 i = a > 0 i <> a (4) we conduct anoth experi, substitut the unigram  langug model weight scheme we us in the initi experi with the three term weight scheme describ abov. as lower bound refer, we includ a term weight scheme consist of a constant 1 for all term. figur 3 show the result of appli the five differ term weight scheme on the human interest model. tfidf perform the worst as we had anticip. the reason is that most term onli appear onc within each sentenc, result in a term frequenc of 1 for most term. thi caus the idf compon to be the main factor in score sentenc. as we ar comput the invers document frequenc for term in the interest corpu collect from web resourc, idf  heavili down-weight highli frequenc topic term and relev term. thi result in tfidf favor all low frequenc term over high frequenc term in the interest corpu. despit thi, the tfidf weight scheme onli score a slight 0.0085 lower than our lower bound refer of constant weight. we view thi as a posit indic that low frequenc term can inde be us in find interest nugget. both kl and js diverg perform margin better than the uniform languag model probabilist scheme that we us in our initi experi. from inspect of the weight list of term, we observ that while low frequenc relev term were boost in strength, high frequenc relev term still domin the top of the weight term list. onli a hand of low frequenc term were weight as strongli as topic keyword and combin with their low frequenc, mai have limit the impact of re-weight such term. howev we feel that despit thi, jensen-shannon  diverg doe provid a small but measur increas in the  perform of our human interest model. 1 js diverg also ha the properti of be bound, allow the result to be treat as a probabl if requir. howev, the bound properti is not requir here as we ar onli treat the diverg comput by js diverg as term weight 5.2 select web resourc in on of our initi experi, we observ that the qualiti of web resourc includ in the interest corpu mai have a direct impact on the result we obtain. we want to determin what  impact the choic of web resourc have on the perform of our human interest model. for thi reason, we split our collect of web resourc into four major group list here: n - new: titl and first paragraph of the top 50 most relev articl found in newslibrari. w - wikipedia: text from the most relev articl found in wikipedia. s - snippet: snippet extract from the top 100 most relev link after queri googl. m - miscellan sourc: combin of content (when  avail) from secondari sourc includ biographi.com, s9.com, bartlebi.com articl, googl definit and wordnet definit. we conduct a gamut of run on the trec 2005 question set us all possibl combin of the abov four group of web resourc to identifi the best possibl combin. all run were conduct on human interest model us js diverg as term weight scheme. the run were sort in descend f3-score and the top 3 best perform run for each entiti class ar list in tabl 2 togeth with earlier report f3-score from figur 2 as a baselin refer. a consist trend can be observ for each entiti class. for person and event topic, newslibrari articl ar the main sourc of interest nugget with googl snippet and  miscellan articl offer addit support evid. thi seem intuit for event as newspap predominantli focu on  report break newsworthi event and ar thu excel sourc of interest nugget. we had expect wikipedia rather than new articl to be a better sourc of interest fact about  peopl and were surpris to discov that new articl outperform wikipedia. we believ that the reason is becaus the peopl  select as topic thu far have been celebr or well known public figur. human reader ar like to be interest in new event that spotlight these person. convers for organ and thing topic, the best sourc of interest nugget come from wikipedia"s most relev articl on the topic with googl snippet again provid addit inform for organ. with an oracl that can classifi topic by entiti class with 100% accuraci and by us the best web resourc for each entiti class as shown in tabl 2, we can attain a f3-score of 0.3158. 6. unifi inform with interesting we have thu far been compar the human interest model against the soft-pattern model in order to understand the  differ between interest and inform nugget. howev from the perspect of a human reader, both inform and interest nugget ar us and definit. inform nugget present a gener overview of the topic while interest nugget give  reader ad depth and insight by provid novel and uniqu aspect about the topic. we believ that a good definit question  answer system should provid the reader with a combin mixtur of both nugget type as a definit answer set. rank person org thing event baselin unigram weight scheme, n+w+s+m 0.3279 0.3630 0.2551 0.2644 1 n+s+m w+s w+m n+m 0.3584 0.3709 0.2688 0.2905 2 n+s n+w+s w+s+m n+s+m 0.3469 0.3702 0.2665 0.2745 3 n+m n+w+s+m w+s n+s 0.3431 0.3680 0.2616 0.2690 tabl 2: top 3 run us differ web resourc for each  entiti class we now have two veri differ expert at identifi  definit. the soft pattern bigram model propos by cui et al. is an expert in identifi inform nugget. the human  interest model we have describ in thi paper on the other hand is an expert in find interest nugget. we had initi hope to unifi the two separ definit question answer system by appli an ensembl learn method [5] such as vote or  boost in order to attain a good mixtur of inform and interest nugget in our answer set. howev, none of the ensembl  learn method we attempt could outperform our human interest model. the reason is that both system ar pick up veri differ sentenc as definit answer. in essenc, our two expert ar disagre on which sentenc ar definit. in the top 10  sentenc from both system, onli 4.4% of these sentenc appear in both answer set. the remain answer were complet  differ. even when we examin the top 500 sentenc gener by both system, the agreement rate wa still an extrem low 5.3%. yet, despit the low agreement rate between both system, each individu system is still abl to attain a rel high f3 score. there is a distinct possibl that each system mai be select differ sentenc with differ syntact structur but actual have the same or similar semant content. thi could result in both system have the same nugget mark as correct even though the sourc answer sentenc ar structur differ. unfortun, we ar unabl to automat verifi thi as the evalu softwar we ar us doe not report correctli identifi answer nugget. to verifi if both system ar select the same answer nugget, we randomli select a subset of 10 topic from the trec 2005 question set and manual identifi correct answer nugget (as  defin by trec accessor) from both system. when we compar the answer nugget found by both system for thi subset of topic, we found that the nugget agreement rate between both system wa 16.6%. while the nugget agreement rate is higher than the  sentenc agreement rate, both system ar gener still pick up differ answer nugget. we view thi as further indic that definit ar inde made up of a mixtur of inform and  interest nugget. it is also indic that in gener, interest and inform nugget ar quit differ in natur. there ar thu ration reason and practic motiv in  unifi answer from both the pattern base and corpu base  approach. howev, the differ between the two system also caus issu when we attempt to combin both answer set.  current, the best approach we found for combin both answer set is to merg and re-rank both answer set with boost agreement. we first normal the top 1,000 rank sentenc from each system, to obtain the normal human interest model score, him(s), and the normal soft pattern bigram model score, sp(s), for everi uniqu sentenc, s. for each sentenc, the two  separ score for ar then unifi into a singl score us equat 5. when onli on system believ that the sentenc is definit, we simpli retain that system"s normal score as the unifi score. when both system agre agre that the sentenc is definit, the sentenc"s score is boost by the degre of agreement between between both system. score(s) = max(shim, ssp)1−min(shim,ssp) (5) in order to maintain a divers set of answer as well as to  ensur that similar sentenc ar not given similar rank, we  further re-rank our combin list of answer us maxim margin relev or mmr [2]. us the approach describ here, we achiev a f3 score of 0.3081. thi score is equival to the initi human interest model score of 0.3031 but fail to outperform the optim human interest model model. 7. conclus thi paper ha present a novel perspect for answer  definit question through the identif of interest nugget. interest nugget ar uncommon piec of inform about the topic that can evok a human reader"s curios. the notion of an averag human reader is an import consider in our  approach. thi is veri differ from the lexico-syntact pattern  approach where the context of a human reader is not even consid when find answer for definit question answer. us thi perspect, we have shown that us a combin of a carefulli select extern corpu, match against multipl centroid and take into consider rare but highli topic  specif term, we can build a definit question answer  modul that is more focus on identifi nugget that ar of interest to human be. experiment result ha shown thi approach can significantli outperform state-of-the-art definit question answer system. we further show that at least two differ type of answer nugget ar requir to form a more thorough set of definit answer. what seem to be a good set of definit answer is some gener inform that provid a quick inform overview mix togeth with some novel or interest aspect about the topic. thu we feel that a good definit question answer system would need to pick up both inform and interest nugget type in order to provid a complet definit coverag on all  import aspect of the topic. while we have attempt to build such a system by combin our propos human interest model with cui et al."s soft pattern bigram model, the inher differ between both type of nugget seemingli caus by the low agreement rate between both model have made thi a difficult task. inde, thi is natur as the two model have been design to identifi two veri differ type of definit answer us veri differ type of featur. as a result, we ar current onli abl to achiev a  hybrid system that ha the same level of perform as our propos human interest model. we approach the problem of definit question answer from a novel perspect, with the notion that interest factor plai a role in identifi definit answer. although the method we us ar simpl, thei have been shown experiment to be  effect. our approach mai also provid some insight into a few anomali in past definit question answer"s trial. for  instanc, the top definit system at the recent trec 2006  evalu wa abl to significantli outperform all other system us rel simpl unigram probabl extract from googl  snippet. we suspect the main contributor to the system"s perform entiti type topic organ depauw univers, merck & co.,  norwegian cruis line (ncl), unit  parcel servic (up), littl leagu  basebal, cliff note, american legion, soni pictur entertain (spe),  telefonica of spain, lion club  intern, amwai, mcdonald"s corpor, harlei-davidson, u.s. naval academi, opec, nato, intern bureau of  univers postal union (upu), organ of islam confer (oic), pbgc person bing crosbi, georg foreman, akira  kurosawa, sani abacha, enrico fermi, arnold palmer, woodi guthri, sammi sosa, michael weiss, paul newman, jess  ventura, rose crumb, rachel carson, paul  rever, vicent fox, rocki marciano, enrico caruso, pope piu xii, kim jong il thing f16, bollywood, viagra, howdi doodi show, louvr museum, meteorit,  virginia wine, count crow, boston big dig, chunnel, longwood garden, camp david, kudzu, u.s. medal of honor, tsunami, genom, food-for-oil agreement, shiit, kinmen island event russian submarin kursk sink, miss  univers 2000 crown, port arthur  massacr, franc win world cup in  soccer, plane clip cabl wire in italian  resort, kip kinkel school shoot, crash of egyptair flight 990, preak 1998, first 2000 bush-gore presidenti debat , 1998 indict and trial of susan  mcdougal, return of hong kong to chines sovereignti, 1998 nagano olymp game, super bowl xxxiv, 1999 north american intern auto show, 1980 mount st. helen erupt, 1998 basebal world  seri, hindenburg disast, hurrican mitch tabl 3: trec 2005 topic group by entiti type is googl"s pagerank algorithm, which mainli consid the  number of linkag, ha an indirect effect of rank web document by the degre of human interest. in our futur work, we seek to further improv on the combin system by incorpor more evid in support of correct  definit answer or to filter awai obvious wrong answer. 8. refer [1] s. blair-goldensohn, k. r. mckeown, and a. h. schlaikjer. a hybrid approach for qa track definit question. in trec "03: proceed of the 12th text retriev confer, gaithersburg, maryland, 2003. [2] j. g. carbonel and j. goldstein. the us of mmr, divers-base rerank for reorder document and produc summari. in research and develop in inform retriev, page 335-336, 1998. [3] y. chen, m. zhou, and s. wang. rerank answer for definit qa us languag model. in proceed of the 21st intern confer on comput linguist and 44th annual meet of the associ for comput linguist, page 1081-1088, sydnei, australia, juli 2006. associ for comput linguist. [4] h. cui, m.-y. kan, and t.-s. chua. gener soft pattern model for definit question answer. in sigir "05: proceed of the 28th annual intern acm sigir confer on research and develop in inform retriev, page 384-391, new york, ny, usa, 2005. acm press. [5] t. g. dietterich. ensembl method in machin learn. lectur note in comput scienc, 1857:1-15, 2000. [6] s. harabagiu, d. moldovan, c. clark, m. bowden, a. hickl, and p. wang. emploi two question answer system at trec 2005. in trec "05: proceed of the 14th text retriev confer, gaithersburg, maryland, 2005. [7] m. kaisser, s. scheibl, and b. webber. experi at the univers of edinburgh for the trec 2006 qa track. in trec "06 notebook: proceed of the 14th text retriev confer, gaithersburg, maryland, 2006. nation institut of standard and technolog. [8] j. lin. diverg measur base on the shannon entropi. ieee transact on inform theori, 37(1):145 - 151, jan 1991. [9] j. lin, e. abel, d. demner-fushman, d. w. oard, p. wu, and y. wu. a menageri of track at maryland: hard, enterpris, qa, and genom, oh my! in trec "05: proceed of the 14th text retriev confer, gaithersburg, maryland, 2005. [10] j. lin and d. demner-fushman. automat evalu answer to definit question. in proceed of human languag technolog confer and confer on empir method in natur languag process, page 931-938, vancouv, british columbia, canada, octob 2005. associ for comput linguist. [11] r. sun, j. jiang, y. f. tan, h. cui, t.-s. chua, and m.-y. kan. us syntact and semant relat analysi in question answer. in trec "05: proceed of the 14th text retriev confer, gaithersburg, maryland, 2005. [12] e. m. voorhe. overview of the trec 2003 question answer track. in text retriev confer 2003, gaithersburg, maryland, 2003. nation institut of standard and technolog. [13] e. m. voorhe. overview of the trec 2005 question answer track. in trec "05: proceed of the 14th text retriev confer, gaithersburg, maryland, 2005. nation institut of standard and technolog. [14] j. xu, a. licuanan, and r. weischedel. trec 2003 qa at bbn: answer definit question. in trec "03: proceed of the 12th text retriev confer, gaithersburg, maryland, 2003. [15] d. zhang and w. s. lee. a languag model approach to passag question answer. in trec "03: proceed of the 12th text retriev confer, gaithersburg, maryland, 2003. 