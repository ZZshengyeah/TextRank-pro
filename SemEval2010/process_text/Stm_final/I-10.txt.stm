smile: sound multi-agent increment learn ;-)∗ gauvain bourgn lamsad, umr 7024 cnr, univers pari-dauphin, 75775 pari cedex 16 amal el fallah segrouchni lip6, umr 7606 cnr, univers pari 6, 104, av. du pr´esid kennedi, 75116 pari henri soldano lipn, umr 7030 cnr, univers pari-nord, 99 av. j-b clement, 93430, villetaneus abstract thi articl deal with the problem of collabor  learn in a multi-agent system. here each agent can updat increment it belief b (the concept represent) so that it is in a wai kept consist with the whole set of inform k (the exampl) that he ha receiv from the environ or other agent. we extend thi notion of consist (or sound) to the whole ma and  discuss how to obtain that, at ani moment, a same consist concept represent is present in each agent. the  correspond protocol is appli to supervis concept learn. the result method smile (stand for sound  multiag increment learn) is describ and experi here. surprisingli some difficult boolean formula ar  better learn, given the same learn set, by a multi agent system than by a singl agent. categori and subject descriptor i.2.6 [artifici intellig]: learn-concept  learn; i.2.11 [artifici intellig]: distribut artifici intellig-multiag system gener term experiment, algorithm, measur, perform 1. introduct thi articl deal with the problem of collabor  concept learn in a multi-agent system. [6] introduc a  characteris of learn in multi-agent system accord to the level of awar of the agent. at level 1, agent learn ∗the primari author of thi paper is a student. in the system without take into account the presenc of other agent, except through the modif brought upon the environ by their action. level 2 impli direct  interact between the agent as thei can exchang messag to improv their learn. level 3 would requir agent to take into account the compet of other agent, and be abl to learn from observ of the other agent" behaviour (while consid them as independ entiti and not  indetermin part of the environ as in level 1). we focu in thi paper on level 2, studi direct interact between agent involv in a learn process. each agent is assum to be abl to learn increment from the data he receiv, mean that each agent can updat hi belief set b to keep it consist with the whole set of inform k that he ha receiv from the environ or from other agent. in such a case, we will sai that he is a-consist. here, the belief set b repres hypothet knowledg that can therefor be revis, wherea the set of inform k repres certain knowledg, consist of non revis observ and fact. moreov, we suppos that at least a part bc of the belief of each agent is  common to all agent and must stai that wai. therefor, an updat of thi common set bc by agent r must provok an updat of bc for the whole commun of agent. it lead us to defin what is the ma-consist of an agent with respect to the commun. the updat process of the  commun belief when on of it member get new inform can then be defin as the consist mainten process ensur that everi agent in the commun will stai  masconsist. thi ma-consist mainten process of an agent get new inform give him the role of a learner and impli commun with other agent act as  critic. howev, agent ar not specialis and can in turn be learner or critic, none of them be kept to a specif role. piec of inform ar distribut among the agent, but can be redund. there is no central memori. the work describ here ha it origin in a former work  concern learn in an intent multi-agent system us a bdi formal [6]. in that work, agent had plan, each of them be associ with a context defin in which condit it can be trigger. plan (each of them have it own context) were common to the whole set of agent in the commun. agent had to adapt their plan context depend on the failur or success of execut plan, us a learn mechan and ask other agent for exampl (plan success or failur). howev thi work lack a collect learn protocol enabl a real autonomi of the multi-agent system. the studi of such a protocol is the  object of the present paper. in section 2 we formal defin the ma-consist of an updat mechan for the whole ma and we propos a gener updat mechan prove to be ma consist. in section 3 we describ smile, an increment multi agent concept learner appli our ma consist updat  mechan to collabor concept learn. section 4 describ variou experi on smile and discuss variou issu includ how the accuraci and the simplic of the current hypothesi vari when compar singl agent learn and ma learn. in section 5 we briefli present some relat work and then conclud in section 6 by discuss further investig on ma consist learn. 2. formal model 2.1 definit and framework in thi section, we present a gener formul of  collect increment learn in a cognit multi agent system. we repres a ma as a set of agent r1, ..., rn. each agent ri ha a belief set bi consist of all the revis knowledg he ha. part of these knowledg must be share with other agent. the part of bi that is common to all agent is denot as bc . thi common part provok a  depend between the agent. if an agent ri updat hi belief set bi to bi, chang in the process bc into bc , all other agent rk must then updat their belief set bk to bk so that bc ⊆ bk. moreov, each agent ri ha store some certain inform ki. we suppos that some consist properti con(bi, ki) can be verifi by the agent itself between it belief bi and it inform ki. as said befor, bi repres knowledg that might be revis wherea ki repres observ fact, taken as be true, and which can possibl contradict bi. definit 1. a-consist of an agent an agent ri is a-consist iff con(bi, ki) is true. exampl 1. agent r1 ha a set of plan which ar in the common part bc of b1. each plan p ha a trigger  context d(p) (which act as a pre-condit) and a bodi. some piec of inform k could be plan p, trigger in  situat s, ha fail in spite of s be an instanc of d(p). if thi piec of inform is ad to k1, then agent r1 is not a-consist anymor: con(b1, k1 ∪ k) is fals. we also want to defin some notion of consist for the whole ma depend on the belief and inform set of it constitut element. we will first defin the  consist of an agent ri with respect to it belief set bi and it own inform set ki togeth with all inform set k1...kn from the other agent of the ma. we will simpli do that by consid what would be the a-consist of the agent if he ha the inform of all the other agent. we call thi notion the ma-consist: definit 2. ma-consist of an agent an agent ri is ma-consist iff con(bi, ki ∪ k) is true, where k = ∪j∈{1,..,n}−{i}kj 1 is the set of all inform from other agent of the ma. 1 we will note thi ∪ kj when the context is similar. exampl 2. us the previou exampl, suppos that the piec of inform k is includ in the inform k2 of agent r2. as long as the piec of inform is not  transmit to r1, and so ad to k1 , r1 remain a-consist. howev, r1 is not ma-consist as k is in the set k of all inform of the ma. the global consist of the ma is then simpli the ma-consist of all it agent. definit 3. consist of a ma a ma r1,...,rn is consist iff all it agent ri ar  masconsist. we now defin the requir properti for a revis  mechan m updat an agent ri when it get a piec of  inform k. in the follow, we will suppos that: • updat is alwai possibl, that is, an agent can  alwai modifi it belief set bi in order to regain it a-consist. we will sai that each agent is local effici. • consid two set of inform con(bi, k1) and con(bi, k2), we also have con(bi, k1 ∪ k2). that is, a-consist of the agent is addit. • if a piec of inform k concern the common set bc is consist with an agent, it is consist with all agent: for all pair of agent (ri,rj) such that con(bi, ki) and con(bj, kj) ar true, we have, for all piec of inform k: con(bi, ki ∪ k) iff con(bj, kj ∪ k). in such a case, we will sai that the ma is coher. thi last condit simpli mean that the common belief set bc is independ of the possibl differ between the belief set bi of each agent ri. in the simplest case, b1 = ... = bn = bc . m will also be view as an increment learn  mechan and repres as an applic chang bi in bi. in the follow, we shall note ri(bi, ki) for ri when it is us. definit 4. a-consist of a revis an updat mechan m is a-consist iff for ani agent ri and ani piec of inform k reach ri, the a-consist of thi agent is preserv. in other word, iff: ri(bi, ki) a-consist ⇒ ri(bi, ki) a-consist, where bi = m(bi) and ki = ki ∪ k is the set of all  inform from other agent of the ma. in the same wai, we defin the ma-consist of a  revis mechan as the a-consist of thi mechan should the agent dispos of all inform in the ma. in the follow, we shall note, if need, ri(bi, ki, k) for the agent ri in ma r1 . . . rn. definit 5. ma-consist of a revis an updat mechan ms is ma-consist iff for all agent ri and all piec of inform k reach ri, the  masconsist of thi agent is preserv. in other word, if: ri(bi, ki, k) ma-consist ⇒ ri(bi, ki, k) ma-consist, where bi = ms(bi), ki = ki ∪ k, and k = ∪kj is the set of all inform from the ma. the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) 165 at last, when a ma-consist mechan is appli by an agent get a new piec of inform, a desir  sideeffect of the mechan should be that all other agent  remain ma-consist after ani modif of the common part bc , that is, the ma itself should becom consist again. thi properti is defin as follow: definit 6. strong ma-consist of a revis an updat mechan ms is strongli ma-consist iff - ms is ma-consist, and - the applic of ms by an agent preserv the consist of the ma. 2.2 a strongli ma-consist updat  mechan the gener idea is that, sinc inform is distribut among all the agent of the ma, there must be some  interact between the learner agent and the other agent in a strongli ma-consist updat mechan ms. in order to ensur it ma-consist, ms will be constitut of  reiter applic by the learner agent ri of an intern a-consist mechan m, follow by some interact between ri and the other agent, until ri regain it  masconsist. we describ below such a mechan, first with a descript of an interact, then an iter, and final a statement of the termin condit of the mechan. the mechan is trigger by an agent ri upon receipt of a piec of inform k disrupt the ma-consist. we shall note m(bi) the belief set of the learner agent ri after an updat, bc the common part modifi by ri, and bj the belief set of anoth agent rj induc by the modif of it common part bc in bc . an interact i(ri, rj) between the learner agent ri and anoth agent rj, act as critic is constitut of the  follow step: • agent ri send the updat bc of the common part of it belief. have appli it updat mechan, ri is a-consist. • agent rj check the modif bj of it belief  induc by the updat bc . if thi modif preserv it a-consist, rj adopt thi modif. • agent rj send either an accept of bc or a denial along with on (or more) piec(s) of inform k such that con(bj, k ) is fals. an iter of ms will then be compos of: • the recept by the learner agent ri of a piec of inform and the updat m(bi) restor it  aconsist • a set of interact i(ri, rj) (in which sever critic agent can possibl particip). if at least on piec of inform k is transmit to ri, the addit of k will necessarili make ri a-inconsist and a new iter will then occur. thi mechan ms end when no agent can provid such a piec of inform k . when it is the case, the  masconsist of the learner agent ri is restor. proposit 1. let r1,...,rn be a consist ma in which agent ri receiv a piec of inform k break it  aconsist, and m an a-consist intern updat  mechan. the updat mechan ms describ abov is strongli ma-consist. proof. the proof directli deriv from the mechan descript. thi mechan ensur that each time an agent receiv an event, it ma-consist will be restor. as the other agent all adopt the final updat bc , thei ar all ma-consist, and the ma is consist. therefor ms is a strongli consist updat mechan. in the mechan ms describ abov, the learner agent is the onli on that receiv and memor inform dure the mechan execut. it ensur that ms  termin. the piec of inform transmit by other agent and memor by the learner agent ar redund as thei ar alreadi present in the ma, more precis in the memori of the critic agent that transmit them. note that the mechan ms propos here doe not  explicitli indic the order nor the scope of the interact. we will consid in the follow that the modif  propos bc is sent sequenti to the differ agent  (synchron mechan). moreov, the respons of a critic agent will onli contain on piec of inform inconsist with the propos modif. we will sai that the  respons of the agent is minim. thi mechan ms, be synchron with minim respons, minim the amount of inform transmit by the agent. we will now  illustr it in the case of multi-agent concept learn. 3. soundmulti-agentincrement learn 3.1 the learn task we experi the mechan propos abov in the case of increment ma concept learn. we consid here a hypothesi languag in which a hypothesi is a  disjunct of term. each term is a conjunct of atom from a set a. an exampl is repres by a tag + or − and a descript 2 compos of a subset of atom e ⊆ a. a term cover an exampl if it constitut atom ar includ in the exampl. a hypothesi cover an exampl if on of it term cover it. thi represent will be us below for learn boolean formula. neg liter ar here repres by  addit atom, like not − a. the boolean formula f =(a ∧ b) ∨ (b ∧ ¬c) will then be written (a ∧ b) ∨ (b ∧ not − c). a posit exampl of f, like {not − a, b, not − c}, repres a model for f. 3.2 increment learn process the learn process is an updat mechan that, given a current hypothesi h, a memori e = e+ ∪ e− fill with the previous receiv exampl, and a new posit or neg exampl e, produc a new updat  hypothesi. befor thi updat, the given hypothesi is complet, mean that it cover all posit exampl of e+ , and 2 when no confus is possibl, the word exampl will be us to refer to the pair (tag, descript) as well as the descript alon. 166 the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) coher, mean that it doe not cover ani neg  exampl of e− . after the updat, the new hypothesi must be complet and coher with the new memori state e ∪ {e}. we describ below our singl agent updat mechan,  inspir from a previou work on increment learn[7]. in the follow, a hypothesi h for the target formula f is a list of term h, each of them be a conjunct of atom. h is coher if all term h ar coher, and h is complet if each element of e+ is cover by at least on term h of h. each term is by construct the lgg (least gener  gener) of a subset of posit instanc {e1, ..., en}[5], that is the most specif term cover {e1, ..., en}. the lgg oper is defin by consid exampl as term, so we denot as lgg(e) the most specif term that cover e, and as lgg(h, e) the most specif term which is more gener than h and that cover e. restrict the term to lgg is the basi of a lot of bottom-up learn algorithm (for instanc [5]). in the typolog propos by [9], our  updat mechan is an increment learner with full instanc memori: learn is made by success updat and all exampl ar store. the updat mechan depend of the ongo hypothesi h, the ongo exampl e+ and e− , and the new exampl e. there ar three possibl case: • e is posit and h cover e, or e is neg and h doe not cover e. no updat is need, h is alreadi complet and coher with e ∪ {e}. • e is posit and h doe not cover e: e is denot as a posit counterexampl of h. then we seek to gener in turn the term h of h. as soon as a correct gener h = lgg(h, e) is found, h replac h in h. if there is a term that is less gener that h , it is discard. if no gener is correct (mean here coher), h ∪ lgg(e) replac h. • e is neg and h cover e: e is denot as a  neg counterexampl of h. each term h cover e is then discard from h and replac by a set of term {h1, ...., hn} that is, as a whole, coher with e− ∪ {e} and that cover the exampl of e+  uncov by h − {h}. term of the final hypothesi h that ar less gener than other ar discard from h. we will now describ the case where e = e− is a cover neg exampl. the follow function ar us here: • coveredonlybi(h, e+) give the subset of e+ cover by h and no other term of h. • bestcov(h1, h2) give h1 if h1 cover more exampl from uncoveredpo than h2, otherwis it give h2. • cover(h) give the element of uncoveredpo cover by h. // special of each h cover e− for each h of h cover e− do h = h − {h} uncoveredpo = coveredonlybi(h, e+ ) ar= atom that ar neither in e− nor in h while (uncoveredpo = ∅) do // seek the best special of h hc=h best=⊥ // ⊥ cover no exampl for each a of ar do hc= h ∧ a best = bestcov(hc, best) endfor ar=ar−{best} hi=lgg(cover(best)) h = h ∪ {hi} uncoveredpo=uncoveredpo - cover(best) endwhil endfor term of h that ar less gener than other ar discard. note that thi mechan tend to both make a minim updat of the current hypothesi and minim the number of term in the hypothesi, in particular by discard term less gener than other on after updat a hypothesi. 3.3 collect learn if h is the current hypothesi, ei the current exampl memori of agent ri and e the set of all the exampl receiv by the system, the notat of section 2 becom bi = bc = h, ki = ei and k = e. con(h, ei) state that h is complet and coher with ei. in such a case, ri is a-consist. the piec of inform k receiv by agent ri is here simpli an exampl e along with it tag. if e is such that the current hypothesi h is not complet or coher with ei ∪ {e}, e contradict h: ri becom a-inconsist, and therefor the ma is not consist anymor. the updat of a hypothesi when a new exampl arriv is an a- consist mechan. follow proposit 1 thi mechan can be us to produc a strong ma-consist mechan: upon recept of a new exampl in the ma by an agent r, an updat is possibl need and, after a set of interact between r and the other agent, result in a new hypothesi share by all the agent and that restor the consist of the ma, that is which is complet and coher with the set es of all the exampl present in the ma. it is clear that by minim the number of  hypothesi modif, thi synchron and minim  mechan minim the number of exampl receiv by the learner from other agent, and therefor, the total number of exampl store in the system. 4. experi in the follow, we will learn a boolean formula that is a difficult test for the learn method: the 11-multiplex (see [4]). it concern 3 address boolean attribut a0, a1, a2 and 8 data boolean attribut d0, ..., d7. formula f11 is satisfi if the number code by the 3 address attribut is the number of a data attribut whose valu is 1. it formula is the follow: f11 = (a0 ∧a1 ∧a2 ∧d7)∨(a0 ∧a1 ∧¬a2 ∧d6)∨(a0 ∧¬a1 ∧ a2 ∧d5)∨(a0 ∧¬a1 ∧¬a2 ∧d4)∨(¬a0 ∧a1 ∧a2 ∧d3)∨(¬a0 ∧ a1 ∧¬a2 ∧d2)∨(¬a0 ∧¬a1 ∧a2 ∧d1)∨(¬a0 ∧¬a1 ∧¬a2 ∧d0). there ar 2048 = 211 possibl exampl, half of whom ar posit (mean thei satisfi f11) while the other half is neg. an experi is typic compos of 50 trial. each run correspond to a sequenc of 600 exampl that ar  increment learn by a multi agent system with n agent the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) 167 (n-ma). a number of variabl such as accuraci, (i.e. the frequenc of correct classif of a set of unseen  exampl), hypothesi size (i.e. the number of term in the  current formula) or number of store exampl, is record each time 25 exampl ar receiv by the system dure those run. in the protocol that is us here, a new exampl is sent to a random agent when the ma is consist. the next exampl will be sent in turn to an other agent when the ma consist will have been restor. in such a wai we simul a kind of slow learn: the frequenc of exampl arriv is slow compar to the time taken by an updat. 4.1 effici of ma concept learn 4.1.1 execut time we briefli discuss here execut time of learn in the ma. note that the whole set of action and interact in the ma is simul on a singl processor. figur 1 show that time linearli depend on the number of agent. at the end of the most activ part of learn (200 exampl), a  16ma ha taken 4 time more learn time than a 4-ma. thi execut time repres the whole set of learn and figur 1: execut time of a n-ma (from n = 2 at the bottom to n = 20 on the top). commun activ and hint at the cost of  maintain a consist learn hypothesi in a ma compos of autonom agent. 4.1.2 redund in the ma memori we studi now the distribut of the exampl in the ma memori. redund is written rs = ns/ne, where ns is the total number of exampl store in the ma, that is the sum of the size of agent exampl memori ei, and ne is the total number of exampl receiv from the environ in the ma. in figur 2, we compar redund in 2 to 20 agent ma. there is a peak, slowli move from 80 to 100 exampl, that repres the number of exampl for which the learn is most activ. for 20 agent, maxim redund is no more than 6, which is far less than the maxim theoret valu of 20. note that when learn becom less activ, redund tend toward it minim valu 1: when there is no more updat, exampl ar onli figur 2: redund of exampl store in a  nma (from n = 2 at the bottom to n = 20 on the top) . store by the agent that receiv them. 4.1.3 a n-ma select a simpler solut than a  singl agent the propos mechan tend to minim the number of term in the select hypothesi. dure learn, the size of the current hypothesi grow up beyond the optimum, and then decreas when the ma converg. in the multiplex 11 testb, the optim number of term is 8, but there also exist equival formula with more term. it is interest to note that in thi case the 10-ma converg toward an exact solut closer to the optim number of term (here 8) (see figur 3). after 1450 exampl have been present both 1-ma and 10-ma have exactli learn the concept (the respect accuraci ar 0.9999 and 1) but the singl agent express in averag the result as a 11.0 term dnf wherea the 10-ma express it as a 8.8 term dnf.  howev for some other boolean function we found that  dure learn 1-ma alwai produc larger hypothes than 10-ma but that both ma converg to hypothes with similar size result. 4.1.4 a n-ma is more accur than a singl agent figur 4 show the improv brought by a ma with n agent compar to a singl agent. thi improv wa not especi expect, becaus whether we have on or n agent, when n exampl ar given to the ma it ha access to the same amount of inform, maintain onli on  ongo hypothesi and us the same basic revis algorithm whenev an agent ha to modifi the current hypothesi. note that if the accuraci of 1, 2, 4 and 10-ma ar  significantli differ, get better as the number of agent increas, there is no clear differ beyond thi point: the accuraci curv of the 100 agent ma is veri close to the on of the 10 agent ma. 4.1.4.1 boolean formula. to evalu thi accuraci improv, we have  experi our protocol on other problem of boolean  function learn, as in the multiplex-11 case, these function 168 the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) figur 3: size of the hypothesi built by 1 and  10ma: the m11 case. figur 4: accuraci of a n-ma: the m11 case (from bottom to top, n = 1, 2, 4, 10, 100). ar learnt in the form of more or less syntact complex dnf3 (that is with more or less conjunct term in the dnf), but ar also more or less difficult to learn as it can be difficult to get it wai in the hypothesi space to reach them. furthermor, the presenc in the descript of  irrelev attribut (that is attribut that doe not belong to the target dnf) make the problem more difficult. the  follow problem have been select to experi our  protocol: (i) the multiplex-11 with 9 irrelev attribut: m11 9, (ii) the 20-multiplex m20 (with 4 address bit and 16 data bit), (iii) a difficult pariti problem (see [4]) the xorp m: there must be an odd number of bit with valu 1 in the p first attribut for the instanc to be posit, the p other bit be irrelev, and (iv) a simpl dnf  formula (a ∧ b ∧ c) ∨ (c ∧ d ∧ e)(e ∧ f ∧ g) ∧ (g ∧ h ∧ i) with 19 irrelev attribut. the follow tabl sum up some  inform about these problem, give the total number of attribut includ irrelev on, the number of irrelev 3 disjunct normal form attribut, the minim number of term of the  correspond dnf, and the number of learn exampl us. pb att. irr. att. term ex. m11 11 0 8 200 m11 9 20 9 8 200 m20 20 0 16 450 xor3 25 28 25 4 200 xor5 5 10 5 16 180 xor5 15 20 15 16 600 simpl4-9 19 28 19 4 200 below ar given the accuraci result of our learn  mechan with a singl agent and a 10 agent ma, along with the result of two standard algorithm implement with the learn environ weka[16]: jrip (an implement of ripper[2]) and id3[12]. for the experi with jrip and id3, we measur the mean accuraci on 50 trial, each time randomli separ exampl in a learn set and a test set. jrip and id3 paramet ar default paramet, except that jrip is us without prune. the follow tabl show the result: pb jrip id3 sm 1 sm 10 m11 88.3 80.7 88.7 95.5 m11 9 73.4 67.9 66.8 83.5 m20 67.7 62.7 64.6 78.2 xor3 25 54.4 55.2 71.4 98.5 xor5 5 52.6 60.8 71.1 78.3 xor5 15 50.9 51.93 62.4 96.1 simpl4-9 19 99.9 92.3 87.89 98.21 it is clear that difficult problem ar better solv with more agent (see for instanc xor5 15). we think that these benefit, which can be import with an increas number of agent, ar due to the fact that each agent realli  memor onli part of the total number of exampl, and thi part is partli select by other agent as counter exampl, which caus a greater number of current hypothesi updat and therefor, a better explor of the hypothes space. 4.1.4.2 ml databas problem. we did also experi with some non boolean problem. we consid onli two class (posit/neg)  problem, taken from the uci"s learn problem databas[3]. in all these problem, exampl ar describ as a  vector of coupl (attribut, valu). the valu domain can be either boolean, numer (wholli order set), or  nomin (non-order set). an adequ set of atom a must be constitut for each problem. for instanc, if a is a numer attribut, we defin at most k threshold si, give k+1  interv of uniform densiti4 . therefor, each distinct threshold si give two atom a ≤ si and a > si. in our experi, we took a maxim number of threshold k = 8. for instanc, in the iono problem case, there were 34 numer attribut, and an instanc is describ with 506 atom. below ar given the accuraci result of our system along with previou result. the column nb ex. refer to the 4 the probabl for the valu of a to be in ani interv is constant the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) 169 number of exampl us for learn5 . column (1)  repres minim and maxim accuraci valu for the thirti three classifi test in [8]. column (2) repres the  result of [13], where variou learn method ar compar to ensembl learn method us weight classifi set. column s-1 and s-10 give the accuraci of smile with  respect 1 and 10 agent. pb nb ex. (1) (2) s-1 s-10 ttt 862/574 // 76.2-99.7 99.7 99.9 kr-vs-kp 2876/958 // 91.4-99.4 96.8 97.3 iono 315 // 88.0-91.8 87.2 88.1 bupa 310 57-72 58-69.3 62.5 63.3 breastw 614 91-97 94.3-97.3 94.7 94.7 vote 391 94-96 95.3-96 91.9 92.6 pima 691 // 71.5- 73.4 65.0 65.0 heart 243 66-86 77.1-84.1 69.5 70.7 thi tabl show that the increment algorithm  correspond to the singl agent case, give honor result rel to non-increment classic method us larger and more complex hypothes. in some case, there is an  accuraci improv with a 10 agent ma. howev, with such benchmark data, which ar often noisi, the difficulti doe not realli come from the wai in which the search space is explor, and therefor the improv observ is not alwai signific. the same kind of phenomenon have been observ with method dedic to hard boolean problem [4]. 4.2 ma synchron here we consid that n singl agent learn without  interact and at a given time start interact thu form a ma. the purpos is to observ how the agent take  advantag of collabor when thei start from differ state of belief and memori. we compar in thi section a 1-ma, a 10-ma (ref) and a 10-ma (100sync) whose agent did not commun dure the arriv of the first 100  exampl (10 by agent). the three accuraci curv ar shown in figur 5. by compar the singl agent curv and the  synchron 10-ma, we can observ that after the begin of the synchron, that is at 125 exampl, accuraci ar ident. thi wa expect sinc as soon as an exampl e receiv by the ma contradict the current hypothesi of the agent ra receiv it, thi agent make an updat and it new hypothesi is propos to the other agent for critic. therefor, thi first contradictori exampl bring the ma to reach consist rel to the whole set of exampl present in agent" memori. a higher accuraci,  correspond to a 10-ma is obtain later, from the 175th exampl. in other word, the benefit of a better explor of the research space is obtain slightli later in the learn  process. note that thi synchron happen natur in all situat where agent have, for some reason, a diverg between their hypothesi and the system memori. thi  includ the fusion of two ma into a singl on or the arriv of new agent in an exist ma. 4.3 experi on asynchron learn: the effect of a larg data stream 5 for ttt and kr-vs-kp, our protocol did not us more than  respect 574 and 958 learn exampl, so we put anoth number in the column. figur 5: accuraci of a 1-ma, a 10-ma, and a 10-ma synchron after 100 exampl. in thi experi we relax our slow learn mode: the exampl ar sent at a given rate to the ma. the  result exampl stream is measur in ms−1 , and repres the number of exampl sent to the ma each ms.  whenev the stream is too larg, the ma cannot reach ma consist on recept of an exampl from the  environ befor a new exampl arriv. thi mean that the updat process, start by agent r0 as he receiv an  exampl, mai be unfinish when a new exampl is receiv by r0 or anoth agent r1. as a result, a critic agent mai have at instant t to send counterexampl of hypothes sent by variou agent. howev as far as the agent, in our  set, memor all the exampl thei receiv whenev the stream end, the ma necessarili reach ma consist with respect to all the exampl receiv so far. in our  experi, though it learn curv is slow down dure the intens learn phase (correspond to low accuraci of the current hypothes), the ma still reach a satisfi hypothesi later on as there ar less and less  counterexampl in the exampl stream. in figur 6 we compar the accuraci of two 11-ma respect submit to  exampl stream of differ rate when learn the m11 formula. the learn curv of the ma receiv an exampl at a 1/33 ms−1 rate is almost not alter (see figur 4) wherea the 1/16 ms−1 ma is first sever slow down befor catch up with the first on. 5. relat work sinc 96 [15], variou work have been perform on  learn in ma, but rather few on concept learn. in [11] the ma perform a form of ensembl learn in which the agent ar lazi learner (no explicit represent is  maintain) and sell useless exampl to other agent. in [10] each agent observ all the exampl but onli perceiv a part of their represent. in mutual onlin concept  learn [14] the agent converg to a uniqu hypothesi, but each agent produc exampl from it own concept  represent, thu result in a kind of synchron rather than in pure concept learn. 170 the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) figur 6: accuraci of two asynchron 11-ma (1/33ms−1 and 1/16ms−1 exampl rate) . 6. conclus we have present here and experi a protocol for ma onlin concept learn. the main featur of thi  collabor learn mechan is that it maintain a  consist properti: though dure the learn process each agent onli receiv and store, with some limit  redund, part of the exampl receiv by the ma, at ani moment the current hypothesi is consist with the whole set of exampl. the hypothes of our experi do not address the issu of distribut ma such as fault (for  instanc messag could be lost or corrupt) or other failur in gener (crash, byzantin fault, etc.). nevertheless, our framework is open, i.e., the agent can leav the system or enter it while the consist mechan is preserv. for instanc if we introduc a timeout mechan, even when a critic agent crash or omit to answer, the consist with the other critic (within the remain agent) is  entail. in [1], a similar approach ha been appli to ma abduct problem: the hypothes to maintain, given an incomplet inform, ar then fact or statement.  further work concern first coupl induct and abduct in order to perform collabor concept learn when  exampl ar onli partial observ by each agent, and second, investig partial memori learn: how learn is  preserv whenev on agent or the whole ma forget some select exampl. aknowledg we ar veri grate to dominiqu bouthinon for  implement late modif in smile, so much eas our experi. part of thi work ha been perform dure the first author"s visit to the ateli de bioinformatiqu of pari vi univers, franc. 7. refer [1] g. bourgn, n. maudet, and s. pinson. when agent commun hypothes in critic situat. in dalt-2006, mai 2006. [2] w. w. cohen. fast effect rule induct. in icml, page 115-123, 1995. [3] c. b. d.j. newman, s. hettich and c. merz. uci repositori of machin learn databas, 1998. [4] s. esmeir and s. markovitch. lookahead-base algorithm for anytim induct of decis tree. in icml"o4, page 257-264. morgan kaufmann, 2004. [5] j. f¨urnkranz. a patholog of bottom-up hill-climb in induct rule learn. in alt, volum 2533 of lnc, page 263-277. springer, 2002. [6] a. guerra-hern´andez, a. elfallah-seghrouchni, and h. soldano. learn in bdi multi-agent system. in clima iv, volum 3259, page 218-233. springer verlag, 2004. [7] m. hennich. mgi: an increment bottom-up algorithm. in ieee aust. and new zealand confer on intellig inform system, page 347-351, 1994. [8] t.-s. lim, w.-y. loh, and y.-s. shih. a comparison of predict accuraci, complex, and train time of thirti-three old and new classif algorithm. machin learn, 40(3):203-228, 2000. [9] m. a. maloof and r. s. michalski. increment learn with partial instanc memori. artif. intel., 154(1-2):95-126, 2004. [10] p. j. modi and w.-m. shen. collabor multiag learn for classif task. in agent "01, page 37-38. acm press, 2001. [11] s. onta˜non and e. plaza. recycl data for multi-agent learn. in icml "05, page 633-640. acm press, 2005. [12] j. r. quinlan. induct of decis tree. machin learn, 1(1):81-106, 1986. [13] u. r¨uckert and s. kramer. toward tight bound for rule learn. in icml "04 (intern confer on machin learn), page 90, new york, ny, usa, 2004. acm press. [14] j. wang and l. gasser. mutual onlin concept learn for multipl agent. in aama, page 362-369. acm press, 2002. [15] g. weiß and s. sen, editor. adapt and learn in multi-agent system, volum 1042 of lectur note in comput scienc. springer, 1996. [16] i. h. witten and e. frank. data mine: practic machin learn tool and techniqu with java implement. morgan kaufmann, octob 1999. the sixth intl. joint conf. on autonom agent and multi-agent system (aama 07) 171 