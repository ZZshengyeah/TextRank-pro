the impact of cach on search engin ricardo baeza-yate1 rbaeza@acm.org aristid gioni1 gioni@yahoo-inc.com flavio junqueira1 fpj@yahoo-inc.com vanessa murdock1 vmurdock@yahoo-inc.com vassili plachoura1 vassili@yahoo-inc.com fabrizio silvestri2 f.silvestri@isti.cnr.it 1 yahoo! research barcelona 2 isti - cnr barcelona, spain pisa, itali abstract in thi paper we studi the trade-off in design effici cach system for web search engin. we explor the impact of differ approach, such as static vs. dynam cach, and cach queri result vs. cach post list. us a queri log span a whole year we explor the  limit of cach and we demonstr that cach post list can achiev higher hit rate than cach queri  answer. we propos a new algorithm for static cach of post list, which outperform previou method. we also studi the problem of find the optim wai to split the static cach between answer and post list. final, we measur how the chang in the queri log affect the  effect of static cach, given our observ that the distribut of the queri chang slowli over time. our result and observ ar applic to differ level of the data-access hierarchi, for instanc, for a memori/disk layer or a broker/remot server layer. categori and subject descriptor h.3.3 [inform storag and retriev]: inform search and retriev - search process; h.3.4 [inform storag and retriev]: system and softwar -  distribut system, perform evalu (effici and  effect) gener term algorithm, experiment 1. introduct million of queri ar submit daili to web search  engin, and user have high expect of the qualiti and speed of the answer. as the searchabl web becom larger and larger, with more than 20 billion page to index,  evalu a singl queri requir process larg amount of data. in such a set, to achiev a fast respons time and to increas the queri throughput, us a cach is crucial. the primari us of a cach memori is to speedup  comput by exploit frequent or recent us data,  although reduc the workload to back-end server is also a major goal. cach can be appli at differ level with increas respons latenc or process requir. for exampl, the differ level mai correspond to the main memori, the disk, or resourc in a local or a wide area network. the decis of what to cach is either off-line (static) or onlin (dynam). a static cach is base on histor inform and is period updat. a dynam cach replac entri accord to the sequenc of request. when a new request arriv, the cach system decid whether to evict some entri from the cach in the case of a cach miss. such onlin decis ar base on a cach polici, and sever differ polici have been studi in the past. for a search engin, there ar two possibl wai to us a cach memori: cach answer: as the engin return answer to a  particular queri, it mai decid to store these answer to resolv futur queri. cach term: as the engin evalu a particular queri, it mai decid to store in memori the post list of the involv queri term. often the whole set of  post list doe not fit in memori, and consequ, the engin ha to select a small set to keep in memori and speed up queri process. return an answer to a queri that alreadi exist in the cach is more effici than comput the answer us cach post list. on the other hand, previous unseen queri occur more often than previous unseen term,  impli a higher miss rate for cach answer. cach of post list ha addit challeng. as post list have variabl size, cach them dynam is not veri effici, due to the complex in term of  effici and space, and the skew distribut of the queri stream, as shown later. static cach of post list pose even more challeng: when decid which term to cach on face the trade-off between frequent queri term and term with small post list that ar space effici.  final, befor decid to adopt a static cach polici the queri stream should be analyz to verifi that it  characterist do not chang rapidli over time. broker static cach post list dynam/static cach answer local queri processor disk next cach level local network access remot network access figur 1: on cach level in a distribut search architectur. in thi paper we explor the trade-off in the design of each cach level, show that the problem is the same and onli a few paramet chang. in gener, we assum that each level of cach in a distribut search architectur is similar to that shown in figur 1. we us a queri log span a whole year to explor the limit of dynam cach queri answer or post list for queri term. more concret, our main conclus ar that: • cach queri answer result in lower hit ratio  compar to cach of post list for queri term, but it is faster becaus there is no need for queri  evalu. we provid a framework for the analysi of the trade-off between static cach of queri answer and post list; • static cach of term can be more effect than  dynam cach with, for exampl, lru. we provid algorithm base on the knapsack problem for  select the post list to put in a static cach, and we show improv over previou work, achiev a hit ratio over 90%; • chang of the queri distribut over time have littl impact on static cach. the remaind of thi paper is organ as follow.  section 2 and 3 summar relat work and character the data set we us. section 4 discuss the limit of  dynam cach. section 5 and 6 introduc algorithm for cach post list, and a theoret framework for the analysi of static cach, respect. section 7 discuss the impact of chang in the queri distribut on static cach, and section 8 provid conclud remark. 2. relat work there is a larg bodi of work devot to queri  optim. bucklei and lewit [3], in on of the earliest work, take a term-at-a-time approach to decid when invert list need not be further examin. more recent exampl demonstr that the top k document for a queri can be return without the need for evalu the complet set of post list [1, 4, 15]. although these approach seek to improv queri process effici, thei differ from our  current work in that thei do not consid cach. thei mai be consid separ and complementari to a cach-base approach. raghavan and sever [12], in on of the first paper on  exploit user queri histori, propos us a queri base, built upon a set of persist optim queri submit in the past, to improv the retriev effect for similar futur queri. markato [10] show the exist of tempor  local in queri, and compar the perform of differ cach polici. base on the observ of markato, lempel and moran propos a new cach polici, call probabilist driven cach, by attempt to estim the probabl distribut of all possibl queri submit to a search engin [8]. fagni et al. follow markato" work by show that combin static and dynam cach polici togeth with an adapt prefetch polici achiev a high hit ratio [7]. differ from our work, thei consid cach and prefetch of page of result. as system ar often hierarch, there ha also been some effort on multi-level architectur. saraiva et al. propos a new architectur for web search engin us a two-level dynam cach system [13]. their goal for such system ha been to improv respons time for hierarch engin. in their architectur, both level us an lru evict  polici. thei find that the second-level cach can effect reduc disk traffic, thu increas the overal throughput. baeza-yate and saint-jean propos a three-level index  organ [2]. long and suel propos a cach system structur accord to three differ level [9]. the  intermedi level contain frequent occur pair of term and store the intersect of the correspond invert list. these last two paper ar relat to our in that thei exploit differ cach strategi at differ level of the memori hierarchi. final, our static cach algorithm for post list in section 5 us the ratio frequenc/size in order to evalu the good of an item to cach. similar idea have been us in the context of file cach [17], web cach [5], and even cach of post list [9], but in all case in a dynam set. to the best of our knowledg we ar the first to us thi approach for static cach of post list. 3. data character our data consist of a crawl of document from the uk domain, and queri log of on year of queri submit to http://www.yahoo.co.uk from novemb 2005 to novemb 2006. in our log, 50% of the total volum of queri ar uniqu. the averag queri length is 2.5 term, with the longest queri have 731 term. 1e-07 1e-06 1e-05 1e-04 0.001 0.01 0.1 1 1e-08 1e-07 1e-06 1e-05 1e-04 0.001 0.01 0.1 1 frequenc(normal) frequenc rank (normal) figur 2: the distribut of queri (bottom curv) and queri term (middl curv) in the queri log. the distribut of document frequenc of term in the uk-2006 dataset (upper curv). figur 2 show the distribut of queri (lower curv), and queri term (middl curv). the x-axi repres the normal frequenc rank of the queri or term. (the most frequent queri appear closest to the y-axi.) the y-axi is tabl 1: statist of the uk-2006 sampl. uk-2006 sampl statist # of document 2,786,391 # of term 6,491,374 # of token 2,109,512,558 the normal frequenc for a given queri (or term). as  expect, the distribut of queri frequenc and queri term frequenc follow power law distribut, with slope of 1.84 and 2.26, respect. in thi figur, the queri frequenc were comput as thei appear in the log with no  normal for case or white space. the queri term (middl curv) have been normal for case, as have the term in the document collect. the document collect that we us for our experi is a summari of the uk domain crawl in mai 2006.1 thi summari correspond to a maximum of 400 crawl  document per host, us a breadth first crawl strategi,  compris 15gb. the distribut of document frequenc of term in the collect follow a power law distribut with slope 2.38 (upper curv in figur 2). the statist of the collect ar shown in tabl 1. we measur the correl between the document frequenc of term in the collect and the number of queri that contain a particular term in the queri log to be 0.424. a scatter plot for a random  sampl of term is shown in figur 3. in thi experi, term have been convert to lower case in both the queri and the document so that the frequenc will be compar. 1e-07 1e-06 1e-05 1e-04 0.001 0.01 0.1 1 1e-06 1e-05 1e-04 0.001 0.01 0.1 1 queryfrequ document frequenc figur 3: normal scatter plot of document-term frequenc vs. queri-term frequenc. 4. cach of queri and term cach reli upon the assumpt that there is local in the stream of request. that is, there must be suffici repetit in the stream of request and within interv of time that enabl a cach memori of reason size to be effect. in the queri log we us, 88% of the uniqu queri ar singleton queri, and 44% ar singleton queri out of the whole volum. thu, out of all queri in the stream compos the queri log, the upper threshold on hit ratio is 56%. thi is becaus onli 56% of all the queri compris queri that have multipl occurr. it is import to observ, howev, that not all queri in thi 56% can be cach hit becaus of compulsori miss. a compulsori miss 1 the collect is avail from the univers of milan: http://law.dsi.unimi.it/. url retriev 05/2007. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 240 260 280 300 320 340 360 numberofel bin number total term term diff total queri uniqu queri uniqu term queri diff figur 4: arriv rate for both term and queri. happen when the cach receiv a queri for the first time. thi is differ from capac miss, which happen due to space constraint on the amount of memori the cach us. if we consid a cach with infinit memori, then the hit ratio is 50%. note that for an infinit cach there ar no capac miss. as we mention befor, anoth possibl is to cach the post list of term. intuit, thi give more freedom in the util of the cach content to respond to queri becaus cach term might form a new queri. on the other hand, thei need more space. as oppos to queri, the fraction of singleton term in the total volum of term is smaller. in our queri log, onli 4% of the term appear onc, but thi account for 73% of the vocabulari of queri term. we show in section 5 that cach a small fraction of term, while account for term appear in mani document, is potenti veri effect. figur 4 show sever graph correspond to the  normal arriv rate for differ case us dai as bin. that is, we plot the normal number of element that appear in a dai. thi graph show onli a period of 122 dai, and we normal the valu by the maximum valu observ throughout the whole period of the queri log.  total queri and total term correspond to the total  volum of queri and term, respect. uniqu queri and uniqu term correspond to the arriv rate of uniqu queri and term. final, queri diff and term diff correspond to the differ between the curv for total and uniqu. in figur 4, as expect, the volum of term is much higher than the volum of queri. the differ between the total number of term and the number of uniqu term is much larger than the differ between the total number of queri and the number of uniqu queri. thi observ impli that term repeat significantli more than queri. if we us smaller bin, sai of on hour, then the ratio of uniqu to volum is higher for both term and queri becaus it leav less room for repetit. we also estim the workload us the document  frequenc of term as a measur of how much work a queri impos on a search engin. we found that it follow close the arriv rate for term shown in figur 4. to demonstr the effect of a dynam cach on the queri frequenc distribut of figur 2, we plot the same  frequenc graph, but now consid the frequenc of queri figur 5: frequenc graph after lru cach. after go through an lru cach. on a cach miss, an lru cach decid upon an entri to evict us the  inform on the recenc of queri. in thi graph, the most frequent queri ar not the same queri that were most frequent befor the cach. it is possibl that queri that ar most frequent after the cach have differ  characterist, and tune the search engin to queri frequent befor the cach mai degrad perform for non-cach queri. the maximum frequenc after cach is less than 1% of the maximum frequenc befor the cach, thu show that the cach is veri effect in reduc the load of frequent queri. if we re-rank the queri accord to after-cach frequenc, the distribut is still a power law, but with a much smaller valu for the highest frequenc. when discuss the effect of dynam cach, an import metric is cach miss rate. to analyz the cach miss rate for differ memori constraint, we us the  work set model [6, 14]. a work set, inform, is the set of refer that an applic or an oper system is current work with. the model us such set in a  strategi that tri to captur the tempor local of refer. the work set strategi then consist in keep in memori onli the element that ar referenc in the previou θ step of the input sequenc, where θ is a configur paramet correspond to the window size. origin, work set have been us for page  replac algorithm of oper system, and consid such a strategi in the context of search engin is interest for three reason. first, it captur the amount of local of queri and term in a sequenc of queri. local in thi case refer to the frequenc of queri and term in a window of time. if mani queri appear multipl time in a window, then local is high. second, it enabl an oﬄin analysi of the expect miss rate given differ memori constraint. third, work set captur aspect of effici cach  algorithm such as lru. lru assum that refer farther in the past ar less like to be referenc in the present, which is implicit in the concept of work set [14]. figur 6 plot the miss rate for differ work set size, and we consid work set of both queri and term. the work set size ar normal against the total number of queri in the queri log. in the graph for queri, there is a sharp decai until approxim 0.01, and the rate at which the miss rate drop decreas as we increas the size of the work set over 0.01. final, the minimum valu it reach is 50% miss rate, not shown in the figur as we have cut the tail of the curv for present purpos. 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.05 0.1 0.15 0.2 missrat normal work set size queri term figur 6: miss rate as a function of the work set size. 1 10 100 1000 10000 100000 1e+06 frequenc distanc figur 7: distribut of distanc express in term of distinct queri. compar to the queri curv, we observ that the  minimum miss rate for term is substanti smaller. the miss rate also drop sharpli on valu up to 0.01, and it decreas minim for higher valu. the minimum valu, howev, is slightli over 10%, which is much smaller than the  minimum valu for the sequenc of queri. thi impli that with such a polici it is possibl to achiev over 80% hit rate, if we consid cach dynam post list for term as oppos to cach answer for queri. thi result doe not consid the space requir for each unit store in the cach memori, or the amount of time it take to put  togeth a respons to a user queri. we analyz these issu more carefulli later in thi paper. it is interest also to observ the histogram of figur 7, which is an intermedi step in the comput of the miss rate graph. it report the distribut of distanc between repetit of the same frequent queri. the distanc in the plot is measur in the number of distinct queri  separ a queri and it repetit, and it consid onli queri appear at least 10 time. from figur 6 and 7, we  conclud that even if we set the size of the queri answer cach to a rel larg number of entri, the miss rate is high. thu, cach the post list of term ha the potenti to improv the hit ratio. thi is what we explor next. 5. cach post list the previou section show that cach post list can obtain a higher hit rate compar to cach queri answer. in thi section we studi the problem of how to select  post list to place on a certain amount of avail memori, assum that the whole index is larger than the amount of memori avail. the post list have variabl size (in fact, their size distribut follow a power law), so it is  benefici for a cach polici to consid the size of the post list. we consid both dynam and static cach. for  dynam cach, we us two well-known polici, lru and lfu, as well as a modifi algorithm that take post-list size into account. befor discuss the static cach strategi, we  introduc some notat. we us fq(t) to denot the queri-term frequenc of a term t, that is, the number of queri  contain t in the queri log, and fd(t) to denot the document frequenc of t, that is, the number of document in the  collect in which the term t appear. the first strategi we consid is the algorithm propos by baeza-yate and saint-jean [2], which consist in select the post list of the term with the highest queri-term frequenc fq(t). we call thi algorithm qtf. we observ that there is a trade-off between fq(t) and fd(t). term with high fq(t) ar us to keep in the cach becaus thei ar queri often. on the other hand, term with high fd(t) ar not good candid becaus thei  correspond to long post list and consum a substanti amount of space. in fact, the problem of select the best post list for the static cach correspond to the  standard knapsack problem: given a knapsack of fix  capac, and a set of n item, such as the i-th item ha valu ci and size si, select the set of item that fit in the knapsack and maxim the overal valu. in our case, valu  correspond to fq(t) and size correspond to fd(t). thu, we emploi a simpl algorithm for the knapsack problem, which is select the post list of the term with the highest valu of the ratio fq(t) fd(t) . we call thi algorithm qtfdf. we tri other variat consid queri frequenc instead of term frequenc, but the gain wa minim compar to the complex ad. in addit to the abov two static algorithm we consid the follow algorithm for dynam cach: • lru: a standard lru algorithm, but mani post list might need to be evict (in order of least-recent usag) until there is enough space in the memori to place the current access post list; • lfu: a standard lfu algorithm (evict of the  leastfrequ us), with the same modif as the lru; • dyn-qtfdf: a dynam version of the qtfdf  algorithm; evict from the cach the term(s) with the lowest fq(t) fd(t) ratio. the perform of all the abov algorithm for 15 week of the queri log and the uk dataset ar shown in figur 8. perform is measur with hit rate. the cach size is measur as a fraction of the total space requir to store the post list of all term. for the dynam algorithm, we load the cach with term in order of fq(t) and we let the cach warm up for 1  million queri. for the static algorithm, we assum complet knowledg of the frequenc fq(t), that is, we estim fq(t) from the whole queri stream. as we show in section 7 the result do not chang much if we comput the queri-term frequenc us the first 3 or 4 week of the queri log and measur the hit rate on the rest. 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 hitrat cach size cach post list static qtf/df lru lfu dyn-qtf/df qtf figur 8: hit rate of differ strategi for cach post list. the most import observ from our experi is that the static qtfdf algorithm ha a better hit rate than all the dynam algorithm. an import benefit a static cach is that it requir no evict and it is henc more effici when evalu queri. howev, if the  characterist of the queri traffic chang frequent over time, then it requir re-popul the cach often or there will be a signific impact on hit rate. 6. analysi of static cach in thi section we provid a detail analysi for the  problem of decid whether it is prefer to cach queri  answer or cach post list. our analysi take into account the impact of cach between two level of the data-access hierarchi. it can either be appli at the memori/disk layer or at a server/remot server layer as in the architectur we discuss in the introduct. us a particular system model, we obtain estim for the paramet requir by our analysi, which we  subsequ us to decid the optim trade-off between cach queri answer and cach post list. 6.1 analyt model let m be the size of the cach measur in answer unit (the cach can store m queri answer). assum that all post list ar of the same length l, measur in answer unit. we consid the follow two case: (a) a cach that store onli precomput answer, and (b) a cach that store onli post list. in the first case, nc = m answer fit in the cach, while in the second case np = m/l post list fit in the cach. thu, np = nc/l. note that although post list requir more space, we can combin term to evalu more queri (or partial queri). for case (a), suppos that a queri answer in the cach can be evalu in 1 time unit. for case (b), assum that if the post list of the term of a queri ar in the cach then the result can be comput in tr1 time unit, while if the post list ar not in the cach then the result can be comput in tr2 time unit. of cours tr2 > tr1. now we want to compar the time to answer a stream of q queri in both case. let vc(nc) be the volum of the most frequent nc queri. then, for case (a), we have an overal time tca = vc(nc) + tr2(q − vc(nc)). similarli, for case (b), let vp(np) be the number of  comput queri. then we have overal time tp l = tr1vp(np) + tr2(q − vp(np)). we want to check under which condit we have tp l < tca. we have tp l − tca = (tr2 − 1)vc(nc) − (tr2 − tr1)vp(np) > 0. figur 9 show the valu of vp and vc for our data. we can see that cach answer satur faster and for thi  particular data there is no addit benefit from us more than 10% of the index space for cach answer. as the queri distribut is a power law with paramet α > 1, the i-th most frequent queri appear with probabl proport to 1 iα . therefor, the volum vc(n), which is the total number of the n most frequent queri, is vc(n) = v0 n i=1 q iα = γnq (0 < γn < 1). we know that vp(n) grow faster than vc(n) and assum, base on experiment result, that the relat is of the form vp(n) = k vc(n)β . in the worst case, for a larg cach, β → 1. that is, both techniqu will cach a constant fraction of the overal queri volum. then cach post list make sens onli if l(tr2 − 1) k(tr2 − tr1) > 1. if we us compress, we have l < l and tr1 > tr1.  accord to the experi that we show later, compress is alwai better. for a small cach, we ar interest in the transient  behavior and then β > 1, as comput from our data. in thi case there will alwai be a point where tp l > tca for a larg number of queri. in realiti, instead of fill the cach onli with answer or onli with post list, a better strategi will be to divid the total cach space into cach for answer and cach for post list. in such a case, there will be some queri that could be answer by both part of the cach. as the answer cach is faster, it will be the first choic for answer those queri. let qnc and qnp be the set of queri that can be answer by the cach answer and the cach post list, respect. then, the overal time is t = vc(nc)+tr1v (qnp −qnc )+tr2(q−v (qnp ∪qnc )), where np = (m − nc)/l. find the optim divis of the cach in order to minim the overal retriev time is a difficult problem to solv analyt. in section 6.3 we us simul to deriv optim cach trade-off for particular implement exampl. 6.2 paramet estim we now us a particular implement of a central system and the model of a distribut system as exampl from which we estim the paramet of the analysi from the previou section. we perform the experi us an optim version of terrier [11] for both index  document and process queri, on a singl machin with a pentium 4 at 2ghz and 1gb of ram. we index the document from the uk-2006 dataset, without remov stop word or appli stem. the post list in the invert file consist of pair of  document identifi and term frequenc. we compress the  document identifi gap us elia gamma encod, and the 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 queryvolum space precomput answer post list figur 9: cach satur as a function of size. tabl 2: ratio between the averag time to  evalu a queri and the averag time to return cach answer (central and distribut case). central system tr1 tr2 tr1 tr2 full evalu 233 1760 707 1140 partial evalu 99 1626 493 798 lan system trl 1 trl 2 tr l 1 tr l 2 full evalu 242 1769 716 1149 partial evalu 108 1635 502 807 wan system trw 1 trw 2 tr w 1 tr w 2 full evalu 5001 6528 5475 5908 partial evalu 4867 6394 5270 5575 term frequenc in document us unari encod [16]. the size of the invert file is 1,189mb. a store answer requir 1264 byte, and an uncompress post take 8 byte. from tabl 1, we obtain l = (8·# of post) 1264·# of term = 0.75 and l = invert file size 1264·# of term = 0.26. we estim the ratio tr = t/tc between the averag time t it take to evalu a queri and the averag time tc it take to return a store answer for the same queri, in the follow wai. tc is measur by load the answer for 100,000 queri in memori, and answer the queri from memori. the averag time is tc = 0.069ms. t is measur by process the same 100,000 queri (the first 10,000 queri ar us to warm-up the system). for each queri, we remov stop word, if there ar at least three  remain term. the stop word correspond to the term with a frequenc higher than the number of document in the index. we us a document-at-a-time approach to  retriev document contain all queri term. the onli disk access requir dure queri process is for read  compress post list from the invert file. we perform both full and partial evalu of answer, becaus some queri ar like to retriev a larg number of document, and onli a fraction of the retriev document will be seen by user. in the partial evalu of queri, we termin the  process after match 10,000 document. the estim ratio tr ar present in tabl 2. figur 10 show for a sampl of queri the workload of the system with partial queri evalu and compress post list. the x-axi correspond to the total time the system spend process a particular queri, and the  vertic axi correspond to the sum t∈q fq · fd(t). notic that the total number of post of the queri-term doe not necessarili provid an accur estim of the workload impos on the system by a queri (which is the case for full evalu and uncompress list). 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 totalpostingstoprocessqueri(normal) total time to process queri (normal) partial process of compress post queri len = 1 queri len in [2,3] queri len in [4,8] queri len > 8 figur 10: workload for partial queri evalu with compress post list. the analysi of the previou section also appli to a  distribut retriev system in on or multipl site. suppos that a document partit distribut system is run on a cluster of machin interconnect with a local area network (lan) in on site. the broker receiv queri and broadcast them to the queri processor, which answer the queri and return the result to the broker. final, the broker merg the receiv answer and gener the final set of answer (we assum that the time spent on  merg result is neglig). the differ between the  central architectur and the document partit  architectur is the extra commun between the broker and the queri processor. us icmp ping on a 100mbp lan, we have measur that send the queri from the broker to the queri processor which send an answer of 4,000 byte back to the broker take on averag 0.615ms. henc, trl = tr + 0.615ms/0.069ms = tr + 9. in the case when the broker and the queri processor ar in differ site connect with a wide area network (wan), we estim that broadcast the queri from the broker to the queri processor and get back an answer of 4,000 byte take on averag 329ms. henc, trw = tr + 329ms/0.069ms = tr + 4768. 6.3 simul result we now address the problem of find the optim  tradeoff between cach queri answer and cach post list. to make the problem concret we assum a fix budget m on the avail memori, out of which x unit ar us for cach queri answer and m − x for cach post list. we perform simul and comput the averag respons time as a function of x. us a part of the queri log as train data, we first alloc in the cach the answer to the most frequent queri that fit in space x, and then we us the rest of the memori to cach post list. for  select post list we us the qtfdf algorithm, appli to the train queri log but exclud the queri that have alreadi been cach. in figur 11, we plot the simul respons time for a central system as a function of x. for the uncompress index we us m = 1gb, and for the compress index we us m = 0.5gb. in the case of the configur that us partial queri evalu with compress post list, the lowest respons time is achiev when 0.15gb out of the 0.5gb is alloc for store answer for queri. we  obtain similar trend in the result for the lan set. figur 12 show the simul workload for a distribut system across a wan. in thi case, the total amount of memori is split between the broker, which hold the cach 400 500 600 700 800 900 1000 1100 1200 0 0.2 0.4 0.6 0.8 1 averageresponsetim space (gb) simul workload -- singl machin full / uncompr / 1 g partial / uncompr / 1 g full / compr / 0.5 g partial / compr / 0.5 g figur 11: optim divis of the cach in a server. 3000 3500 4000 4500 5000 5500 6000 0 0.2 0.4 0.6 0.8 1 averageresponsetim space (gb) simul workload -- wan full / uncompr / 1 g partial / uncompr / 1 g full / compr / 0.5 g partial / compr / 0.5 g figur 12: optim divis of the cach when the next level requir wan access. answer of queri, and the queri processor, which hold the cach of post list. accord to the figur, the  differ between the configur of the queri processor is less import becaus the network commun  overhead increas the respons time substanti. when us uncompress post list, the optim alloc of  memori correspond to us approxim 70% of the memori for cach queri answer. thi is explain by the fact that there is no need for network commun when the queri can be answer by the cach at the broker. 7. effect of the queri dynam for our queri log, the queri distribut and queri-term distribut chang slowli over time. to support thi claim, we first assess how topic chang compar the distribut of queri from the first week in june, 2006, to the  distribut of queri for the remaind of 2006 that did not appear in the first week in june. we found that a veri small  percentag of queri ar new queri. the major of queri that appear in a given week repeat in the follow week for the next six month. we then comput the hit rate of a static cach of 128, 000 answer train over a period of two week (figur 13). we report hit rate hourli for 7 dai, start from 5pm. we observ that the hit rate reach it highest valu dure the night (around midnight), wherea around 2-3pm it reach it minimum. after a small decai in hit rate valu, the hit rate stabil between 0.28, and 0.34 for the entir week, suggest that the static cach is effect for a whole week after the train period. 0.26 0.27 0.28 0.29 0.3 0.31 0.32 0.33 0.34 0.35 0.36 0.37 0 20 40 60 80 100 120 140 160 hit-rate time hit on the frequent queri of distanc figur 13: hourli hit rate for a static cach hold 128,000 answer dure the period of a week. the static cach of post list can be period  recomput. to estim the time interv in which we need to recomput the post list on the static cach we need to consid an effici/qualiti trade-off: us too short a time interv might be prohibit expens, while  recomput the cach too infrequ might lead to have an obsolet cach not correspond to the statist  characterist of the current queri stream. we measur the effect on the qtfdf algorithm of the chang in a 15-week queri stream (figur 14). we comput the queri term frequenc over the whole stream, select which term to cach, and then comput the hit rate on the whole queri stream. thi hit rate is as an upper bound, and it assum perfect knowledg of the queri term frequenc. to simul a realist scenario, we us the first 6 (3) week of the queri stream for comput queri term frequenc and the follow 9 (12) week to estim the hit rate. as figur 14 show, the hit rate decreas by less than 2%. the high correl among the queri term frequenc dure differ time period explain the grace adapt of the static cach algorithm to the futur queri stream. inde, the pairwis correl among all possibl 3-week period of the 15-week queri stream is over 99.5%. 8. conclus cach is an effect techniqu in search engin for improv respons time, reduc the load on queri  processor, and improv network bandwidth util. we present result on both dynam and static cach.  dynam cach of queri ha limit effect due to the high number of compulsori miss caus by the number of uniqu or infrequ queri. our result show that in our uk log, the minimum miss rate is 50% us a work set strategi. cach term is more effect with respect to miss rate, achiev valu as low as 12%. we also propos a new algorithm for static cach of post list that  outperform previou static cach algorithm as well as dynam algorithm such as lru and lfu, obtain hit rate valu that ar over 10% higher compar these strategi. we present a framework for the analysi of the trade-off between cach queri result and cach post list, and we simul differ type of architectur. our result show that for central and lan environ, there is an optim alloc of cach queri result and cach of post list, while for wan scenario in which network time prevail it is more import to cach queri result. 0.45 0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 0.1 0.2 0.3 0.4 0.5 0.6 0.7 hitrat cach size dynam of static qtf/df cach polici perfect knowledg 6-week train 3-week train figur 14: impact of distribut chang on the static cach of post list. 9. refer [1] v. n. anh and a. moffat. prune queri evalu us pre-comput impact. in acm cikm, 2006. [2] r. a. baeza-yate and f. saint-jean. a three level search engin index base in queri log distribut. in spire, 2003. [3] c. bucklei and a. f. lewit. optim of invert vector search. in acm sigir, 1985. [4] s. b¨uttcher and c. l. a. clark. a document-centric approach to static index prune in text retriev system. in acm cikm, 2006. [5] p. cao and s. irani. cost-awar www proxi cach algorithm. in usit, 1997. [6] p. den. work set past and present. ieee tran. on softwar engin, se-6(1):64-84, 1980. [7] t. fagni, r. perego, f. silvestri, and s. orlando. boost the perform of web search engin: cach and prefetch queri result by exploit histor usag data. acm tran. inf. syst., 24(1):51-78, 2006. [8] r. lempel and s. moran. predict cach and prefetch of queri result in search engin. in www, 2003. [9] x. long and t. suel. three-level cach for effici queri process in larg web search engin. in www, 2005. [10] e. p. markato. on cach search engin queri result. comput commun, 24(2):137-143, 2001. [11] i. ouni, g. amati, v. plachoura, b. he, c. macdonald, and c. lioma. terrier: a high perform and scalabl inform retriev platform. in sigir workshop on open sourc inform retriev, 2006. [12] v. v. raghavan and h. sever. on the reus of past optim queri. in acm sigir, 1995. [13] p. c. saraiva, e. s. de moura, n. ziviani, w. meira, r. fonseca, and b. riberio-neto. rank-preserv two-level cach for scalabl search engin. in acm sigir, 2001. [14] d. r. slutz and i. l. traiger. a note on the calcul of averag work set size. commun of the acm, 17(10):563-565, 1974. [15] t. strohman, h. turtl, and w. b. croft. optim strategi for complex queri. in acm sigir, 2005. [16] i. h. witten, t. c. bell, and a. moffat. manag gigabyt: compress and index document and imag. john wilei & son, inc., ny, 1994. [17] n. e. young. on-line file cach. algorithmica, 33(3):371-383, 2002. 