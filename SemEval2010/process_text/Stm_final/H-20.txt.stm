new event detect base on index-tree and name entiti zhang kuo tsinghua univers beij, 100084, china 86-10-62771736 zkuo99@mail.tsinghua.edu.cn li juan zi tsinghua univers beij, 100084, china 86-10-62781461 ljz@keg.cs.tsinghua.edu.cn wu gang tsinghua univers beij, 100084, china 86-10-62789831 wug03@keg.cs.tsinghua.edu.cn abstract new event detect (ned) aim at detect from on or multipl stream of new stori that which on is report on a new event (i.e. not report previous). with the overwhelm volum of new avail todai, there is an increas need for a ned system which is abl to detect new event more effici and accur. in thi paper we propos a new ned model to speed up the ned task by us new index-tree dynam. moreov, base on the observ that term of differ type have differ effect for ned task, two term reweight approach ar propos to improv ned accuraci. in the first approach, we propos to adjust term weight dynam base on previou stori cluster and in the second approach, we propos to emploi statist on train data to learn the name entiti reweight model for each class of stori. experiment result on two linguist data consortium (ldc) dataset tdt2 and tdt3 show that the propos model can improv both effici and accuraci of ned task significantli, compar to the baselin system and other exist system. categori and subject descriptor h.3.3 [inform system]: inform search and retriev; h.4.2 [inform system applic]: type of  systemsdecis support. gener term algorithm, perform, experiment 1. introduct topic detect and track (tdt) program aim to develop techniqu which can effect organ, search and structur new text materi from a varieti of newswir and broadcast media [1]. new event detect (ned) is on of the five task in tdt. it is the task of onlin identif of the earliest report for each topic as soon as that report arriv in the sequenc of document. a topic is defin as a semin event or activ, along with directli relat event and activ [2]. an event is defin as someth (non-trivial) happen in a certain place at a certain time [3]. for instanc, when a bomb explod in a build, the explod is the semin event that trigger the topic, and other stori on the same topic would be those discuss salvag effort, the search for perpetr, arrest and trial and so on. us new inform is usual buri in a mass of data gener everydai. therefor, ned system ar veri us for peopl who need to detect novel inform from real-time new stream. these real-life need often occur in domain like financi market, new analysi, and intellig gather. in most of state-of-the-art (current) ned system, each new stori on hand is compar to all the previou receiv stori. if all the similar between them do not exce a threshold, then the stori trigger a new event. thei ar usual in the form of cosin similar or helling similar metric. the core problem of ned is to identifi whether two stori ar on the same topic. obvious, these system cannot take advantag of topic inform. further more, it is not accept in real applic becaus of the larg amount of comput requir in the ned process. other system organ previou stori into cluster (each cluster correspond to a topic), and new stori is compar to the previou cluster instead of stori. thi manner can reduc compar time significantli. nevertheless, it ha been prove that thi manner is less accur [4, 5]. thi is becaus sometim stori within a topic drift far awai from each other, which could lead low similar between a stori and it topic. on the other hand, some propos ned system tri to improv accuraci by make better us of name entiti [10, 11, 12, 13]. howev, none of the system have consid that term of differ type (e.g. noun, verb or person name) have differ effect for differ class of stori in determin whether two stori ar on the same topic. for exampl, the name of elect candid (person name) ar veri import for stori of elect class; the locat (locat name) where accid happen ar import for stori of accid class. so, in ned, there still exist follow three problem to be investig: (1) how to speed up the detect procedur while do not decreas the detect accuraci? (2) how to make good us of cluster (topic) inform to improv accuraci? (3) how to obtain better new stori represent by better understand of name entiti. driven by these problem, we have propos three approach in thi paper. (1)to make the detect procedur faster, we propos a new ned procedur base on new index-tree creat dynam. stori index-tree is creat by assembl similar stori togeth to form new cluster in differ hierarchi accord to their valu of similar. comparison between current stori and previou cluster could help find the most similar stori in less compar time. the new procedur can reduc the amount of compar time without hurt accuraci. (2)we us the cluster of the first floor in the index-tree as new topic, in which term weight ar adjust dynam accord to term distribut in the cluster. in thi approach, cluster (topic) inform is us properli, so the problem of theme decentr is avoid. (3)base on observ on the statist obtain from train data, we found that term of differ type (e.g. noun and verb) have differ effect for differ class of stori in determin whether two stori ar on the same topic. and we propos to us statist to optim the weight of the term of differ type in a stori accord to the new class that the stori belong to. on tdt3 dataset, the new ned model just us 14.9% compar time of the basic model, while it minimum normal cost is 0.5012, which is 0.0797 better than the basic model, and also better than ani other result previous report for thi dataset [8, 13]. the rest of the paper is organ as follow. we start off thi paper by summar the previou work in ned in section 2. section 3 present the basic model for ned that most current system us. section 4 describ our new detect procedur base on new index-tree. in section 5, two term reweight method ar propos to improv ned accuraci. section 6 give our experiment data and evalu metric. we final wrap up with the experiment result in section 7, and the conclus and futur work in section 8. 2. relat work papka et al. propos singl-pass cluster on ned [6]. when a new stori wa encount, it wa process immedi to extract term featur and a queri represent of the stori"s content is built up. then it wa compar with all the previou queri. if the document did not trigger ani queri by exceed a threshold, it wa mark as a new event. lam et al build up previou queri represent of stori cluster, each of which correspond to a topic [7]. in thi manner comparison happen between stori and cluster. recent year, most work focu on propos better method on comparison of stori and document represent. brant et al. [8] extend a basic increment tf-idf model to includ  sourcespecif model, similar score normal base on document-specif averag, similar score normal base on sourc-pair specif averag, term reweight base on invers event frequenc, and segment of document. good improv on tdt bench-mark were shown. stoke et al. [9] util a combin of evid from two distinct represent of a document"s content. on of the represent wa the usual free text vector, the other made us of lexic chain (creat us wordnet) to build anoth term vector. then the two represent ar combin in a linear fashion. a margin increas in effect wa achiev when the combin represent wa us. some effort have been done on how to util name entiti to improv ned. yang et al. gave locat name entiti four time weight than other term and name entiti [10]. doremi research group combin semant similar of person name, locat name and time togeth with textual similar [11][12]. umass [13] research group split document represent into two part: name entiti and non-name entiti. and it wa found that some class of new could achiev better perform us name entiti represent, while some other class of new could achiev better perform us non-name entiti represent. both [10] and [13] us text categor techniqu to classifi new stori in advanc. in [13] new stori ar classifi automat at first, and then test sensit of name and non-name term for ned for each class. in [10] frequent term for each class ar remov from document represent. for exampl, word elect doe not help identifi differ elect. in their work, effect of differ kind of name (or term with differ po) for ned in differ new class ar not investig. we us statist analysi to reveal the fact and us it to improv ned perform. 3. basic model in thi section, we present the basic new event detect model which is similar to what most current system appli. then, we propos our new model by extend the basic model. new event detect system us new stori stream as input, in which stori ar strictli time-order. onli previous receiv stori ar avail when deal with current stori. the output is a decis for whether the current stori is on a new event or not and the confid of the decis. usual, a ned model consist of three part: stori represent, similar calcul and detect procedur. 3.1 stori represent preprocess is need befor gener stori represent. for preprocess, we token word, recogn abbrevi, normal abbrevi, add part-of-speech tag, remov stopword includ in the stop list us in inqueri [14], replac word with their stem us k-stem algorithm[15], and then gener word vector for each new stori. we us increment tf-idf model for term weight calcul [4]. in a tf-idf model, term frequenc in a new document is weight by the invers document frequenc, which is gener from train corpu. when a new term occur in test process, there ar two solut: simpli ignor the new term or set df of the term as a small const (e.g. df = 1). the new term receiv too low weight in the first solut (0) and too high weight in the second solut. in increment tf-idf model, document frequenc ar updat dynam in each time step t: 1( ) ( ) ( )t t d tdf w df w df w−= + (1) where dt repres new stori set receiv in time t, and dfdt(w) mean the number of document that term w occur in, and dft(w) mean the total number of document that term w occur in befor time t. in thi work, each time window includ 50 new stori. thu, each stori d receiv in t is repres as follow: 1 2{ ( , , ), ( , , ),..., ( , , )}nd weight d t w weight d t w weight d t w→ where n mean the number of distinct term in stori d, and ( , , )weight d t w mean the weight of term w in stori d at time t: ' log( ( , ) 1) log(( 1) /( ( ) 0.5)) ( , , ) log( ( , ') 1) log(( 1) /( ( ') 0.5)) t t t t w d tf d w n df w weight d t w tf d w n df w ∈ + + + = + + +∑ (2) where nt mean the total number of new stori befor time t, and tf(d,w) mean how mani time term w occur in new stori d. 3.2 similar calcul we us helling distanc for the calcul of similar between two stori, for two stori d and d" at time t, their similar is defin as follow: , ' ( , ', ) ( , , ) * ( ', , ) w d d sim d d t weight d t w weight d t w ∈ = ∑ (3) 3.3 detect procedur for each stori d receiv in time step t, the valu ( ') ( ) ( ) ( ( , ', )) time d time d n d max sim d d t < = (4) is a score us to determin whether d is a stori about a new topic and at the same time is an indic of the confid in our decis [8]. time(d) mean the public time of stori d. if the score exce the thresholdθ new, then there exist a suffici similar document, thu d is a old stori, otherwis, there is no suffici similar previou document, thu d is an new stori. 4. new ned procedur tradit ned system can be classifi into two main type on the aspect of detect procedur: (1) s-s type, in which the stori on hand is compar to each stori receiv previous, and us the highest similar to determin whether current stori is about a new event; (2) s-c type, in which the stori on hand is compar to all previou cluster each of which repres a topic, and the highest similar is us for final decis for current stori. if the highest similar exce thresholdθ new, then it is an old stori, and put it into the most similar cluster; otherwis it is a new stori and creat a new cluster. previou work show that the first manner is more accur than the second on [4][5]. sinc sometim stori within a topic drift far awai from each other, a stori mai have veri low similar with it topic. so us similar between stori for determin new stori is better than us similar between stori and cluster. nevertheless, the first manner need much more compar time which mean the first manner is low effici. we propos a new detect procedur which us comparison with previou cluster to help find the most similar stori in less compar time, and the final new event decis is made accord to the most similar stori. therefor, we can get both the accuraci of s-s type method and the effici of s-c type method. the new procedur creat a new index-tree dynam, in which similar stori ar put togeth to form a hierarchi of cluster. we index similar stori togeth by their common ancestor (a cluster node). dissimilar stori ar index in differ cluster. when a stori is come, we us comparison between the current stori and previou hierarch cluster to help find the most similar stori which is us for new event decis. after the new event decis is made, the current stori is insert to the index-tree for the follow detect. the new index-tree is defin formal as follow: s-tree = {r, nc , ns , e} where r is the root of s-tree, nc is the set of all cluster node, ns is the set of all stori node, and e is the set of all edg in s-tree. we defin a set of constraint for a s-tree: ⅰ . , is an non-termin node in the treec i i n i∀ ∈ → ⅱ . , is a termin node in the tree i i n i∀ ∈ → ⅲ . , out degre of is at least 2c i i n i∀ ∈ → ⅳ . , is repres as the centroid of it desendantsc i i in∀ ∈ → for a new stori di, the comparison procedur and insert procedur base on index-tree ar defin as follow. an exampl is shown by figur 1 and figur 2. figur 1. comparison procedur figur 2. insert procedur comparison procedur: step 1: compar di to all the direct child node of r and select λ node with highest similar, e.g., c1 2 and c1 3 in figur 1. step 2: for each select node in the last step, e.g. c1 2, compar di to all it direct child node, and select λ node with highest similar, e.g. c2 2 and d8. repeat step 2 for all non-termin node. step 3: record the termin node with the highest similarti to di, e.g. s5, and the similar valu (0.20). insert di to the s-tree with r as root: find the node n which is direct child of r in the path from r to the termin node with highest similar s, e.g. c1 2. if s is smaller than θ init+(h-1)δ , then add di to the tree as a direct child of r. otherwis, if n is a termin node, then creat a cluster node instead of n, and add both n and di as it direct children; if n is an non-termin node, then repeat thi procedur and insert di to the sub-tree with n as root recurs. here h is the length between n and the root of s-tree. the more the stori in a cluster similar to each other, the better the cluster repres the stori in it. henc we add no constraint on the maximum of tree"s height and degre of a node. therefor, we cannot give the complex of thi index-tree base procedur. but we will give the number of compar time need by the new procedur in our experi in section7. 5. term reweight method in thi section, two term reweight method ar propos to improv ned accuraci. in the first method, a new wai is explor for better us of cluster (topic) inform. the second on find a better wai to make us of name entiti base on new classif. 5.1 term reweight base on distribut distanc tf-idf is the most preval model us in inform retriev system. the basic idea is that the fewer document a term appear in, the more import the term is in discrimin of document (relev or not relev to a queri contain the term). nevertheless, in tdt domain, we need to discrimin document with regard to topic rather than queri. intuit, us cluster (topic) vector to compar with subsequ new stori should outperform us stori vector. unfortun, the experiment result do not support thi intuit [4][5]. base on observ on data, we find the reason is that a new topic usual contain mani directli or indirectli relat event, while thei all have their own sub-subject which ar usual differ with each other. take the topic describ in section 1 as an exampl, event like the explos and salvag have veri low similar with event about crimin trial, therefor stori about trial would have low similar with the topic vector built on it previou event. thi section focus on how to effect make us of topic inform and at the same time avoid the problem of content decentr. at first, we classifi term into 5 class to help analysi the need of the modifi model: term class a: term that occur frequent in the whole corpu, e.g., year and peopl. term of thi class should be given low weight becaus thei do not help much for topic discrimin. term class b: term that occur frequent within a new categori, e.g., elect, storm. thei ar us to distinguish two stori in differ new categori. howev, thei cannot provid inform to determin whether two stori ar on the same or differ topic. in anoth word, term elect and term storm ar not help in differenti two elect campaign and two storm disast. therefor, term of thi class should be assign lower weight. term class c: term that occur frequent in a topic, and infrequ in other topic, e.g., the name of a crash plane, the name of a specif hurrican. new stori that belong to differ topic rare have overlap term in thi class. the more frequent a term appear in a topic, the more import the term is for a stori belong to the topic, therefor the term should be set higher weight. term class d: term that appear in a topic exclus, but not frequent. for exampl, the name of a fireman who did veri well in a salvag action, which mai appear in onli two or three stori but never appear in other topic. term of thi type should receiv more weight than in tf-idf model. howev, sinc thei ar not popular in the topic, it is not appropri to give them too high weight. term class e: term with low document frequenc, and appear in differ topic. term of thi class should receiv lower weight. now we analyz whether tf-idf model can give proper weight to the five class of term. obvious, term of class a ar lowli weight in tf-idf model, which is conform with the requir describ abov. in tf-idf model, term of class b ar highli depend with the number of stori in a new class. tf-idf model cannot provid low weight if the stori contain the term belong to a rel small new class. for a term of class c, the more frequent it appear in a topic, the less weight  tfidf model give to it. thi strongli conflict with the requir of term in class c. for term of class d, tf-idf model give them high weight correctli. but for term of class e, tf-idf model give high weight to them which ar not conform with the requir of low weight. to sum up, term of class b, c, e cannot be properli weight in tf-idf model. so, we propos a modifi model to resolv thi problem. when θ init andθ new ar set close, we assum that most of the stori in a first-level cluster (a direct child node of root node) ar on the same topic. therefor, we make us of a first-level cluster to captur term distribut (df for all the term within the cluster) within the topic dynam. kl diverg of term distribut in a first-level cluster and the whole stori set is us to adjust term weight: ' ' ' ( , , ) * (1 * ( || )) ( , , ) ( , , ') * (1 * ( || )) cw tw cw tw w d d weight d t w kl p p weight d t w weight d t w kl p p γ γ ∈ + = +∑ (5) where ( ) ( ) ( ) ( ) 1,cw cw c c c c df w df w p y p y n n = = − (6) ( ) ( ) ( ) ( ) 1,t t tw tw t t df w df w p y p y n n = = − (7) where dfc(w) is the number of document contain term w within cluster c, and nc is the number of document in cluster c, and nt is the total number of document that arriv befor time step t. γ is a const paramet, now is manual set 3. kl diverg is defin as follow [17]: ( ) ( || ) ( ) log ( )x p x kl p q p x q x = ∑ (8) the basic idea is: for a stori in a topic, the more a term occur within the topic, and the less it occur in other topic, it should be assign higher weight. obvious, modifi model can meet all the requir of the five term class list abov. 5.2 term reweight base on term type and stori class previou work found that some class of new stori could achiev good improv by give extra weight to name entiti. but we find that term of differ type should be given differ amount of extra weight for differ class of new stori. we us open-nlp1 to recogn name entiti type and  part-ofspeech tag for term that appear in new stori. name entiti type includ person name, organ name, locat name, date, time, monei and percentag, and five poss ar select: none (nn), verb (vb), adject (jj), adverb (rb) and cardin number (cd). statist analysi show topic-level discrimin term type for differ class of stori. for the sake of conveni, name entiti type and part-of-speech tag ar uniformli call term type in subsequ section. determin whether two stori ar about the same topic is a basic compon for ned task. so at first we us 2 χ statist to comput correl between term and topic. for a term t and a topic t, a conting tabl is deriv: tabl 1. a 2×2 conting tabl doc number belong to topic t not belong to topic t includ t a b not includ t c d the 2 χ statist for a specif term t with respect to topic t is defin to be [16]: 2 2 ( , ) ( ) * ( ) ( ) * ( ) * ( ) * ( ) w t a b c d ad cb a c b d a b c d χ = + + + − + + + + (9) new topic for the tdt task ar further classifi into 11 rule of interpret (roi) 2 . the roi can be seen as a higher level class of stori. the averag correl between a term type and a topic roi is comput as: 2 avg 2 ( , )( ( , ) )k m m km kt r w p w tp r p w t r p χ χ ∈ ∈ ∑ ∑（ , ）= 1 1 k=1…k, m=1…m (10) where k is the number of term type (set 12 constantli in the paper). m is the number new class (roi, set 11 in the paper). pk repres the set of all term of type k, and rm repres the set of all topic of class m, p(t,t) mean the probabl that t occur in topic t. becaus of limit of space, onli part of the term type (9 term type) and part of new class (8 class) ar list in tabl 2 with the averag correl valu between them. the statist is deriv from label data in tdt2 corpu. (result in tabl 2 ar alreadi normal for conveni in comparison.) the statist in tabl 2 indic the us of differ term type in topic discrimin with respect to differ new class. we can see that, locat name is the most us term type for three new class: natur disast, violenc or war, financ. and for three other categori elect, legal/crimin case, scienc and discoveri, person name is the most discrimin term type. for scandal/hear, date is the most import inform for topic discrimin. in addit, legal/crimin case and financ topic have higher correl with monei term, while scienc and discoveri have higher correl with percentag term. non-name term ar more stabl for differ class. 1 . http://opennlp.sourceforg.net/ 2 . http://project.ldc.upenn.edu/tdt3/guid/label.html from the analysi of tabl 2, it is reason to adjust term weight accord to their term type and the new class the stori belong to. new term weight ar reweight as follow: ( ) ( ) ( ) ( ') ' ( , , ) * ( , , ) ( , , ) *' class d d type w t class d d type w w d weight d t w weight d t w weight d t w α α ∈ = ∑ (11) where type(w) repres the type of term w, and class(d) repres the class of stori d, c kα is reweight paramet for new class c and term type k. in the work, we just simpli us statist in tabl 2 as the reweight paramet. even thought us the statist directli mai not the best choic, we do not discuss how to automat obtain the best paramet. we will try to us machin learn techniqu to obtain the best paramet in the futur work. in the work, we us boostext [20] to classifi all stori into on of the 11 roi. boostext is a boost base machin learn program, which creat a seri of simpl rule for build a classifi for text or attribut-valu data. we us term weight gener us tf-idf model as featur for stori classif. we train the model on the 12000 judg english stori in tdt2, and classifi the rest of the stori in tdt2 and all stori in tdt3. classif result ar us for term reweight in formula (11). sinc the class label of topic-off stori ar not given in tdt dataset, we cannot give the classif accuraci here. thu we do not discuss the effect of classif accuraci to ned perform in the paper. 6. experiment setup 6.1 dataset we us two ldc [18] dataset tdt2 and tdt3 for our experi. tdt2 contain new stori from januari to june 1998. it contain around 54,000 stori from sourc like abc, associ press, cnn, new york time, public radio intern, voic of america etc. onli english stori in the collect were consid. tdt3 contain approxim 31,000 english stori collect from octob to decemb 1998. in addit to the sourc us in tdt2, it also contain stori from nbc and msnbc tv broadcast. we us transcrib version of the tv and radio broadcast besid textual new. tdt2 dataset is label with about 100 topic, and approxim 12,000 english stori belong to at least on of these topic. tdt3 dataset is label with about 120 topic, and approxim 8000 english stori belong to at least on of these topic. all the topic ar classifi into 11 rule of interpret: (1)elect, (2)scandal/hear, (3)legal/crimin case, (4)natur disast, (5)accid, (6)ongo violenc or war, (7)scienc and discoveri new, (8)financ, (9)new law, (10)sport new, (11)misc. new. 6.2 evalu metric tdt us a cost function cdet that combin the probabl of miss a new stori and a fals alarm [19]: * * * *det miss miss target fa fa nontargetc c p p c p p= + (12) tabl 2. averag correl between term type and new class where cmiss mean the cost of miss a new stori, pmiss mean the probabl of miss a new stori, and ptarget mean the probabl of see a new stori in the data; cfa mean the cost of a fals alarm, pfa mean the probabl of a fals alarm, and pnontarget mean the probabl of see an old stori. the cost cdet is normal such that a perfect system score 0 and a trivial system, which is the better on of mark all stori as new or old, score 1: ( ( * , * ) ) det det miss target fa nontarget c norm c min c p c p = (13) new event detect system give two output for each stori. the first part is ye or no indic whether the stori trigger a new event or not. the second part is a score indic confid of the first decis. confid score can be us to plot det curv, i.e., curv that plot fals alarm vs. miss probabl. minimum normal cost can be determin if optim threshold on the score were chosen. 7. experiment result 7.1 main result to test the approach propos in the model, we implement and test five system: system-1: thi system is us as baselin. it is implement base on the basic model describ in section 3, i.e., us increment tf-idf model to gener term weight, and us helling distanc to comput document similar. similar score normal is also emploi [8]. s-s detect procedur is us. system-2: thi system is the same as system-1 except that s-c detect procedur is us. system-3: thi system is the same as system-1 except that it us the new detect procedur which is base on index-tree. system-4: implement base on the approach present in section 5.1, i.e., term ar reweight accord to the distanc between term distribut in a cluster and all stori. the new detect procedur is us. system-5: implement base on the approach present in section 5.2, i.e., term of differ type ar reweight accord to new class us train paramet. the new detect procedur is us. the follow ar some other ned system: system-6: [21] for each pair of stori, it comput three similar valu for name entiti, non-name entiti and all term respect. and emploi support vector machin to predict new or old us the similar valu as featur. system-7: [8] it extend a basic increment tf-idf model to includ sourc-specif model, similar score normal base on document-specif averag, similar score normal base on sourc-pair specif averag, etc. system-8: [13] it split document represent into two part: name entiti and non-name entiti, and choos on effect part for each new class. tabl 3 and tabl 4 show topic-weight normal cost and compar time on tdt2 and tdt3 dataset respect. sinc no heldout data set for fine-tune the threshold θ new wa avail for experi on tdt2, we onli report minimum normal cost for our system in tabl 3. system-5 outperform all other system includ system-6, and it perform onli 2.78e+8 compar time in detect procedur which is onli 13.4% of system-1. tabl 3. ned result on tdt2 system min norm(cdet) cmp time system-1 0.5749 2.08e+9 system-2① 0.6673 3.77e+8 system-3② 0.5765 2.81e+8 system-4② 0.5431 2.99e+8 system-5② 0.5089 2.78e+8 system-6 0.5300  -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 when evalu on the normal cost on tdt3, we us the optim threshold obtain from tdt2 data set for all system. system-2 reduc compar time to 1.29e+9 which is just 18.3% of system-1, but at the same time it also get a deterior minimum normal cost which is 0.0499 higher than system-1. system-3 us the new detect procedur base on new index-tree. it requir even less compar time than system-2. thi is becaus stori-stori comparison usual yield greater similar than stori-cluster on, so stori tend to be combin locat person date organ monei percentag nn jj cd elect 0.37 1 0.04 0.58 0.08 0.03 0.32 0.13 0.1 scandal/hear 0.66 0.62 0.28 1 0.11 0.02 0.27 0.13 0.05 legal/crimin case 0.48 1 0.02 0.62 0.15 0 0.22 0.24 0.09 natur disast 1 0.27 0 0.04 0.04 0 0.25 0.04 0.02 violenc or war 1 0.36 0.02 0.14 0.02 0.04 0.21 0.11 0.02 scienc and discoveri 0.11 1 0.01 0.22 0.08 0.12 0.19 0.08 0.03 financ 1 0.45 0.04 0.98 0.13 0.02 0.29 0.06 0.05 sport 0.16 0.27 0.01 1 0.02 0 0.11 0.03 0.01 togeth in system-3. and system-3 is basic equival to system-1 in accuraci result. system-4 adjust term weight base on the distanc of term distribut between the whole corpu and cluster stori set, yield a good improv by 0.0468 compar to system-1. the best system (system-5) ha a minimum normal cost 0.5012, which is 0.0797 better than system-1, and also better than ani other result previous report for thi dataset [8, 13]. further more, system-5 onli need 1.05e+8 compar time which is 14.9% of system-1. tabl 4. ned result on tdt3 system norm(cdet) min norm(cdet) cmp time system-1 0.6159 0.5809 7.04e+8 system-2① 0.6493 0.6308 1.29e+8 system-3② 0.6197 0.5868 1.03e+8 system-4② 0.5601 0.5341 1.03e+8 system-5② 0.5413 0.5012 1.05e+8 system-7 -- 0.5783  -system-8 -- 0.5229  -① θ new=0.13 ② θ init=0.13, λ =3,δ =0.15 figur5 show the five det curv for our system on data set tdt3. system-5 achiev the minimum cost at a fals alarm rate of 0.0157 and a miss rate of 0.4310. we can observ that  system4 and system-5 obtain lower miss probabl at region of low fals alarm probabl. the hypothesi is that, more weight valu is transfer to kei term of topic from non-kei term. similar score between two stori belong to differ topic ar lower than befor, becaus their overlap term ar usual not kei term of their topic. 7.2 paramet select for index-tree detect figur 3 show the minimum normal cost obtain by system-3 on tdt3 us differ paramet. theθ init paramet is test on six valu span from 0.03 to 0.18. and the λ paramet is test on four valu 1, 2, 3 and 4. we can see that, whenθ init is set to 0.12, which is the closest on toθ new, the cost ar lower than other. thi is easi to explain, becaus when stori belong to the same topic ar put in a cluster, it is more reason for the cluster to repres the stori in it. when paramet λ is set to 3 or 4, the cost ar better than other case, but there is no much differ between 3 and 4. 0 0.05 0.1 0.15 0.2 1 2 3 4 0.5 0.6 0.7 0.8 0.9 1 θ-initλ mincost 0.6 0.65 0.7 0.75 0.8 0.85 0.9 figur 3. min cost on tdt3 (δ =0.15) 0 0.05 0.1 0.15 0.2 1 2 3 4 0 0.5 1 1.5 2 2.5 x 10 8 θ-init λ comparingtim 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 8 figur 4. compar time on tdt3 (δ =0.15) figur 4 give the compar time us by system-3 on tdt3 with the same paramet as figur 3. the compar time ar strongli depend onθ init. becaus the greaterθ init is, the less stori combin togeth, the more compar time ar need for new event decis. so we usθ init =0.13,λ =3,δ =0.15 for system-3, 4, and 5. in thi paramet set, we can get both low minimum normal cost and less compar time. 8. conclus we have propos a new index-tree base detect procedur in our model. it reduc compar time to about on seventh of tradit method without hurt ned accuraci. we also have present two extens to the basic tf-idf model. the first extens is made by adjust term weight base on term distribut between the whole corpu and a cluster stori set. and the second extens to basic tf-idf model is better us of term type (name entiti type and part-of-speed) accord to new categori. our experiment result on tdt2 and tdt3 dataset show that both of the two extens contribut significantli to improv in accuraci. we did not consid new time inform as a clue for ned task, sinc most of the topic last for a long time and tdt data set onli span for a rel short period (no more than 6 month). for the futur work, we want to collect new set which span for a longer period from internet, and integr time inform in ned task. sinc topic is a rel coars-grain new cluster, we also want to refin cluster granular to event-level, and identifi differ event and their relat within a topic. acknowledg thi work is support by the nation natur scienc foundat of china under grant no. 90604025. ani opinion, find and conclus or recommend express in thi materi ar the author(s) and do not necessarili reflect those of the sponsor. 9. refer [1] http://www.nist.gov/speech/test/tdt/index.htm [2] in topic detect and track. event-base inform organ. kluwer academ publish, 2002. .01 .02 .05 .1 .2 .5 1 2 5 10 20 40 60 80 90 1 2 5 10 20 40 60 80 90 fals alarm probabl (in %) missprob(in%) system1 topic weight curv system1 min norm(cost) system2 topic weight curv system2 min norm(cost) system3 topic weight curv system3 min norm(cost) system4 topic weight curv system4 min norm(cost) system5 topic weight curv system5 min norm(cost) random perform figur 5. det curv on tdt3 [3] y. yang, j. carbonel, r. brown, t. pierc, b.t. archibald, and x. liu. learn approach for detect and track new event. in ieee intellig system special issu on applic of intellig inform retriev, volum 14 (4), 1999, 32-43. [4] y. yang, t. pierc, and j. carbonel. a studi on retrospect and on-line event detect. in proceed of sigir-98, melbourn, australia, 1998, 28-36. [5] j. allan, v. lavrenko, d. malin, and r. swan. detect, bound, and timelin: umass and tdt-3. in proceed of topic detect and track workshop (tdt-3), vienna, va, 2000, 167-174. [6] r. papka and j. allan. on-line new event detect us singl pass cluster titl2:. technic report  um-cs1998-021, 1998. [7] w. lam, h. meng, k. wong, and j. yen. us contextu analysi for new event detect. intern journal on intellig system, 2001, 525-546. [8] b. thorsten, c. francin, and f. ayman. a system for new event detect. in proceed of the 26th annual intern acm sigir confer, new york, ny, usa. acm press. 2003, 330-337. [9] s. nicola and c. joe. combin semant and syntact document classifi to improv first stori detect. in proceed of the 24th annual intern acm sigir confer, new york, ny, usa. acm press. 2001,  424425. [10] y. yang, j. zhang, j. carbonel, and c. jin.  topiccondit novelti detect. in proceed of the 8th acm sigkdd intern confer, acm press. 2002, 688-693. [11] m. juha, a.m. helena, and s. marko. appli semant class in event detect and track. in proceed of intern confer on natur languag process (icon 2002), 2002, page 175-183. [12] m. juha, a.m. helena, and s. marko. simpl semant in topic detect and track. inform retriev, 7(3-4): 2004, 347-368. [13] k. giridhar and j. allan. text classif and name entiti for new event detect. in proceed of the 27th annual intern acm sigir confer, new york, ny, usa. acm press. 2004, 297-304. [14] j. p. callan, w. b. croft, and s. m. hard. the inqueri retriev system. in proceed of dexa-92, 3rd intern confer on databas and expert system applic, 1992, 78-83. [15] r. krovetz. view morpholog as an infer process. in proceed of acm sigir93, 1993, 61-81. [16] y. yang and j. pedersen. a compar studi on featur select in text categor. in j. d. h. fisher, editor, the fourteenth intern confer on machin learn (icml'97), morgan kaufmann, 1997, 412-420. [17] t. m. cover, and j.a. thoma. element of inform theori. wilei. 1991. [18] the linguist data consortium, http://www.ldc,upenn.edu/. [19] the 2001 tdt task definit and evalu plan, http://www.nist.gov/speech/test/tdt/tdt2001/evalplan.htm. [20] r. e. schapir and y. singer. boostext: a boost-base system for text categor. in machin learn 39(2/3):1, kluwer academ publish, 2000, 35-168. [21] k. giridhar and j. allan. 2005. us name and topic for new event detect. in proceed of human technolog confer and confer on empir method in natur languag, vancouv, 2005, 121-128 