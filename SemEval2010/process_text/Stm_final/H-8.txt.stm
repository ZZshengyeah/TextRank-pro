robust test collect for retriev evalu ben carterett center for intellig inform retriev comput scienc depart univers of massachusett amherst amherst, ma 01003 carteret@cs.umass.edu abstract low-cost method for acquir relev judgment can be a boon to research who need to evalu new retriev task or topic but do not have the resourc to make  thousand of judgment. while these judgment ar veri  us for a on-time evalu, it is not clear that thei can be trust when re-us to evalu new system. in thi work, we formal defin what it mean for judgment to be reusabl: the confid in an evalu of new system can be accur assess from an exist set of relev judgment. we then present a method for augment a set of relev judgment with relev estim that requir no addit assessor effort. us thi method practic guarante reusabl: with as few as five judgment per topic taken from onli two system, we can reliabl  evalu a larger set of ten system. even the smallest set of judgment can be us for evalu of new system. categori and subject descriptor: h.3 inform storag and retriev; h.3.4 system and softwar:  perform evalu gener term: experiment, measur,  reliabl 1. introduct consid an inform retriev research who ha  invent a new retriev task. she ha built a system to  perform the task and want to evalu it. sinc the task is new, it is unlik that there ar ani extant relev  judgment. she doe not have the time or resourc to judg everi document, or even everi retriev document. she can onli judg the document that seem to be the most  inform and stop when she ha a reason degre of confid in her conclus. but what happen when she develop a new system and need to evalu it? or anoth research group decid to implement a system to perform the task? can thei reliabl reus the origin judgment? can thei evalu without more relev judgment? evalu is an import aspect of inform retriev research, but it is onli a semi-solv problem: for most retriev task, it is imposs to judg the relev of everi document; there ar simpli too mani of them. the solut us by nist at trec (text retriev confer) is the pool method [19, 20]: all compet system contribut n document to a pool, and everi document in that pool is judg. thi method creat larg set of judgment that ar reusabl for train or evalu new system that did not contribut to the pool [21]. thi solut is not adequ for our hypothet  research. the pool method give thousand of relev judgment, but it requir mani hour of (paid) annot time. as a result, there have been a slew of recent paper on reduc annot effort in produc test collect: cormack et al. [11], zobel [21], sanderson and joho [17], carterett et al. [8], and aslam et al. [4], among other. as we will see, the judgment these method produc can significantli bia the evalu of a new set of system. return to our hypothet resesarch, can she reus her relev judgment? first we must formal defin what it mean to be reusabl. in previou work,  reusabl ha been test by simpli assess the accuraci of a set of relev judgment at evalu unseen system. while we can sai that it wa right 75% of the time, or that it had a rank correl of 0.8, these number do not have ani  predict power: thei do not tell us which system ar like to be wrong or how confid we should be in ani on. we need a more care definit of reusabl. specif, the question of reusabl is not how  accur we can evalu new system. a malici  adversari can alwai produc a new rank list that ha not retriev ani of the judg document. the real question is how much confid we have in our evalu, and, more importantli, whether we can trust our estim of confid. even if confid is not high, as long as we can trust it, we can identifi which system need more  judgment in order to increas confid. ani set of judgment, no matter how small, becom reusabl to some degre. small, reusabl test collect could have a huge impact on inform retriev research. research group would be abl to share the relev judgment thei have done in-hous for pilot studi, new task, or new topic. the amount of data avail to research would grow  exponenti over time. 2. robust evalu abov we gave an intuit definit of reusabl: a collect is reusabl if we can trust our estim of  confid in an evalu. by that we mean that if we have made some relev judgment and have, for exampl, 75% confid that system a is better than system b, we would like there to be no more than 25% chanc that our  assess of the rel qualiti of the system will chang as we continu to judg document. our evalu should be robust to miss judgment. in our previou work, we defin confid as the  probabl that the differ in an evalu measur calcul for two system is less than zero [8]. thi notion of  confid is defin in the context of a particular evalu task that we call compar evalu: determin the sign of the differ in an evalu measur. other  evalu task could be defin; estim the magnitud of the differ or the valu of the measur themselv ar exampl that entail differ notion of confid. we therefor see confid as a probabl estim. on of the question we must ask about a probabl estim is what it mean. what doe it mean to have 75% confid that system a is better than system b? as describ abov, we want it to mean that if we continu to judg document, there will onli be a 25% chanc that our assess will chang. if thi is what it mean, we can trust the confid estim. but do we know it ha that mean? our calcul of confid rest on an assumpt about the probabl of relev of unjudg document, specif that each unjudg document wa equal like to be relev or nonrelev. thi assumpt is almost certainli not realist in most ir applic. as it turn out, it is thi assumpt that determin whether the  confid estim can eb trust. befor elabor on thi, we formal defin confid. 2.1 estim confid averag precis (ap) is a standard evalu metric that captur both the abil of a system to rank relev document highli (precis) as well as it abil to retriev relev document (recal). it is typic written as the mean precis at the rank of relev document: ap = 1 |r| i∈r prec@r(i) where r is the set of relev document and r(i) is the rank of document i. let xi be a random variabl indic the relev of document i. if document ar order by rank, we can express precis as prec@i = 1/i i j=1 xj . averag precis then becom the quadrat equat ap = 1 xi n i=1 xi/i i j=1 xj = 1 xi n i=1 j≥i aijxixj where aij = 1/ max{r(i), r(j)}. us aij instead of 1/i  allow us to number the document arbitrarili. to see why thi is true, consid a toi exampl: a list of 3 document with relev document b, c at rank 1 and 3 and  nonrelev document a at rank 2. averag precis will be 1 2 (1 1 x2 b+ 1 2 xbxa+ 1 3 xbxc + 1 2 x2 a+ 1 3 xaxc + 1 3 x2 c) = 1 2 1 + 2 3 becaus xa = 0, xb = 1, xc = 1. though the order b, a, c is differ from the label a, b, c, it doe not affect the comput. we can now see averag precis itself is a random  variabl with a distribut over all possibl assign of  relev to all document. thi random variabl ha an  expect, a varianc, confid interv, and a certain probabl of be less than or equal to a given valu. all of these ar depend on the probabl that  document i is relev: pi = p(xi = 1). suppos in our  previou exampl we do not know the relev judgment, but we believ pa = 0.4, pb = 0.8, pc = 0.7. we can then comput e.g. p(ap = 0) = 0.2 · 0.6 · 0.3 = 0.036, or p(ap = 1 2 ) = 0.2 · 0.4 · 0.7 = 0.056. sum over all possibl, we can comput  expect and varianc: e[ap] ≈ 1 pi aiipi + j>i aij pipj v ar[ap] ≈ 1 ( pi)2 n i a2 iipiqi + j>i a2 ijpipj(1 − pipj) + i=j 2aiiaijpipj(1 − pi) + k>j=i 2aijaikpipjpk(1 − pi) ap asymptot converg to a normal distribut with expect and varianc as defin abov.1 for our compar evalu task we ar interest in the sign of the differ in two averag precis: Δap = ap1 − ap2. as we show in our previou work, Δap ha a close form when document ar order arbitrarili: Δap = 1 xi n i=1 j≥i cij xixj cij = aij − bij where bij is defin analog to aij for the second  rank. sinc ap is normal, Δap is normal as well, mean we can us the normal cumul densiti function to  determin the confid that a differ in ap is less than zero. sinc topic ar independ, we can easili extend thi to mean averag precis (map). map is also normal distribut; it expect and varianc ar: emap = 1 t t∈t e[apt] (1) vmap = 1 t2 t∈t v ar[apt] Δmap = map1 − map2 confid can then be estim by calcul the  expect and varianc and us the normal densiti function to find p(Δmap < 0). 2.2 confid and robust have defin confid, we turn back to the issu of trust in confid estim, and show how it ti into the robust of the collect to miss judgment. 1 these ar actual approxim to the true expect and varianc, but the error is a neglig o(n2−n ). let z be the set of all pair of rank result for a  common set of topic. suppos we have a set of m relev judgment xm = {x1, x2, ..., xm} (us small x rather than capit x to distinguish between judg and unjudg  document); these ar the judgment against which we comput confid. let zα be the subset of pair in z for which we predict that Δmap = −1 with confid α given the judgment xm . for the confid estim to be  accur, we need at least α · |zα| of these pair to actual have Δmap = −1 after we have judg everi document. if thei do, we can trust the confid estim; our evalu will be robust to miss judgment. if our confid estim ar base on unrealist  assumpt, we cannot expect them to be accur. the assumpt thei ar base on ar the probabl of  relev pi. we need these to be realist. we argu that the best possibl distribut of relev p(xi) is the on that explain all of the data (all of the observ made about the retriev system) while at the same time make no unwarr assumpt. thi is known as the principl of maximum entropi [13]. the entropi of a random variabl x with distribut p(x) is defin as h(p) = − i p(x = i) log p(x = i). thi ha found a wide arrai of us in comput scienc and inform retriev. the maximum entropi distribut is the on that maxim h. thi distribut is uniqu and ha an exponenti form. the follow theorem show the util of a maximum entropi distribut for relev when estim confid. theorem 1. if p(xn |i, xm ) = argmaxph(p), confid estim will be accur. where xm is the set of relev judgment defin abov, xn is the full set of document that we wish to estim the relev of, and i is some inform about the document (unspecifi as of now). we forgo the proof for the time be, but it is quit simpl. thi sai that the better the estim of relev, the more accur the evalu. the task of creat a reusabl test collect thu becom the task of estim the  relev of unjudg document. the theorem and it proof sai noth whatsoev about the evalu metric. the probabl estim ar entir indeped of the measur we ar interest in. thi mean the same probabl estim can tell us about averag precis as well as precis, recal, bpref, etc. furthermor, we could assum that the relev of  document i and j is independ and achiev the same result, which we state as a corollari: corollari 1. if p(xi|i, xm ) = argmaxph(p), confid estim will be accur. the task therefor becom the imput of the miss valu of relev. the theorem impli that the closer we get to the maximum entropi distribut of relev, the closer we get to robust. 3. predict relev in our statement of theorem 1, we left the natur of the inform i unspecifi. on of the advantag of our  confid estim is that thei admit inform from a wide varieti of sourc; essenti anyth that can be  model can be us as inform for predict relev. a natur sourc of inform is the retriev system  themselv: how thei rank the judg document, how often thei fail to rank relev document, how thei perform across topic, and so on. if we treat each system as an  inform retriev expert provid an opinion about the relev of each document, the problem becom on of expert opinion aggreg. thi is similar to the metasearch or data fusion problem in which the task is to take k input system and merg them into a singl rank. aslam et al. [3] previous identifi a connect between evalu and metasearch. our  problem ha two kei differ: 1. we explicitli need probabl of relev that we can plug into eq. 1; metasearch algorithm have no such requir. 2. we ar accumul relev judgment as we  proce with the evalu and ar abl to re-estim relev given each new judgment. in light of (1) abov, we introduc a probabilist model for expert combin. 3.1 a model for expert opinion aggreg suppos that each expert j provid a probabl of  relev qij = pj(xi = 1). the inform about the  relev of document i will then be the set of k expert opinion i = qi = (qi1, qi2, · · · , qik). the probabl distribut we wish to find is the on that maxim the entropi of pi = p(xi = 1|qi). as it turn out, find the maximum entropi model is equival to find the paramet that maxim the  likelihood [5]. blower [6] explicitli show that find the  maximum entropi model for a binari variabl is equival to solv a logist regress. then pi = p(xi = 1|qi) = exp k j=1 λjqij 1 + exp k j=1 λj qij (2) where λ1, · · · , λk ar the regress paramet. we includ a beta prior for p(λj) with paramet α, β. thi can be seen as a type of smooth to account for the fact that the train data is highli bias. thi model ha the advantag of includ the  statist depend between the expert. a model of the same form wa shown by clemen & winkler to be the best for aggreg expert probabl [10]. a similar  maximumentropi-motiv approach ha been us for expert  aggreg [15]. aslam & montagu [1] us a similar model for metasearch, but assum independ among expert. where do the qij s come from? us raw, uncalibr score as predictor will not work becaus score distribut vari too much between topic. a languag model ranker, for instanc, will typic give a much higher score to the top retriev document for a short queri than to the top retriev document for a long queri. we could train a separ predict model for each topic, but that doe not take advantag of all of the inform we have: we mai onli have a hand of judgment for a topic, not enough to train a model to ani confid. furthermor, it seem reason to assum that if an expert make good predict for on topic, it will make good predict for other topic as well. we could us a hierarch model [12], but that will not gener to unseen topic. instead, we will calibr the score of each expert individu so that score can be compar both within topic and between topic. thu our model take into account not onli the depend between expert, but also the depend between expert" perform on differ task (topic). 3.2 calibr expert each expert give us a score and a rank for each document. we need to convert these to probabl. a method such as the on us by manmatha et al. [14] could be us to convert score into probabl of relev. the pairwis prefer method of carterett & petkova [9] could also be us, interpet the rank of on document over anoth as an express of prefer. let q∗ ij be expert j"s self-report probabl that  document i is relev. intuit it seem clear that q∗ ij should decreas with rank, and it should be zero if document i is unrank (the expert did not believ it to be relev). the pairwis prefer model can handl these two  requir easili, so we will us it. let θrj (i) be the relev coeffici of the document at rank rj(i). we want to find the θs that maxim the likelihood function: ljt(Θ) = rj (i)<rj (k) exp(θrj (i) − θrj (k)) 1 + exp(θrj (i) − θrj (k)) we again includ a beta prior on p(θrj(i)) with paramet |rt| + 1 and |nt| + 1, the size of the set of judg  relev and nonrelev document respect. us these as prior paramet ensur that the result probabl will be concentr around the ratio of relev document that have been discov for topic t. thi mean that the probabl estim decreas by rank and ar higher for topic that have more relev document. after find the Θ that maxim the likelihood, we have q∗ ij = exp(θrj (i)) 1+exp(θrj (i)) . we defin θ∞ = −∞, so that the  probabl that an unrank document is relev is 0. sinc q∗ ij is base on the rank at which a document is retriev rather than the ident of the document itself, the probabl ar ident from expert to expert, e.g. if expert e put document a at rank 1, and expert d put document b at rank 1, we will have q∗ ae = q∗ bd. therefor we onli have to solv thi onc for each topic. the abov model give topic-independ probabl for each document. but suppos an expert who report 90% probabl is onli right 50% of the time. it opinion should be discount base on it observ perform.  specif, we want to learn a calibr function qij = cj(q∗ ij) that will ensur that the predict probabl ar tune to the expert"s abil to retriev relev document given the judgment that have been made to thi point. platt"s svm calibr method [16] fit a sigmoid  function between q∗ ij and the relev judgment to obtain qij = cj (q∗ ij) = exp(aj +bjq∗ ij ) 1+exp(aj +bj q∗ ij ) . sinc q∗ ij is topic-independ, we onli need to learn on calibr function for each  expert. onc we have the calibr function, it is appli to adjust the expert" predict to their actual perform. the calibr probabl ar plug into model (2) to find the document probabl. figur 1: conceptu diagram of our aggreg model. expert e1, e2 have rank document a, b, c for topic t1 and document d, e, f for topic t2. the first step is to obtain q∗ ij. next is calibr to true perform to find qij . final we obtain pi = p(xi = 1|qi1, qi2), · · · . 3.3 model summari our model ha three compon that differ by the data thei take as input and what thei produc as output. a conceptu diagram is shown in figur 1. 1. rank → probabl (per system per topic). thi give us q∗ ij, expert j"s self-report probabl of the relev of document i. thi is unsupervis; it  requir no label data (though if we have some, we us it to set prior paramet). 2. probabl → calibr probabl (per system). thi give us qij = cj (q∗ ij), expert j"s calibr  probabl of the relev of document i. thi is  semisupervis; we have relev judgment at some rank which we us to imput the probabl of relev at other rank. 3. calibr probabl → document probabl. thi give us pi = p(xi = 1|qi), the probabl of relev of document i given calibr expert probabl qij . thi is supervis; we learn coeffici from a set of judg document and us those to estim the  relev of the unjudg document. although the model appear rather complex, it is realli just three success applic of logist regress. as such, it can be implement in a statist program languag such as r in a few line of code. the us of beta (conjug) prior ensur that no expens comput method such as mcmc ar necessari [12], so the model is train and appli fast enough to be us on-line. our code is avail at http://ciir.cs.umass.edu/~carteret/. 4. experi three hypothes ar under consider. the first, and most import, is that us our expert aggreg model to predict relev produc test collect that ar robust enough to be reusabl; that is, we can trust the estim of confid when we evalu system that did not contribut ani judgment to the pool. the other two hypothes relat to the improv we see by us better estim of relev than we did in our previou work [8]. these ar that (a) it take fewer relev track no. topic no. run no. judg no. rel ad-hoc 94 50 40 97,319 9,805 ad-hoc 95 49 33 87,069 6,503 ad-hoc 96 50 61 133,681 5,524 ad-hoc 97 50 74 72,270 4,611 ad-hoc 98 50 103 80,345 4,674 ad-hoc 99 50 129 86,830 4,728 web 04 225 74 88,566 1,763 robust 05 50 74 37,798 6,561 terabyt 05 50 58 45,291 10,407 tabl 1: number of topic, number of run, number of document judg, and number found relev for each of our data set. judgment to reach 95% confid and (b) the accuraci of the predict is higher than if we were to simpli assum pi = 0.5 for all unjudg document. 4.1 data we obtain full ad-hoc run submit to trec 3 through 8. each run rank at most 1000 document for 50 topic (49 topic for trec 4). addition, we obtain all run from the web track of trec 13, the robust2 track of trec 14, and the terabyt (ad-hoc) track of trec 14. these ar the track that have replac the ad-hoc track sinc it end in 1999. statist ar shown in tabl 1. we set asid the trec 4 (ad-hoc 95) set for train, trec 3 and 5-8 (ad-hoc 94 and 96-99) for primari test, and the remain set for addit test. we us the qrel file assembl by nist as truth. the number of relev judgment made and relev  document found for each track ar list in tabl 1. for comput reason, we truncat rank list at 100 document. there is no reason that we could not go deeper, but calcul varianc is o(n3 ) and thu veri  timeconsum. becaus of the reciproc rank natur of ap, we do not lose much inform by truncat at rank 100. 4.2 algorithm we will compar three algorithm for acquir relev judgment. the baselin is a variat of trec pool that we will call increment pool (ip). thi algorithm take a number k as input and present the first k document in rank order (without regard to topic) to be judg. it doe not estim the relev of unjudg document; it simpli assum ani unjudg document is nonrelev. the second algorithm is that present in carterett et al. [8] (algorithm 1). document ar select base on how interest thei ar in determin whether a differ in mean averag precis exist. for thi approach pi = 0.5 for all i; there is no estim of probabl. we will call thi mtc for minim test collect. the third algorithm augment mtc with updat  estim of probabl of relev. we will call thi rtc for robust test collect. it is ident to algorithm 1,  except that everi 10th iter we estim pi for all unjudg document i us the expert aggreg model of section 3. rtc ha smooth (prior distribut) paramet that must be set. we train us the ad-hoc 95 set. we limit 2 robust here mean robust retriev; thi is differ from our goal of robust evalu. algorithm 1 (mtc) given two rank list and confid level α, predict the sign of Δmap. 1: pi ← 0.5 for all document i 2: while p(Δmap < 0) < α do 3: calcul weight wi for all unjudg document i (see carterett et al. [8] for detail) 4: j ← argmaxiwi 5: xj ← 1 if document j is relev, 0 otherwis 6: pj ← xj 7: end while the search to uniform prior with rel high varianc. for expert aggreg, the prior paramet ar α = β = 1. 4.3 experiment design first, we want to know whether we can augment a set of relev judgment with a set of relev probabl in order to reus the judgment to evalu a new set of system. for each experiment trial: 1. pick a random subset of k run. 2. from those k, pick an initi c < k to evalu. 3. run rtc to 95% confid on the initi c. 4. us the model from section 3, estim the  probabl of relev for all document retriev by all k run. 5. calcul emap for all k run, and p(Δmap < 0) for all pair of run. we do the same for mtc, but omit step 4. note that  after evalu the first c system, we make no addit relev judgment. to put our method to the test, we select c = 2: we will build a set of judgment from evalu onli two initi system. we will then gener to a set of k = 10 (of which those two ar a subset). as we run more trial, we obtain the data we need to test all three of our hypothes. 4.4 experiment evalu recal that a set of judgment is robust if the accuraci of the predict it make is at least it estim confid. on wai to evalu robust is to bin pair by their  confid, then calcul the accuraci over all the pair in each bin. we would like the accuraci to be no less than the lowest confid score in the bin, but prefer higher. sinc summari statist ar us, we devis the  follow metric. suppos we ar a bookmak take bet on whether Δmap < 0. we us rtc or mtc to set the odd o = p (Δmap <0) 1−p (Δmap <0) . suppos a bettor wager $1 on Δmap ≥ 0. if it turn out that Δmap < 0, we win the dollar. otherwis, we pai out o. if our confid  estim ar perfectli accur, we break even. if confid is greater than accuraci, we lose monei; we win if accuraci is greater than confid. counterintuit, the most desir outcom is  break even: if we lose monei, we cannot trust the confid estim, but if we win monei, we have either  underestim confid or judg more document than necessari. howev, the cost of not be abl to trust the confid estim is higher than the cost of extra relev  judgment, so we will treat posit outcom as good. the amount we win on each pairwis comparison i is: wi = yi − (1 − yi) pi 1 − pi = yi − pi 1 − pi yi = 1 if Δmap < 0 and 0 otherwis, and pi = p(Δmap < 0). the summari statist is w, the mean of wi. note that as pi increas, we lose more for be wrong. thi is as it should be: the penalti should be great for miss the high probabl predict. howev, sinc our loss grow without bound as predict approach certainti, we cap −wi at 100. for our hypothesi that rtc requir fewer judgment than mtc, we ar interest in the number of judgment need to reach 95% confid on the first pair of system. the median is more interest than the mean: most pair requir a few hundr judgment, but a few pair requir  sever thousand. the distribut is therefor highli skew, and the mean strongli affect by those outlier. final, for our hypothesi that rtc is more accur than mtc, we will look at kendal"s τ correl between a rank of k system by a small set of judgment and the true rank us the full set of judgment. kendal"s τ, a nonparametr statist base on pairwis swap between two list, is a standard evalu for thi type of studi. it rang from −1 (perfectli anti-correl) to 1 (rank ident), with 0 mean that half of the pair ar swap. as we touch on in the introduct, though, an accuraci measur like rank correl is not a good evalu of reusabl. we includ it for complet. 4.4.1 hypothesi test run multipl trial allow the us of statist  hypothesi test to compar algorithm. us the same set of system allow the us of pair test. as we state abov, we ar more interest in the median number of judgment than the mean. a test for differ in median is the wilcoxon sign rank test. we can also us a pair t-test to test for a differ in mean. for rank correl, we can us a pair t-test to test for a differ in τ. 5. result and analysi the comparison between mtc and rtc is shown in  tabl 2. with mtc and uniform probabl of relev, the result ar far from robust. we cannot reus the relev judgment with much confid. but with rtc, the  result ar veri robust. there is a slight dip in accuraci when confid get abov 0.95; nonetheless, the confid  predict ar trustworthi. mean wi show that rtc is much closer to 0 than mtc. the distribut of confid score show that at least 80% confid is achiev more than 35% of the time, indic that neither algorithm is be too conserv in it confid estim. the confid estim ar rather low overal; that is becaus we have built a test collect from onli two initi system.  recal from section 1 that we cannot requir (or even expect) a minimum level of confid when we gener to new system. more detail result for both algorithm ar shown in figur 2. the solid line is the ideal result that would give w = 0. rtc is on or abov thi line at all point until confid reach about 0.97. after that there is a slight dip in accuraci which we discuss below. note that both mtc rtc confid % in bin accuraci % in bin accuraci 0.5 − 0.6 33.7% 61.7% 28.6% 61.9% 0.6 − 0.7 18.1% 73.1% 20.1% 76.3% 0.7 − 0.8 10.4% 70.1% 15.5% 78.0% 0.8 − 0.9 9.4% 69.0% 12.1% 84.9% 0.9 − 0.95 7.3% 78.0% 6.6% 93.1% 0.95 − 0.99 17.9% 70.4% 12.4% 93.4% 1.0 3.3% 68.3% 4.7% 98.9% w −5.34 −0.39 median judg 251 235 mean τ 0.393 0.555 tabl 2: confid that p(Δmap < 0) and  accuraci of predict when gener a set of  relev judgment acquir us mtc and rtc. each bin contain over 1,000 trial from the adhoc 3, 5-8 set. rtc is much more robust than mtc. w is defin in section 4.4; closer to 0 is better. median judg is the number of judgment to reach 95% confid on the first two system. mean τ is the averag rank correl for all 10 system. 0.5 0.6 0.7 0.8 0.9 1 0.5 0.6 0.7 0.8 0.9 1 accuraci confid breakeven rtc mtc figur 2: confid vs. accuraci of mtc and rtc. the solid line is the perfect result that would give w = 0; perform should be on or abov thi line. each point repres at least 500 pairwis comparison. algorithm ar well abov the line up to around confid 0.7. thi is becaus the baselin perform on these data set is high; it is quit easi to achiev 75% accuraci do veri littl work [7]. number of judgment: the median number of  judgment requir by mtc to reach 95% confid on the first two system is 251, an averag of 5 per topic. the median requir by rtc is 235, about 4.7 per topic. although the number ar close, rtc"s median is significantli lower by a pair wilcoxon test (p < 0.0001). for comparison, a pool of depth 100 would result in a minimum of 5,000 judgment for each pair. the differ in mean is much greater. mtc requir a mean of 823 judgment, 16 per topic, while rtc requir a mean of 502, 10 per topic. (recal that mean ar strongli skew by a few pair that take thousand of judgment.) thi differ is signific by a pair t-test (p < 0.0001). ten percent of the set result in 100 or fewer judgment (less than two per topic). perform on these is veri high: w = 0.41, and 99.7% accuraci when confid is at least 0.9. thi show that even tini collect can be reusabl. for the 50% of set with more than 235 judgment, accuraci is 93% when confid is at least 0.9. rank correl: mtc and rtc both rank the 10 system by emap (eq. (1)) calcul us their respect probabl estim. the mean τ rank correl between true map and emap is 0.393 for mtc and 0.555 for rtc. thi differ is signific by a pair t-test (p < 0.0001). note that we do not expect the τ correl to be high, sinc we ar rank the system with so few relev  judgment. it is more import that we estim confid in each pairwis comparison correctli. we ran ip for the same number of judgment that mtc took for each pair, then rank the system by map  us onli those judgment (all unjudg document assum nonrelev). we calcul the τ correl to the true rank. the mean τ correl is 0.398, which is not  significantli differ from mtc, but is significantli lower than rtc. us uniform estim of probabl is  indistinguish from the baselin, wherea estim relev by expert aggreg boost perform a great deal: nearli 40% over both mtc and ip. overfit: it is possibl to overfit: if too mani judgment come from the first two system, the varianc in Δmap is reduc and the confid estim becom unreli. we saw thi in tabl 2 and figur 2 where rtc exhibit a dip in accuraci when confid is around 97%. in fact, the number of judgment made prior to a wrong predict is over 50% greater than the number made prior to a correct predict. overfit is difficult to quantifi exactli, becaus  make more relev judgment doe not alwai caus it: at higher confid level, more relev judgment ar made, and as tabl 2 show, accuraci is greater at those higher confid. obvious have more relev judgment should increas both confid and accuraci; the  differ seem to be when on system ha a great deal more judgment than the other. pairwis comparison: our pairwis comparison fall into on of three group: 1. the two origin run from which relev judgment ar acquir; 2. on of the origin run vs. on of the new run; 3. two new run. tabl 3 show confid vs. accuraci result for each of these three group. interestingli, perform is worst when compar on of the origin run to on of the addit run. thi is most like due to a larg differ in the number of judgment affect the varianc of Δmap.  nevertheless, perform is quit good on all three subset. worst case: the case intuit most like to  produc an error is when the two system be compar have retriev veri few document in common. if we want the judgment to be reusabl, we should to be abl to gener even to run that ar veri differ from the on us to acquir the relev judgment. a simpl measur of similar of two run is the averag percentag of document thei retriev in common for each topic [2]. we calcul thi for all pair, then look at  perform on pair with low similar. result ar shown in accuraci confid two origin on origin no origin 0.5 − 0.6 - 48.1% 62.8% 0.6 − 0.7 - 57.1% 79.2% 0.7 − 0.8 - 67.9% 81.7% 0.8 − 0.9 - 82.2% 86.3% 0.9 − 0.95 95.9% 93.7% 92.6% 0.95 − 0.99 96.2% 92.5% 93.1% 1.0 100% 98.0% 99.1% w −1.11 −0.87 −0.27 tabl 3: confid vs. accuraci of rtc when  compar the two origin run, on origin run and on new run, and two new run. rtc is robust in all three case. accuraci when similar confid 0 − 0.1 0.1 − 0.2 0.2 − 0.3 0.5 − 0.6 68.4% 63.1% 61.4% 0.6 − 0.7 84.2% 78.6% 76.6% 0.7 − 0.8 82.0% 79.8% 78.9% 0.8 − 0.9 93.6% 83.3% 82.1% 0.9 − 0.95 99.3% 92.7% 92.4% 0.95 − 0.99 98.7% 93.4% 93.3% 1.0 99.9% 97.9% 98.1% w 0.44 −0.45 −0.49 tabl 4: confid vs. accuraci of rtc when a pair of system retriev 0-30% document in  common (broken out into 0%-10%, 10%-20%, and  20%30%). rtc is robust in all three case. tabl 4. perform is in fact veri robust even when  similar is low. when the two run share veri few document in common, w is actual posit. mtc and ip both perform quit poorli in these case. when the similar wa between 0 and 10%, both mtc and ip correctli predict Δmap onli 60% of the time, compar to an 87.6% success rate for rtc. by data set: all the previou result have onli been on the ad-hoc collect. we did the same experi on our addit data set, and broke out the result by data set to see how perform vari. the result in tabl 5 show everyth about each set, includ bin accuraci, w, mean τ, and median number of judgment to reach 95% confid on the first two system. the result ar highli consist from collect to collect, suggest that our method is not overfit to ani particular data set. 6. conclus and futur work in thi work we have offer the first formal definit of the common idea of reusabl of a test collect and present a model that is abl to achiev reusabl with veri small set of relev judgment. tabl 2 and figur 2 togeth show how bias a small set of judgment can be: mtc is dramat overestim confid and is much less accur than rtc, which is abl to remov the bia to give a robust evalu. the confid estim of rtc, in addit to be  accur, provid a guid for obtain addit judgment: focu on judg document from the lowest-confid  comparison. in the long run, we see small set of relev  judgaccuraci confid ad-hoc 94 ad-hoc 96 ad-hoc 97 ad-hoc 98 ad-hoc 99 web 04 robust 05 terabyt 05 0.5 − 0.6 64.1% 61.8% 62.2% 62.0% 59.4% 64.3% 61.5% 61.6% 0.6 − 0.7 76.1% 77.8% 74.5% 78.2% 74.3% 78.1% 75.9% 75.9% 0.7 − 0.8 75.2% 78.9% 77.6% 80.0% 78.6% 82.6% 77.5% 80.4% 0.8 − 0.9 83.2% 85.5% 84.6% 84.9% 86.8% 84.5% 86.7% 87.7% 0.9 − 0.95 93.0% 93.6% 92.8% 93.7% 92.6% 94.2% 93.9% 94.2% 0.95 − 0.99 93.1% 94.3% 93.1% 93.7% 92.8% 95.0% 93.9% 91.6% 1.0 99.2% 96.8% 98.7% 99.5% 99.6% 100% 99.2% 98.3% w -0.34 -0.34 -0.48 -0.35 -0.44 -0.07 -0.41 -0.67 median judg 235 276 243 213 179 448 310 320 mean τ 0.538 0.573 0.556 0.579 0.532 0.596 0.565 0.574 tabl 5: accuraci, w, mean τ, and median number of judgment for all 8 test set. the result ar highli consist across data set. ment be share by research, each group  contribut a few more judgment to gain more confid about their particular system. as time goe on, the number of judgment grow until there is 100% confid in everi evalu-and there is a full test collect for the task. we see further us for thi method in scenario such as web retriev in which the corpu is frequent chang. it could be appli to evalu on a dynam test collect as defin by soboroff [18]. the model we present in section 3 is by no mean the onli possibl for creat a robust test collect. a  simpler expert aggreg model might perform as well or  better (though all our effort to simplifi fail). in addit to expert aggreg, we could estim probabl by  look at similar between document. thi is an obviou area for futur explor. addition, it will be worthwhil to investig the issu of overfit: the circumst it occur under and what can be done to prevent it. in the meantim, cap  confid estim at 95% is a hack that solv the problem. we have mani more experiment result that we  unfortun did not have space for but that reinforc the notion that rtc is highli robust: with just a few judgment per topic, we can accur assess the confid in ani  pairwis comparison of system. acknowledg thi work wa support in part by the center for intellig inform retriev and in part by the defens advanc research project agenc (darpa) under contract number hr0011-06-c-0023. ani opinion, find, and conclus or recommend express in thi materi ar those of the author and do not necessarili reflect those of the  sponsor. 7. refer [1] j. aslam and m. montagu. model for metasearch. in proceed of sigir, page 275-285, 2001. [2] j. aslam and r. savel. on the effect of evalu retriev system in the absenc of relev judgment. in proceed of sigir, page 361-362, 2003. [3] j. a. aslam, v. pavlu, and r. savel. a unifi model for metasearch, pool, and system evalu. in proceed of cikm, page 484-491, 2003. [4] j. a. aslam, v. pavlu, and e. yilmaz. a statist method for system evalu us incomplet judgment. in proceed of sigir, page 541-548, 2006. [5] a. l. berger, s. d. pietra, and v. j. d. pietra. a maximum entropi approach to natur languag process. comput linguist, 22(1):39-71, 1996. [6] d. j. blower. an easi deriv of logist regress from the bayesian and maximum entropi perspect. in proceed of the 23rd intern workship on bayesian infer and maximum entropi method in scienc and engin, page 30-43, 2004. [7] b. carterett and j. allan. research methodolog in studi of assessor effort for retriev evalu. in proceed of riao, 2007. [8] b. carterett, j. allan, and r. k. sitaraman. minim test collect for retriev evalu. in proceed of sigir, page 268-275, 2006. [9] b. carterett and d. i. petkova. learn a rank from pairwis prefer. in proceed of sigir, 2006. [10] r. t. clemen and r. l. winkler. unanim and compromis among probabl forecast. manag scienc, 36(7):767-779, juli 1990. [11] g. v. cormack, c. r. palmer, and c. l. clark. effici construct of larg test collect. in proceed of sigir, page 282-289, 1998. [12] a. gelman, j. b. carlin, h. s. stern, and d. b. rubin. bayesian data analysi. chapman & hall/crc, 2004. [13] e. t. jayn. probabl theori: the logic of scienc. cambridg univers press, 2003. [14] r. manmatha and h. sever. a formal approach to score normal for metasearch. in proceed of hlt, page 88-93, 2002. [15] i. j. myung, s. ramamoorti, and j. andrew d. baili. maximum entropi aggreg of expert predict. manag scienc, 42(10):1420-1436, octob 1996. [16] j. platt. probabilist output for support vector machin and comparison to regular likelihood method. page 61-74, 2000. [17] m. sanderson and h. joho. form test collect with no system pool. in proceed of the 27th annual intern acm sigir confer on research and develop in inform retriev, page 33-40, 2004. [18] i. soboroff. dynam test collect: measur search effect on the live web. in proceed of sigir, page 276-283, 2006. [19] k. sparck jone and c. j. van rijsbergen. inform retriev test collect. journal of document, 32(1):59-75, 1976. [20] e. m. voorhe and d. k. harman, editor. trec: experi and evalu in inform retriev. mit press, 2005. [21] j. zobel. how reliabl ar the result of larg-scale inform retriev experi? in proceed of sigir, page 307-314, 1998. 