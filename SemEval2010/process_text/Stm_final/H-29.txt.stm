estim and us of uncertainti in pseudo-relev feedback kevyn collin-thompson and jami callan languag technolog institut school of comput scienc carnegi mellon univers pittsburgh, pa 15213-8213 u.s.a. {kct | callan}@cs.cmu.edu abstract exist pseudo-relev feedback method typic  perform averag over the top-retriev document, but  ignor an import statist dimens: the risk or varianc associ with either the individu document model, or their combin. treat the baselin feedback method as a black box, and the output feedback model as a random variabl, we estim a posterior distribut for the  feedback model by resampl a given queri"s top-retriev  document, us the posterior mean or mode as the enhanc feedback model. we then perform model combin over sever enhanc model, each base on a slightli modifi queri sampl from the origin queri. we find that  resampl document help increas individu feedback model precis by remov nois term, while sampl from the queri improv robust (worst-case perform) by  emphas term relat to multipl queri aspect. the  result is a meta-feedback algorithm that is both more robust and more precis than the origin strong baselin method. categori and subject descriptor: h.3.3 [inform retriev]: retriev model gener term: algorithm, experiment 1. introduct uncertainti is an inher featur of inform retriev. not onli do we not know the queri that will be present to our retriev algorithm ahead of time, but the user"s  inform need mai be vagu or incomplet specifi by these queri. even if the queri were perfectli specifi, languag in the collect document is inher complex and ambigu and match such languag effect is a formid problem by itself. with thi in mind, we wish to treat mani import quantiti calcul by the  retriev system, whether a relev score for a document, or a weight for a queri expans term, as random  variabl whose true valu is uncertain but where the  uncertainti about the true valu mai be quantifi by replac the fix valu with a probabl distribut over possibl valu. in thi wai, retriev algorithm mai attempt to quantifi the risk or uncertainti associ with their  output rank, or improv the stabil or precis of their intern calcul. current algorithm for pseudo-relev feedback (prf) tend to follow the same basic method whether we us  vector space-base algorithm such as rocchio"s formula [16], or more recent languag model approach such as  relev model [10]. first, a set of top-retriev document is obtain from an initi queri and assum to approxim a set of relev document. next, a singl feedback model vector is comput accord to some sort of averag,  centroid, or expect over the set of possibl-relev  document model. for exampl, the document vector mai be combin with equal weight, as in rocchio, or by queri likelihood, as mai be done us the relev model1 . the us of an expect is reason for practic and  theoret reason, but by itself ignor potenti valuabl inform about the risk of the feedback model. our main hypothesi in thi paper is that estim the uncertainti in feedback is us and lead to better  individu feedback model and more robust combin model. therefor, we propos a method for estim uncertainti associ with an individu feedback model in term of a posterior distribut over languag model. to do thi, we systemat vari the input to the baselin feedback method and fit a dirichlet distribut to the output. we us the posterior mean or mode as the improv feedback model estim. thi process is shown in figur 1. as we show later, the mean and mode mai vari significantli from the singl feedback model propos by the baselin method. we also perform model combin us sever improv feedback languag model obtain by a small number of new queri sampl from the origin queri. a model"s weight combin two complementari factor: the model"s probabl of gener the queri, and the varianc of the model, with high-varianc model get lower weight. 1 for exampl, an expect paramet vector condit on the queri observ is form from top-retriev  document, which ar treat as train string (see [10], p. 62). figur 1: estim the uncertainti of the feedback model for a singl queri. 2. sampl-base feedback in section 2.1-2.5 we describ a gener method for  estim a probabl distribut over the set of possibl languag model. in section 2.6 and 2.7 we summar how differ queri sampl ar us to gener multipl  feedback model, which ar then combin. 2.1 model feedback uncertainti given a queri q and a collect c, we assum a  probabilist retriev system that assign a real-valu document score f(d, q) to each document d in c, such that the score is proport to the estim probabl of relev. we make no other assumpt about f(d, q). the natur of f(d, q) mai be complex: for exampl, if the retriev  system support structur queri languag [12], then f(d, q) mai repres the output of an arbitrarili complex  infer network defin by the structur queri oper. in theori, the score function can vari from queri to queri, although in thi studi for simplic we keep the score function the same for all queri. our specif queri method is given in section 3. we treat the feedback algorithm as a black box and  assum that the input to the feedback algorithm ar the  origin queri and the correspond top-retriev document, with a score be given to each document. we assum that the output of the feedback algorithm is a vector of term weight to be us to add or reweight the term in the  represent of the origin queri, with the vector normal to form a probabl distribut. we view the the input to the feedback black box as random variabl, and analyz the feedback model as a random variabl that chang in  respons to chang in the input. like the document score function f(d, q), the feedback algorithm mai implement a complex, non-linear score formula, and so as it input vari, the result feedback model mai have a complex distribut over the space of feedback model (the sampl space). becaus of thi potenti complex, we do not  attempt to deriv a posterior distribut in close form, but instead us simul. we call thi distribut over  possibl feedback model the feedback model distribut. our goal in thi section is to estim a us approxim to the feedback model distribut. for a specif framework for experi, we us the  languag model (lm) approach for inform retriev [15]. the score of a document d with respect to a queri q and collect c is given by p(q|d) with respect to languag model ˆθq and ˆθd estim for the queri and document respect. we denot the set of k top-retriev  document from collect c in respons to q by dq(k, c). for simplic, we assum that queri and document ar  gener by multinomi distribut whose paramet ar repres by unigram languag model. to incorpor feedback in the lm approach, we assum a model-base scheme in which our goal is take the queri and result rank document dq(k, c) as input, and output an expans languag model ˆθe, which is then interpol with the origin queri model ˆθq: ˆθnew = (1 − α) · ˆθq + α · ˆθe (1) thi includ the possibl of α = 1 where the origin queri mode is complet replac by the feedback model. our sampl space is the set of all possibl languag  model lf that mai be output as feedback model. our  approach is to take sampl from thi space and then fit a distribut to the sampl us maximum likelihood. for simplic, we start by assum the latent feedback  distribut ha the form of a dirichlet distribut. although the dirichlet is a unimod distribut, and in gener quit limit in it express in the sampl space, it is a  natur match for the multinomi languag model, can be  estim quickli, and can captur the most salient featur of confid and uncertain feedback model, such as the overal spread of the distibut. 2.2 resampl document model we would like an approxim to the posterior  distribut of the feedback model lf . to accomplish thi, we appli a wide-us simul techniqu call bootstrap sampl ([7], p. 474) on the input paramet, name, the set of top-retriev document. bootstrap sampl allow us to simul the approxim effect of perturb the paramet within the black box feedback algorithm by perturb the input to that  algorithm in a systemat wai, while make no assumpt about the natur of the feedback algorithm. specif, we sampl k document with replac from dq(k, c), and calcul an expans languag model θb  us the black box feedback method. we repeat thi process b time to obtain a set of b feedback languag model, to which we then fit a dirichlet distribut. typic b is in the rang of 20 to 50 sampl, with perform be rel stabl in thi rang. note that instead of treat each top document as equal like, we sampl accord to the estim probabl of relev of each document in dq(k, c). thu, a document is more like to be chosen the higher it is in the rank. 2.3 justif for a sampl approach the rational for our sampl approach ha two part. first, we want to improv the qualiti of individu  feedback model by smooth out variat when the baselin feedback model is unstabl. in thi respect, our approach resembl bag [4], an ensembl approach which  gener multipl version of a predictor by make bootstrap copi of the train set, and then averag the (numer) predictor. in our applic, top-retriev document can be seen as a kind of noisi train set for relev. second, sampl is an effect wai to estim basic properti of the feedback posterior distribut, which can then be us for improv model combin. for  exampl, a model mai be weight by it predict confid, estim as a function of the variabl of the posterior around the model. foo2-401.map-dim:5434,size:12*12unit,gaussianneighborhood (a) topic 401 foreign minor, germani foo2-402.map-dim:5698,size:12*12unit,gaussianneighborhood (b) topic 402 behavior genet foo2-459.map-dim:8969,size:12*12unit,gaussianneighborhood (c) topic 459 when can a lender foreclos on properti figur 2: visual of expans languag model  varianc us self-organ map, show the distribut of languag model that result from resampl the input to the baselin expans method. the languag model that would have been chosen by the baselin expans is at the center of each map. the similar function is  jensenshannon diverg. 2.4 visual feedback distribut befor describ how we fit and us the dirichlet  distribut over feedback model, it is instruct to view some exampl of actual feedback model distribut that result from bootstrap sampl the top-retriev document from differ trec topic. each point in our sampl space is a languag model, which typic ha sever thousand dimens. to help analyz the behavior of our method we us a self-organ map (via the som-pak packag [9]), to ‘flatten" and visual the high-dimension densiti function2 . the densiti map for three trec topic ar shown in figur 2 abov. the dark area repres region of high similar between languag model. the light area  repres region of low similar - the ‘vallei" between  cluster. each diagram is center on the languag model that would have been chosen by the baselin expans. a singl peak (mode) is evid in some exampl, but more complex structur appear in other. also, while the distribut is usual close to the baselin feedback model, for some topic thei ar a signific distanc apart (as measur by  jensenshannon diverg), as in subfigur 2c. in such case, the mode or mean of the feedback distribut often perform significantli better than the baselin (and in a smaller  proport of case, significantli wors). 2.5 fit a posterior feedback distribut after obtain feedback model sampl by resampl the feedback model input, we estim the feedback  distribut. we assum that the multinomi feedback  model {ˆθ1, . . . , ˆθb} were gener by a latent dirichlet  distribut with paramet {α1, . . . , αn }. to estim the {α1, . . . , αn }, we fit the dirichlet paramet to the b  languag model sampl accord to maximum likelihood  us a gener newton procedur, detail of which ar given in minka [13]. we assum a simpl dirichlet prior over the {α1, . . . , αn }, set each to αi = μ · p(wi | c), where μ is a paramet and p(· | c) is the collect languag model estim from a set of document from collect c. the paramet fit converg veri quickli - typic just 2 or 2 becaus our point ar languag model in the  multinomi simplex, we extend som-pak to support  jensenshannon diverg, a wide-us similar measur  between probabl distribut. 3 iter ar enough - so that it is practic to appli at queri-time when comput overhead must be small. in practic, we can restrict the calcul to the vocabulari of the top-retriev document, instead of the entir collect. note that for thi step we ar re-us the exist retriev document and not perform addit queri. given the paramet of an n-dimension dirichlet  distribut dir(α) the mean μ and mode x vector ar easi to calcul and ar given respect by μi = αip αi (2) and xi = αi−1p αi−n . (3) we can then choos the languag model at the mean or the mode of the posterior as the final enhanc feedback model. (we found the mode to give slightli better perform.) for inform retriev, the number of sampl we will have avail is like to be quit small for perform  reason - usual less than ten. moreov, while random  sampl is us in certain case, it is perfectli accept to allow determinist sampl distribut, but these must be design carefulli in order to approxim an accur output varianc. we leav thi for futur studi. 2.6 queri variant we us the follow method for gener variant of the origin queri. each variant correspond to a differ assumpt about which aspect of the origin queri mai be import. thi is a form of determinist sampl. we select three simpl method that cover complimentari assumpt about the queri. no-expans us onli the origin queri. the  assumpt is that the given term ar a complet descript of the inform need. leav-on-out a singl term is left out of the origin queri. the assumpt is that on of the queri term is a nois term. singl-term a singl term is chosen from the origin queri. thi assum that onli on aspect of the queri, name, that repres by the term, is most import. after gener a variant of the origin queri, we combin it with the origin queri us a weight αsub so that we do not strai too ‘far". in thi studi, we set αsub = 0.5. for exampl, us the indri [12] queri languag, a  leav-oneout variant of the initi queri that omit the term ‘ireland" for trec topic 404 is: #weight(0.5 #combin(ireland peac talk) 0.5 #combin(peac talk)) 2.7 combin enhanc feedback model from multipl queri variant when us multipl queri variant, the result  enhanc feedback model ar combin us bayesian model combin. to do thi, we treat each word as an item to be classifi as belong to a relev or non-relev class, and deriv a class probabl for each word by combin the score from each queri variant. each score is given by that term"s probabl in the dirichlet distribut. the term score ar weight by the invers of the varianc of the term in the enhanc feedback model"s dirichlet  distribut. the prior probabl of a word"s membership in the relev class is given by the probabl of the origin queri in the entir enhanc expans model. 3. evalu in thi section we present result confirm the us of estim a feedback model distribut from weight resampl of top-rank document, and of combin the feedback model obtain from differ small chang in the origin queri. 3.1 gener method we evalu perform on a total of 350 queri  deriv from four set of trec topic: 51-200 (trec-1&2), 351-400 (trec-7), 401-450 (trec-8), and 451-550 (wt10g, trec-9&10). we chose these for their vari content and document properti. for exampl, wt10g document ar web page with a wide varieti of subject and style while trec-1&2 document ar more homogen new articl. index and retriev wa perform us the indri system in the lemur toolkit [12] [1]. our queri were deriv from the word in the titl field of the trec topic. phrase were not us. to gener the baselin queri pass to indri, we wrap the queri term with indri"s #combin oper. for exampl, the initi queri for topic 404 is: #combin(ireland peac talk) we perform krovetz stem for all experi.  becaus we found that the baselin (indri) expans method perform better us a stopword list with the feedback model, all experi us a stoplist of 419 common  english word. howev, an interest side-effect of our  resampl approach is that it tend to remov mani stopword from the feedback model, make a stoplist less critic. thi is discuss further in section 3.6. 3.2 baselin feedback method for our baselin expans method, we us an algorithm includ in indri 1.0 as the default expans method. thi method first select term us a log-odd calcul  describ by pont [14], but assign final term weight us lavrenko"s relev model[10]. we chose the indri method becaus it give a consist strong baselin, is base on a languag model approach, and is simpl to experi with. in a trec evalu us the gov2 corpu [6], the method wa on of the  topperform run, achiev a 19.8% gain in map compar to us unexpand queri. in thi studi, it achiev an averag gain in map of 17.25% over the four collect. indri"s expans method first calcul a log-odd ratio o(v) for each potenti expans term v given by o(v) = x d log p(v|d) p(v|c) (4) over all document d contain v, in collect c. then, the expans term candid ar sort by descend o(v), and the top m ar chosen. final, the term weight r(v) us in the expand queri ar calcul base on the relev model r(v) = x d p(q|d)p(v|d) p(v) p(d) (5) the quantiti p(q|d) is the probabl score assign to the document in the initi retriev. we us dirichlet  smooth of p(v|d) with μ = 1000. thi relev model is then combin with the origin queri us linear interpol, weight by a paramet α. by default we us the top 50 document for feedback and the top 20 expans term, with the feedback interpol paramet α = 0.5 unless otherwis state. for exampl, the baselin expand queri for topic 404 is: #weight(0.5 #combin(ireland peac talk) 0.5 #weight(0.10 ireland 0.08 peac 0.08 northern ...) 3.3 expans perform we measur our feedback algorithm"s effect by two main criteria: precis, and robust. robust, and the tradeoff between precis and robust, is analyz in section 3.4. in thi section, we examin averag  precis and precis in the top 10 document (p10). we also includ recal at 1,000 document. for each queri, we obtain a set of b feedback model us the indri baselin. each feedback model wa obtain from a random sampl of the top k document taken with replac. for these experi, b = 30 and k = 50. each feedback model contain 20 term. on the queri side, we us leav-on-out (loo) sampl to creat the queri variant. singl-term queri sampl had consist wors perform across all collect and so our result here  focu on loo sampl. we us the method describ in section 2 to estim an enhanc feedback model from the dirichlet posterior distribut for each queri variant, and to combin the feedback model from all the queri variant. we call our method ‘resampl expans" and denot it as rs-fb here. we denot the indri baselin feedback method as base-fb. result from appli both the baselin  expans method (base-fb) and resampl expans (rs-fb) ar shown in tabl 1. we observ sever trend in thi tabl. first, the averag precis of rs-fb wa compar to base-fb, achiev an averag gain of 17.6% compar to us no expans across the four collect. the indri baselin expans gain wa 17.25%. also, the rs-fb method achiev  consist improv in p10 over base-fb for everi topic set, with an averag improv of 6.89% over base-fb for all 350 topic. the lowest p10 gain over base-fb wa +3.82% for trec-7 and the highest wa +11.95% for wt10g.  final, both base-fb and rs-fb also consist improv recal over us no expans, with base-fb achiev  better recal than rs-fb for all topic set. 3.4 retriev robust we us the term robust to mean the worst-case  averag precis perform of a feedback algorithm. ideal, a robust feedback method would never perform wors than us the origin queri, while often perform better us the expans. to evalu robust in thi studi, we us a veri  simpl measur call the robust index (ri)3 . for a set of queri q, the ri measur is defin as: ri(q) = n+ − n− |q| (6) where n+ is the number of queri help by the feedback method and n− is the number of queri hurt. here, by ‘help" we mean obtain a higher averag precis as a result of feedback. the valu of ri rang from a minimum 3 thi is sometim also call the reliabl of improv index and wa us in sakai et al. [17]. collect noexp base-fb rs-fb trec 1&2 avgp 0.1818 0.2419 (+33.04%) 0.2406 (+32.24%) p10 0.4443 0.4913 (+10.57%) 0.5363 (+17.83%) recal 15084/37393 19172/37393 15396/37393 trec 7 avgp 0.1890 0.2175 (+15.07%) 0.2169 (+14.75%) p10 0.4200 0.4320 (+2.85%) 0.4480 (+6.67%) recal 2179/4674 2608/4674 2487/4674 trec 8 avgp 0.2031 0.2361 (+16.25%) 0.2268 (+11.70%) p10 0.3960 0.4160 (+5.05%) 0.4340 (+9.59%) recal 2144/4728 2642/4728 2485/4728 wt10g avgp 0.1741 0.1829 (+5.06%) 0.1946 (+11.78%) p10 0.2760 0.2630 (-4.71%) 0.2960 (+7.24%) recal 3361/5980 3725/5980 3664/5980 tabl 1: comparison of baselin (base-fb) feedback and feedback us re-sampl (rs-fb). improv shown for  basefb and rs-fb is rel to us no expans. (a) trec 1&2 (upper curv); trec 8 (lower curv) (b) trec 7 (upper curv); wt10g (lower curv) figur 3: the trade-off between robust and averag  precis for differ corpora. the x-axi give the chang in map over us baselin expans with α = 0.5. the  yaxi give the robust index (ri). each curv through uncircl point show the ri/map tradeoff us the  simpl small-α strategi (see text) as α decreas from 0.5 to zero in the direct of the arrow. circl point repres the tradeoff obtain by resampl feedback for α = 0.5. collect n base-fb rs-fb n− ri n− ri trec 1&2 103 26 +0.495 15 +0.709 trec 7 46 14 +0.391 10 +0.565 trec 8 44 12 +0.455 12 +0.455 wt10g 91 48 -0.055 39 +0.143 combin 284 100 +0.296 76 +0.465 tabl 2: comparison of robust index (ri) for baselin feedback (base-fb) vs. resampl feedback (rs-fb). also shown ar the actual number of queri hurt by feedback (n−) for each method and collect. queri for which  initi averag precis wa neglig (≤ 0.01) were ignor, give the remain queri count in column n. of −1.0, when all queri ar hurt by the feedback method, to +1.0 when all queri ar help. the ri measur doe not take into account the magnitud or distribut of the amount of chang across the set q. howev, it is easi to understand as a gener indic of robust. on obviou wai to improv the worst-case perform of feedback is simpli to us a smaller fix α interpol paramet, such as α = 0.3, place less weight on the  (possibl riski) feedback model and more on the origin queri. we call thi the ‘small-α" strategi. sinc we ar also  reduc the potenti gain when the feedback model is ‘right", howev, we would expect some trade-off between averag precis and robust. we therefor compar the  precis/robust trade-off between our resampl feedback algorithm, and the simpl small-α method. the result ar summar in figur 3. in the figur, the curv for each topic set interpol between trade-off point, begin at x=0, where α = 0.5, and continu in the direct of the arrow as α decreas and the origin queri is given more and more weight. as expect, robust  continu increas as we move along the curv, but mean  averag precis gener drop as the gain from feedback ar elimin. for comparison, the perform of resampl feedback at α = 0.5 is shown for each collect as the circl point. higher and to the right is better. thi figur show that resampl feedback give a somewhat better trade-off than the small-α approach for 3 of the 4 collect. figur 4: histogram show improv robust of  resampl feedback (rs-fb) over baselin feedback (base-fb) for all dataset combin. queri ar bin by % chang in ap compar to the unexpand queri. collect ds + qv ds + no qv trec 1&2 avgp 0.2406 0.2547 (+5.86%) p10 0.5263 0.5362 (+1.88%) ri 0.7087 0.6515 (-0.0572) trec 7 avgp 0.2169 0.2200 (+1.43%) p10 0.4480 0.4300 (-4.02%) ri 0.5652 0.2609 (-0.3043) trec 8 avgp 0.2268 0.2257 (-0.49%) p10 0.4340 0.4200 (-3.23%) ri 0.4545 0.4091 (-0.0454) wt10g avgp 0.1946 0.1865 (-4.16%) p10 0.2960 0.2680 (-9.46%) ri 0.1429 0.0220 (-0.1209) tabl 3: comparison of resampl feedback us  document sampl (ds) with (qv) and without (no qv)  combin feedback model from multipl queri variant. tabl 2 give the robust index score for base-fb and rs-fb. the rs-fb feedback method obtain higher robust than base-fb on three of the four topic set, with onli slightli wors perform on trec-8. a more detail view show the distribut over  rel chang in ap is given by the histogram in figur 4. compar to base-fb, the rs-fb method achiev a  notic reduct in the number of queri significantli hurt by expans (i.e. where ap is hurt by 25% or more), while preserv posit gain in ap. 3.5 effect of queri and document sampl method given our algorithm"s improv robust seen in  section 3.4, an import question is what compon of our system is respons. is it the us of document re-sampl, the us of multipl queri variant, or some other factor? the result in tabl 3 suggest that the model combin base on queri variant mai be larg account for the improv robust. when queri variant ar turn off and the  origin queri is us by itself with document sampl, there is littl net chang in averag precis, a small decreas in p10 for 3 out of the 4 topic set, but a signific drop in robust for all topic set. in two case, the ri measur drop by more than 50%. we also examin the effect of the document sampl method on retriev effect, us two differ  strategi. the ‘uniform weight" strategi ignor the relev score from the initi retriev and gave each document in the top k the same probabl of select. in contrast, the ‘relev-score weight" strategi chose document with probabl proport to their relev score. in thi wai, document that were more highli rank were more like to be select. result ar shown in tabl 4. the relev-score weight strategi perform better overal, with significantli higher ri and p10 score on 3 of the 4 topic set. the differ in averag precis between the method, howev, is less mark. thi suggest that uniform weight act to increas varianc in retriev  result: when initi averag precis is high, there ar mani relev document in the top k and uniform sampl mai give a more repres relev model than focus on the highli-rank item. on the other hand, when initi precis is low, there ar few relev document in the bottom rank and uniform sampl mix in more of the non-relev document. for space reason we onli summar our find on  sampl size here. the number of sampl ha some effect on precis when less than 10, but perform stabil at around 15 to 20 sampl. we us 30 sampl for our  experi. much beyond thi level, the addit benefit of more sampl decreas as the initi score distribut is more close fit and the process time increas. 3.6 the effect of resampl on expans term qualiti ideal, a retriev model should not requir a stopword list when estim a model of relev: a robust  statist model should down-weight stopword automat depend on context. stopword can harm feedback if  select as feedback term, becaus thei ar typic poor discrimin and wast valuabl term slot. in practic, howev, becaus most term select method resembl a tf · idf type of weight, term with low idf but veri high tf can sometim be select as expans term candid. thi happen, for exampl, even with the relev model approach that is part of our baselin feedback. to ensur as strong a baselin as possibl, we us a stoplist for all  experi report here. if we turn off the stopword list, howev, we obtain result such as those shown in tabl 5 where four of the top ten baselin feedback term for trec topic 60 (said, but, their, not) ar stopword us the  basefb method. (the top 100 expans term were select to gener thi exampl.) indri"s method attempt to address the stopword  problem by appli an initi step base on pont [14] to  select less-common term that have high log-odd of be in the top-rank document compar to the whole  collect. nevertheless, thi doe not overcom the stopword problem complet, especi as the number of feedback term grow. us resampl feedback, howev, appear to mitig collect qv + uniform qv + relev-score weight weight trec 1&2 avgp 0.2545 0.2406 (-5.46%) p10 0.5369 0.5263 (-1.97%) ri 0.6212 0.7087 (+14.09%) trec 7 avgp 0.2174 0.2169 (-0.23%) p10 0.4320 0.4480 (+3.70%) ri 0.4783 0.5652 (+18.17%) trec 8 avgp 0.2267 0.2268 (+0.04%) p10 0.4120 0.4340 (+5.34%) ri 0.4545 0.4545 (+0.00%) wt10g avgp 0.1808 0.1946 (+7.63%) p10 0.2680 0.2960 (+10.45%) ri 0.0220 0.1099 (+399.5%) tabl 4: comparison of uniform and relev-weight document sampl. the percentag chang compar to uniform sampl is shown in parenthes. qv indic that queri variant were us in both run. baselin fb p(wi|r) resampl fb p(wi|r) said 0.055 court 0.026 court 0.055 pai 0.018 pai 0.034 feder 0.012 but 0.026 educ 0.011 employe 0.024 teacher 0.010 their 0.024 employe 0.010 not 0.023 case 0.010 feder 0.021 their 0.009 worker 0.020 appeal 0.008 educ 0.020 union 0.007 tabl 5: feedback term qualiti when a stoplist is not us. feedback term for trec topic 60: merit pai vs senior. the effect of stopword automat. in the exampl of  tabl 5, resampl feedback leav onli on stopword (their) in the top ten. we observ similar feedback term behavior across mani other topic. the reason for thi effect appear to be the interact of the term select score with the top-m term cutoff. while the presenc and even  proport of particular stopword is fairli stabl across differ document sampl, their rel posit in the top-m list is not, as set of document with vari number of  better, lower-frequenc term candid ar examin for each sampl. as a result, while some number of stopword mai appear in each sampl document set, ani given stopword tend to fall below the cutoff for multipl sampl, lead to it classif as a high-varianc, low-weight featur. 4. relat work our approach is relat to previou work from sever  area of inform retriev and machin learn. our us of queri variat wa inspir by the work of yomtov et al. [20], carpineto et al. [5], and amati et al. [2], among other. these studi us the idea of creat multipl  subqueri and then examin the natur of the overlap in the document and/or expans term that result from each subqueri. model combin is perform us heurist. in particular, the studi of amati et al. and carpineto et al. investig combin term from individu distribut method us a term-rerank combin heurist. in a set of trec topic thei found wide averag variat in the rank-distanc of term from differ expans  method. their combin method gave modest posit  improv in averag precis. the idea of examin the overlap between list of  suggest term ha also been us in earli queri expans approach. xu and croft"s method of local context  analysi (lca) [19] includ a factor in the empir-deriv weight formula that caus expans term to be  prefer that have connect to multipl queri term. on the document side, recent work by zhou & croft [21] explor the idea of ad nois to document, re-score them, and us the stabil of the result rank as an estim of queri difficulti. thi is relat to our us of document sampl to estim the risk of the feedback model built from the differ set of top-retriev  document. sakai et al. [17] propos an approach to improv the robust of pseudo-relev feedback us a method thei call select sampl. the essenc of their method is that thei allow skip of some top-rank document, base on a cluster criterion, in order to select a more  vari and novel set of document later in the rank for us by a tradit pseudo-feedback method. their studi did not find signific improv in either robust (ri) or map on their corpora. greiff, morgan and pont [8] explor the role of varianc in term weight. in a seri of simul that simplifi the problem to 2-featur document, thei found that averag precis degrad as term frequenc varianc - high  noiseincreas. downweight term with high varianc result in improv averag precis. thi seem in accord with our own find for individu feedback model. estim of output varianc have recent been us for improv text classif. lee et al. [11] us  queryspecif varianc estim of classifi output to perform improv model combin. instead of us sampl, thei were abl to deriv close-form express for classifi varianc by assum base classifi us simpl type of infer network. ando and zhang propos a method that thei call  structur feedback [3] and show how to appli it to queri  expans for the trec genom track. thei us r queri variat to obtain r differ set sr of top-rank  document that have been intersect with the top-rank  document obtain from the origin queri qorig. for each si, the normal centroid vector ˆwi of the document is  calcul. princip compon analysi (pca) is then appli to the ˆwi to obtain the matrix Φ of h left singular vector φh that ar us to obtain the new, expand queri qexp = qorig + Φt Φqorig. (7) in the case h = 1, we have a singl left singular vector φ: qexp = qorig + (φt qorig)φ so that the dot product φt qorig is a type of dynam weight on the expand queri that is base on the similar of the origin queri to the expand queri. the us of varianc as a feedback model qualiti measur occur indirectli through the applic of pca. it would be interest to studi the connect between thi approach and our own  modelfit method. final, in languag model approach to feedback, tao and zhai [18] describ a method for more robust feedback that allow each document to have a differ feedback α. the feedback weight ar deriv automat us  regular em. a roughli equal balanc of queri and expans model is impli by their em stop condit. thei  propos tailor the stop paramet η base on a function of some qualiti measur of feedback document. 5. conclus we have present a new approach to pseudo-relev feedback base on document and queri sampl. the us of sampl is a veri flexibl and power devic and is  motiv by our gener desir to extend current model of  retriev by estim the risk or varianc associ with the paramet or output of retriev process. such varianc estim, for exampl, mai be natur us in a bayesian framework for improv model estim and combin. applic such as select expans mai then be  implement in a principl wai. while our studi us the languag model approach as a framework for experi, we make few assumpt about the actual work of the feedback algorithm. we believ it is like that ani reason effect baselin feedback algorithm would benefit from our approach. our result on standard trec collect show that our framework  improv the robust of a strong baselin feedback method across a varieti of collect, without sacrif averag precis. it also give small but consist gain in  top10 precis. in futur work, we envis an investig into how vari the set of sampl method us and the number of sampl control the trade-off between  robust, accuraci, and effici. acknowledg we thank paul bennett for valuabl discuss relat to thi work, which wa support by nsf grant #ii-0534345 and #cn-0454018, and u.s. dept. of educ grant #r305g03123. ani opinion, find, and conclus or recommend express in thi materi ar the author. and do not necessarili reflect those of the sponsor. 6. refer [1] the lemur toolkit for languag model and retriev. http://www.lemurproject.org. [2] g. amati, c. carpineto, and g. romano. queri difficulti, robust, and select applic of queri expans. in proc. of the 25th european conf. on inform retriev (ecir 2004), page 127-137. [3] r. k. ando and t. zhang. a high-perform semi-supervis learn method for text chunk. in proc. of the 43rd annual meet of the acl, page 1-9, june 2005. [4] l. breiman. bag predictor. machin learn, 24(2):123-140, 1996. [5] c. carpineto, g. romano, and v. giannini. improv retriev feedback with multipl term-rank function combin. acm tran. info. system, 20(3):259 - 290. [6] k. collin-thompson, p. ogilvi, and j. callan. initi result with structur queri and languag model on half a terabyt of text. in proc. of 2005 text retriev confer. nist special public. [7] r. o. duda, p. e. hart, and d. g. stork. pattern classif. wilei and son, 2nd edit, 2001. [8] w. r. greiff, w. t. morgan, and j. m. pont. the role of varianc in term weight for probabilist inform retriev. in proc. of the 11th intl. conf. on info. and knowledg mgmt. (cikm 2002), page 252-259. [9] t. kohonen, j. hynninen, j. kanga, and j. laaksonen. sompak: the self-organ map program packag. technic report a31, helsinki univers of technolog, 1996. http://www.ci.hut.fi/research/paper/som tr96.ps.z. [10] v. lavrenko. a gener theori of relev. phd thesi, univers of massachusett, amherst, 2004. [11] c.-h. lee, r. greiner, and s. wang. us queri-specif varianc estim to combin bayesian classifi. in proc. of the 23rd intl. conf. on machin learn (icml 2006), page 529-536. [12] d. metzler and w. b. croft. combin the languag model and infer network approach to retriev. info. process and mgmt., 40(5):735-750, 2004. [13] t. minka. estim a dirichlet distribut. technic report, 2000. http://research.microsoft.com/ minka/paper/dirichlet. [14] j. pont. advanc in inform retriev, chapter languag model for relev feedback, page 73-96. 2000. w.b. croft, ed. [15] j. m. pont and w. b. croft. a languag model approach to inform retriev. in proc. of the 1998 acm sigir confer on research and develop in inform retriev, page 275-281. [16] j. rocchio. the smart retriev system, chapter relev feedback in inform retriev, page 313-323. prentic-hall, 1971. g. salton, ed. [17] t. sakai, t. manab, and m. koyama. flexibl pseudo-relev feedback via select sampl. acm transact on asian languag inform process (talip), 4(2):111-135, 2005. [18] t. tao and c. zhai. regular estim of mixtur model for robust pseudo-relev feedback. in proc. of the 2006 acm sigir confer on research and develop in inform retriev, page 162-169. [19] j. xu and w. b. croft. improv the effect of inform retriev with local context analysi. acm tran. inf. syst., 18(1):79-112, 2000. [20] e. yomtov, s. fine, d. carmel, and a. darlow. learn to estim queri difficulti. in proc. of the 2005 acm sigir conf. on research and develop in inform retriev, page 512-519. [21] y. zhou and w. b. croft. rank robust: a novel framework to predict queri perform. in proc. of the 15th acm intl. conf. on inform and knowledg mgmt. (cikm 2006), page 567-574. 